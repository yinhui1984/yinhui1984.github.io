[{"categories":["Blockchain"],"content":"IPFS 基础知识 ","date":"2022-10-24","objectID":"/ipfs/:0:0","tags":["IPFS","L1","Web3.0"],"title":"IPFS","uri":"/ipfs/"},{"categories":["Blockchain"],"content":"什么是IPFS 相比于以前的本地存储, 我们现在更喜欢使用云存储, 云存储是由云存储提供商提供的集中式存储, 其有很多优点, 比如用户使用起来简单,提供数据保护等, 但短板也很明显, 比如可访问性、保密性、信任、以及抗审查能力弱等问题。针对这些问题， 便出现了P2P数据网络，大家印象最深刻的便是BT下载。 关于P2P数据网络， 参考这里 ： https://yinhui1984.github.io/p2p/ IPFS 属于新一代P2P数据网络之一（还有 Swarm、SAFE、Storj等等），采用官方的解释是 “IPFS is a distributed system for storing and accessing files, websites, applications, and data.” 另外， 从区块链的角度说， 将数据放在诸如ETH这样的链上代价是昂贵的，对应大型数据也是不现实的， 所以需要一个系统来解决Dapp的数据存储问题， 正如编写传统APP需要有数据库一样。 ","date":"2022-10-24","objectID":"/ipfs/:1:0","tags":["IPFS","L1","Web3.0"],"title":"IPFS","uri":"/ipfs/"},{"categories":["Blockchain"],"content":"IPFS初识 ","date":"2022-10-24","objectID":"/ipfs/:2:0","tags":["IPFS","L1","Web3.0"],"title":"IPFS","uri":"/ipfs/"},{"categories":["Blockchain"],"content":"安装与启动 首先安装IPFS Desktop 和 CLI： https://docs.ipfs.tech/install/ 命令行安装： \u003e wget --no-check-certificate https://dist.ipfs.tech/kubo/v0.16.0/kubo_v0.16.0_linux-amd64.tar.gz \u003e tar -xvzf kubo_v0.16.0_linux-amd64.tar.gz \u003e cd kubo \u0026\u0026 sudo bash install.sh 初始化 \u003e ipfs init 启动节点 \u003e ipfs daemon 查看节点信息 \u003e ipfs id -f=\"\u003cid\u003e\" 12D3KooWJdT87m7RVHHwYmvTzhitNhuG9eVBJB5EiQeCGcR13aHE 可以在另外一台电脑或虚拟机上使用ipfs ping \u003cid\u003e 来尝试ping这个id ➜ ~ ipfs ping 12D3KooWJdT87m7RVHHwYmvTzhitNhuG9eVBJB5EiQeCGcR13aHE PING 12D3KooWJdT87m7RVHHwYmvTzhitNhuG9eVBJB5EiQeCGcR13aHE. Pong received: time=0.66 ms ... 尝试连接: ➜ ~ ipfs swarm connect /ipfs/12D3KooWJdT87m7RVHHwYmvTzhitNhuG9eVBJB5EiQeCGcR13aHE connect 12D3KooWJdT87m7RVHHwYmvTzhitNhuG9eVBJB5EiQeCGcR13aHE success ","date":"2022-10-24","objectID":"/ipfs/:2:1","tags":["IPFS","L1","Web3.0"],"title":"IPFS","uri":"/ipfs/"},{"categories":["Blockchain"],"content":"上传一个文件 我们使用下面这个脚本生成一个大于256K的文件,然后上传到IPFS #!/usr/bin/env sh TEXTFILE=./text.txt TRUE \u003e $TEXTFILE counter=0 # while size of text.txt \u003c 300k, write content into it # get size of text.txt # linux: stat -c%s \"$FILENAME\" # macos: stat -f%z \"$FILENAME\" FILESIZE=$(stat -f%z \"$TEXTFILE\") LINE=\"########################################################\" while [ \"$FILESIZE\" -lt 307200 ]; do echo ${counter}$LINE \u003e\u003e ./text.txt counter=$((counter+1)) FILESIZE=$(stat -f%z \"$TEXTFILE\") done OSX MP16 ~/Desktop/ipfs_demo ❯ ipfs add ./local_file/text.txt added QmPLXXaC81eGS3fNoCkvaqaRPFRu9pUCQMbKvajo9co1ND text.txt 300.04 KiB / 300.04 KiB [=========================] 100.00% 上传完成后, 其会给出一个地址字符串, 叫着 CID (conent id). 可以理解为该文件的hash值, 但不仅仅如此. 参考这里: https://docs.ipfs.tech/concepts/content-addressing/#cid-versions 使用ipfs cat 命令可以将内容打印出来: ➜ ~ ipfs cat QmPLXXaC81eGS3fNoCkvaqaRPFRu9pUCQMbKvajo9co1ND 0######################################################## 1######################################################## 2######################################################## 3######################################################## ... ... 5051######################################################## 5052######################################################## 5053######################################################## 5054######################################################## ➜ ~ 使用ipfs ls命令我们可以看到 这个CID又指向另外2个CID OSX MP16 ~ ❯ ipfs ls -v QmPLXXaC81eGS3fNoCkvaqaRPFRu9pUCQMbKvajo9co1ND Hash Size Name QmaroDZbcMjim4a8nVyahnvb3hhCSSTsCZB2jCJEsrd3ZF 262144 QmU6xSMhb74oxAXRjLVRwqsJJgU4GH14FDVME5qys8uFZF 45101 分别ipfs cat出这两个CID, 看看其中的内容: OSX MP16 ~ ❯ ipfs cat QmaroDZbcMjim4a8nVyahnvb3hhCSSTsCZB2jCJEsrd3ZF 0######################################################## 1######################################################## 2######################################################## 3######################################################## 4######################################################## ... ... 4312######################################################## 4313######################################################## 4314######################################################## 4315################################### OSX MP16 ~ ❯ OSX MP16 ~ ❯ ipfs cat QmU6xSMhb74oxAXRjLVRwqsJJgU4GH14FDVME5qys8uFZF ##################### 4316######################################################## 4317######################################################## 4318######################################################## 4319######################################################## 4320######################################################## ... ... 5051######################################################## 5052######################################################## 5053######################################################## 5054######################################################## 很明显的, 我们上传的文件被分成了2个部分,分别存储了. 这涉及到2个知识: IPFS的文件存储是分块(Block)存储的, 一个块最大容量是256KB IPFS使用的是默克尔树的形式来进行存储的 到 IPFS Desktop上看就更形象了 在公共网关上查看 ipfs 内容能在本地看到, 但无法在公共网关上看到 ? 添加配置: ipfs config --json Swarm.RelayClient.Enabled true 重启ipfs ipfs shutdown ipfs daemon https://ipfs.io/ipfs/QmPLXXaC81eGS3fNoCkvaqaRPFRu9pUCQMbKvajo9co1ND ","date":"2022-10-24","objectID":"/ipfs/:2:2","tags":["IPFS","L1","Web3.0"],"title":"IPFS","uri":"/ipfs/"},{"categories":["Blockchain"],"content":"理论基础 ","date":"2022-10-24","objectID":"/ipfs/:3:0","tags":["IPFS","L1","Web3.0"],"title":"IPFS","uri":"/ipfs/"},{"categories":["Blockchain"],"content":"Hash Hash函数在https://yinhui1984.github.io/pow/#hash 中说过. 但那里没有提及Hash面临的问题: 哈希算法很多, 不同的软件可能采用不同的算法, 并且算法输出的哈希值长度也不一样 随着时间的推移, 某一些哈希算法可能会被发现存在不安全因素而被弃用而采取其他的算法,或进行升级 这就导致在编写哈希解码程序的时候, 一个程序会面对很多种算法, 这在兼容性和算法升级上是很痛苦的. mutihash (聚合哈希) 针对上面的问题, 提出了mutihash https://multiformats.io/multihash/ 基本原理就是在hash值前面加上哈希算法类型和哈希值长度这样两个前缀 \u003chash-func-type\u003e\u003cdigest-length\u003e\u003cdigest-value\u003e 完整类型列表在这里 : https://github.com/multiformats/multicodec/blob/master/table.csv name tag code status description … sha2-256 multihash 0x12 permanent … 比如 \"12200ED3911004C0EF2CC63ADCDC9E44CD8C2C831EEC0E4431402000F5325A7FE1AE\" 就表示类型是0x12, 也就是sha2-256, 长度为0x20 = 32Byte = 256bit , 哈希值为 0ED3911004C0EF2CC63ADCDC9E44CD8C2C831EEC0E4431402000F5325A7FE1AE 举例 OSX MP16 ~ ❯ cat ./hello.txt helloworld OSX MP16 ~ ❯ ipfs add ./hello.txt added QmUU2HcUBVSXkfWPUc3WUSeCMrWWeEJTuAgR9uyWBhh9Nf hello.txt 11 B / 11 B [==============] 100.00 点击IPFS Desktop 文件 -\u003e 导入(来自IPFS路径) 按钮, 导入上面的CID, 然后在导入的题目上选择\"检查\" 我们可以看到其采用的是sha2-256的哈希算法 我们导出该数据块(block), 手动使用sha2-256来看看其hash值是否如此: ~❯ ipfs block get QmUU2HcUBVSXkfWPUc3WUSeCMrWWeEJTuAgR9uyWBhh9Nf \u003e hello.block ~❯ sha256sum ./hello.block 5b0995ced69229d26009c53c185a62ea805a339383521edbed1028c496615448 ./hello.block 注意: 直接对./hello.txt 进行hash得到的值是不同的 ~❯ sha256sum ./hello.txt 8cd07f3a5ff98f2a78cfc366c13fb123eb8d29c1ca37c79df190425d5b9e424d ./hello.txt 这是为什么? 这是因为IPFS在存储hello.txt中的内容时,还添加了其他信息, 其和数据信息一起作为\"块的内容\"被存储起来的 ","date":"2022-10-24","objectID":"/ipfs/:3:1","tags":["IPFS","L1","Web3.0"],"title":"IPFS","uri":"/ipfs/"},{"categories":["Blockchain"],"content":"CID 关于CID的介绍参考这里 : https://docs.ipfs.tech/concepts/content-addressing/#what-is-a-cid 以及官方教程: https://proto.school/anatomy-of-a-cid 我们这里以CID v0为例, 看看IPFS是如何生成CID的 导出CID为 QmUU2HcUBVSXkfWPUc3WUSeCMrWWeEJTuAgR9uyWBhh9Nf 一个块: ~ \u003e ipfs block get QmUU2HcUBVSXkfWPUc3WUSeCMrWWeEJTuAgR9uyWBhh9Nf \u003e hello.block IPFS 生成CID v0的步骤 : 1, 将块数据进行一次sha256 哈希, 得到H1 2, 在H1前面追加哈希算法类型和H1哈希长度 得到 S 3, 将S进行一次base58编码 package main import ( \"crypto/sha256\" \"fmt\" \"github.com/mr-tron/base58/base58\" \"os\" ) func main() { bytes, _ := os.ReadFile(\"hello.block\") s := sha256.Sum256(bytes) //0x12 表示 sha256 //https://github.com/multiformats/multicodec/blob/master/table.csv //0x20 表示 32Byte s1 := append([]byte{0x12, 0x20}, s[:]...) output := base58.Encode(s1[:]) fmt.Println(\"MY CID: \", output) } OSX MP16 ~/Desktop/ipfs_demo/cid_demo ❯ go run . MY CID: QmUU2HcUBVSXkfWPUc3WUSeCMrWWeEJTuAgR9uyWBhh9Nf OSX MP16 ~/Desktop/ipfs_demo/cid_demo ❯ 一个在线的CID查看器: https://cid.ipfs.tech/#QmUU2HcUBVSXkfWPUc3WUSeCMrWWeEJTuAgR9uyWBhh9Nf 通用的生成CID的代码如下: https://github.com/ipfs/go-cid package main import ( \"fmt\" \"github.com/ipfs/go-cid\" mc \"github.com/multiformats/go-multicodec\" mh \"github.com/multiformats/go-multihash\" \"os\" ) func main() { bytes, _ := os.ReadFile(\"hello.block\") pref := cid.Prefix{ //这里指定 CID version Version: 0, Codec: uint64(mc.Raw), //这里指定哈希算法 MhType: mh.SHA2_256, MhLength: -1, // default length } c, err := pref.Sum(bytes) if err != nil { panic(err) } fmt.Println(\"Created CID: \", c) } 其他编程语言的CID实现在这里 : https://github.com/multiformats/cid#implementations ","date":"2022-10-24","objectID":"/ipfs/:3:2","tags":["IPFS","L1","Web3.0"],"title":"IPFS","uri":"/ipfs/"},{"categories":["Blockchain"],"content":"默克尔有向无环图(Merkle DAG) 参考这篇文章, 写得非常详细 https://developer.aliyun.com/article/842854 ","date":"2022-10-24","objectID":"/ipfs/:3:3","tags":["IPFS","L1","Web3.0"],"title":"IPFS","uri":"/ipfs/"},{"categories":["Blockchain"],"content":"分布式哈希表 DHT Comming soon … ","date":"2022-10-24","objectID":"/ipfs/:3:4","tags":["IPFS","L1","Web3.0"],"title":"IPFS","uri":"/ipfs/"},{"categories":["Blockchain"],"content":"IPFS和朋友们: 下一代点对点数据网络的定性比较 Erik Daniel and Florian Tschorsch https://arxiv.org/pdf/2201.05286.pdf 摘要–分散的分布式存储为减少数据孤岛的影响提供了一种方法，因为集中式云存储往往会助长这种影响。虽然这种趋势的意图并不新鲜，但由于技术的进步，特别是区块链网络的发展，这个话题得到了牵引。因此，我们观察到，新一代的点对点数据网络出现了。因此，在这篇调查报告中，我们对下一代数据网络进行了技术概述。我们使用选定的数据网络来介绍一般概念，并强调新的发展。具体来说，我们提供了星际文件系统的更深入的概要，以及Swarm、Hypercore Protocol、SAFE、Storj和Arweave的总体概述。我们确定了共同的构建模块，并提供了一个定性的比较。从概述中，我们得出了有关数据网络的未来挑战和研究目标。 索引词–数据网络，区块链网络，点对点网络，叠加网络 ","date":"2022-10-20","objectID":"/ipfs_friends/:0:0","tags":["IPFS","L1","Web3.0"],"title":"IPFS和朋友们","uri":"/ipfs_friends/"},{"categories":["Blockchain"],"content":"介绍 如今，用户以这种或那种方式通过使用云存储供应商来存储和共享数据。云存储是集中组织的，其中存储基础设施通常由一个单一的逻辑实体拥有和管理。这种云存储供应商负责存储、定位、提供和保护数据。虽然云存储可以有很多经济和技术上的优势，但它也引起了一系列的担忧。集中的控制和治理导致了可能影响可访问性、可用性和保密性的数据孤岛。例如，数据访问可能会受到审查的影响。同时，数据孤岛构成了一个有价值的漏洞和获取数据出售的目标，这对安全和隐私构成了威胁。一般来说，用户失去了自我决定的控制权，而将其委托给云计算供应商。 摆脱数据孤岛和减少信任假设的一个方向是点对点数据网络。这个术语概括了一系列的数据存储方法，它们建立在对等（P2P）网络的基础上，包括数据存储、复制、分发和交换等方面。作为P2P网络的典型，peers直接互动，建立一个覆盖网络，共享资源，并可以做出自主的本地决定。因此，P2P数据网络致力于共同管理和共享存储。虽然P2P网络的主要目标和原则在过去20年中没有改变，但P2P网络随着时间的推移不断发展，改进了可用性和功能。在图1中，我们说明了从第一代到下一代数据网络的发展。 ","date":"2022-10-20","objectID":"/ipfs_friends/:1:0","tags":["IPFS","L1","Web3.0"],"title":"IPFS和朋友们","uri":"/ipfs_friends/"},{"categories":["Blockchain"],"content":"A. 第一代数据网络 有许多不同的老式P2P网络，也可以归类为数据网络。P2P技术的普及是在1999年随着音频文件共享网络Napster出现的，紧随其后的是用于共享所有类型文件的Gnutella[1]。Napster和Gnutella标志着一个开端，随后许多其他P2P网络集中于专门的应用领域或新颖的网络结构。例如，Freenet[2]实现了匿名存储和检索。Chord[3]、CAN[4]和Pastry[5]提供了维护结构化叠加网络拓扑的协议。特别是，BitTorrent[6]受到了用户和研究界的广泛关注。BitTorrent引入了一种激励机制来实现帕累托效率，试图提高网络利用率达到更高的稳健性。我们认为Napster、Gnutella、Freenet、BitTorrent等网络是第一代P2P数据网络，它们主要关注文件共享。 Androutsellis-Theotokis和Spinellis[7]提供了2004年P2P内容分发技术的现状，对前一代技术进行了广泛的介绍。以前的其他作品也对前一代产品进行了更仔细的研究，更关注特定的P2P数据网络（如FreeNet和Past）[8, 9]或一般的分散文件系统（如Google FS和Hadoop Distributed FS）[10]。 P2P技术的进步和这种第一代数据网络的普及，影响了分布式文件系统[8]和内容分发技术[7]的领域。这种趋势也属于一般的数据网络，特别是P2P数据网络的范畴。 ","date":"2022-10-20","objectID":"/ipfs_friends/:1:1","tags":["IPFS","L1","Web3.0"],"title":"IPFS和朋友们","uri":"/ipfs_friends/"},{"categories":["Blockchain"],"content":"B. 过度阶段 P2P文件共享系统中似乎缺少一个组成部分，那就是提高文件的长期存储和可用性的方法。随着2008年比特币[11]的问世，P2P理念，尤其是联合数据复制获得了新的发展。分布式账本技术在分布式系统中提供了可用性、完整性和拜占庭容错性。特别是，加密货币显示了其在去中心化环境中作为货币激励机制的潜力。这些和其他的趋势和发展，例如Kademlia[12]和以信息为中心的网络[13]，导致了我们发明了下一代的P2P数据网络。 ","date":"2022-10-20","objectID":"/ipfs_friends/:1:2","tags":["IPFS","L1","Web3.0"],"title":"IPFS和朋友们","uri":"/ipfs_friends/"},{"categories":["Blockchain"],"content":"C. 下一代数据网络 从2014年IPFS[14]的推出开始，我们将下一代数据网络定义为过去十年出现的去中心化的数据共享和存储的系统和概念。我们提供了这个下一代P2P数据网络的技术概述。与现有文献相比，我们对下一代数据网络，即P2P数据网络进行了比较概述。我们专注于独立于区块链的利用的存储和内容共享。 在本文中，我们展示了这些新系统是如何建立的，它们如何利用从以前的系统中获得的知识，以及过去十年的新发展和进步。我们确定了这些系统的构建块、相似性和趋势。虽然有些系统本身就是其他应用的构件，例如去中心化的应用（DApps），但我们专注于两个主要的系统方面：内容分发和分布式存储。此外，我们还提供了对激励机制的见解，部署在检索或存储文件，或两者兼而有之。由于许多新的数据网络被开发出来，我们不能提供所有数据网络的全面概述。相反，我们专注于一些具有复杂或独特机制的精选系统，不同的使用案例，以及不同程度的内容和用户隐私。我们的概述侧重于概念，并从实施细节中抽象出来，以提取一般的见解。然而，应该注意的是，由于正在进行的开发，这些系统很容易发生变化。我们的调查报告利用了广泛的来源，包括同行评议的论文、白皮书以及文档、规范和源代码。 具体来说，我们关注IPFS[14]、Swarm[15]、Hypercore协议[16]、SAFE[17]、Storj[18]和Arweave[19]。特别是，InterPlanetary File System（IPFS）作为区块链的存储层已经得到了普及[20-26]，并且是一系列研究的主题[27-37]。此外，我们将这些系统的概述与之前的系统和研究方向，即BitTorrent、以信息为中心的网络和区块链放在一起。通过对比前驱系统，我们勾勒出数据网络的演变，并能够深刻地讨论下一代的进步。 基于这一概述，我们提取了P2P数据网络的构建模块和一些独特的方面。虽然所有系统都允许分布式内容共享和存储，但它们似乎都集中在其中一个方面。也就是说，每个系统的目的略有不同，要求和关注点也不同。这导致了在网络组织、文件查询、分散程度、冗余度和隐私方面的不同设计决定。例如，Storj的目标是分布式云存储，而Hypercore协议的重点是分布大型数据集。同样，IPFS旨在取代网络的客户端-服务器结构，因此需要比BitTorrent更关注数据查询，因为BitTorrent主要是将每个文件放在自己的覆盖网络中。同时，我们发现在构建数据网络的方法上有许多相似之处，例如，使用Kademlia来构建网络或寻找对等人，将文件分割成碎片，或激励不同的任务来增加功能。 其他关于下一代数据网络的研究特别关注与区块链的互动。Huang等人[38]主要涉及IPFS和Swarm，Benisi等人[39]讨论这些技术时更注重区块链方面。Casino等人[40]仔细研究了去中心化存储的不可更改性及其后果和可能的威胁。然而，一些数据网络由于可扩展性或延迟问题，明确决定反对使用区块链。因此，在我们的调查报告中，我们从更广泛的角度来看待数据网络，关注区块链之外的数据网络的设计决策。 Naik和Keshavamurthy[41]对最近的P2P网络给出了一个更普遍的观点。他们描述了下一级P2P网络，BitTorrent和Chord等经典网络的演变，并讨论了流失率下的性能问题。应该注意的是，他们对下一代网络的定义与我们对下一代的定义不同，因为他们把IPFS定义为 “经典的P2P网络”。相反，我们认为，P2P数据网络随着时间的推移而发展，融入了新建立的领域的想法，例如，明确的激励机制。 其余部分的结构如下。调查从系统观点过渡到数据网络的研究观点，而不是组件观点。作为系统观点的一部分，我们首先提供了数据网络的技术先驱的背景信息（第二节）。随后，我们介绍了 “IPFS和朋友”，并提供了下一代数据网络的详细技术概述（第三节和第四节）。最后，我们提到相关的系统和概念（第IV-F节）。作为组件观点的一部分，我们推导出数据网络的构件，并分享从技术概述中获得的见解（第五节）。最后，我们过渡到研究视角，并确定研究领域和开放的挑战（第六节）。第七部分是本调查的结论。 ","date":"2022-10-20","objectID":"/ipfs_friends/:1:3","tags":["IPFS","L1","Web3.0"],"title":"IPFS和朋友们","uri":"/ipfs_friends/"},{"categories":["Blockchain"],"content":"前驱技术 自P2P数据网络首次出现以来，已经有二十多年了。在此期间，该技术不断发展，并影响了新网络的发展。我们观察到，P2P数据网络基本上有三个 “时代”。首先是1999-2002年的P2P文件共享和网络，如BitTorrent和Kademlia，我们认为这是第一代。这个时代之后是 “过渡阶段”，出现了以信息为中心的网络和加密货币等新思想。大约从2014年起，随着IPFS的发明，我们看到新一代的P2P数据网络逐渐受到重视。为了更好地理解和欣赏这些影响因素，我们提供了一个介绍，即BitTorrent、Kademlia、以信息为中心的网络、自我认证的名称和区块链等重要的 “前驱 “技术铺垫。 ","date":"2022-10-20","objectID":"/ipfs_friends/:2:0","tags":["IPFS","L1","Web3.0"],"title":"IPFS和朋友们","uri":"/ipfs_friends/"},{"categories":["Blockchain"],"content":"A. BitTorrent BitTorrent协议[6]是一个P2P文件共享协议。它有一个控制下载行为的激励结构，试图实现公平的资源消耗。BitTorrent的目标是提供一种比使用单一服务器更有效的方式来分发文件。这是通过利用文件在每次下载时被复制的事实来实现的，使文件分发具有自我扩展性。 文件以torrents的形式进行交换。一般来说，每个torrent是一个P2P覆盖网络，负责一个文件。为了用BitTorrent协议交换一个文件，需要创建一个.torrent文件，其中包含文件的元数据和一个联络点，即一个跟踪器。也可以在一个.torrent文件中定义多个文件。在文件被共享之前，torrent文件需要被提供，例如在一个网络服务器上。跟踪器作为torrent的引导节点。拥有完整文件的对等体被称为播种者。那些仍然错过大块文件(chunks)的对等者被称为租赁者。Leechers要求获取文件块并同时作为已经下载的文件块的下载点。 图2是BitTorrent如何处理文件的概念性概述，可以看出。这些角色及其相互作用如下：一个对等体得到.torrent文件，联系.torrent文件中列出的跟踪者𝑇，得到一个对等体的列表，连接到对等体并成为一个租赁者。在图中，对等体𝑆0作为文件的种子，对等体𝐿𝑖代表请求不同块的租赁者。如图所示，在.torrent文件中，该文件被分割成若干块𝑐𝑗。在一个泄密者成功获得所有的块之后，它就成为一个新的种子。种子𝑆0和租借者为该文件建立torrent网络。其他文件则分布在不同的torrent网络中，可能有不同的对等人。 除了所提出的集中式跟踪器之外，还有无跟踪器的torrent。在无追踪器的torrent中，种子是通过分布式哈希表（DHT）找到的。客户端从torrent文件中获得密钥，DHT返回torrent的可用对等体列表。BitTorrent客户端可以使用预先确定的节点或由torrent文件提供的节点来引导DHT. 使BitTorrent独特（可能也是成功的）的特点是明确激励对等人交换数据，这在文件共享策略中实现了最稀有的一块第一和针锋相对。最稀有的片段首先描述了BitTorrent的块选择。它可以确保最大限度地减少数据块的重叠，使文件交换对节点的流失更加有力。在网络中最不常见的块被优先选择用于下载。针锋相对 “描述了带宽资源分配机制。在BitTorrent中，对等人根据从对等人那里下载的数据来决定他们向谁上传数据。这应该可以防止勒索者只下载而不提供任何资源给其他人。 BitTorrent被研究得很好[42-44]，并且已经证明了它的时间考验。尽管它年代久远，但仍有数百万人[45]积极使用它来分享文件，也是新的点对点文件分发系统的典范。此外，BitTorrent基金会和Tron基金会开发了BitTorrent Token（BTT）[46]，它作为一个基于区块链的激励层，提高了文件的可用性和持久性。新的激励结构通过投标数据扩展了针锋相对。出价数据决定BTT/字节率，对等体为持续服务支付BTT。作为付款的交换，对等体是畅通无阻(unchoked)，有资格接收数据。token的交换由一个支付渠道处理。 ","date":"2022-10-20","objectID":"/ipfs_friends/:2:1","tags":["IPFS","L1","Web3.0"],"title":"IPFS和朋友们","uri":"/ipfs_friends/"},{"categories":["Blockchain"],"content":"B. Kademlia (卡德米利亚协议) 从今天的角度来看，Kademlia[12]可能是使用最广泛的DHT。我们将在后面看到，大多数P2P数据网络都以这种或那种方式建立在Kademlia之上。Kademlia也影响了P2P文件交换的协议，比如BitTorrent，它通过使用基于Kademlia的DHT实现了无跟踪的torrent [47]。 一般来说，Kademlia可以被归类为结构化覆盖网络，它规定了如何结构化和维护P2P网络。为此，对等体被分配了一个身份，这决定了它的位置，从而决定了它的邻居。对于邻居的选择，采用的是XOR度量。XOR度量的优点是它是对称的和单向的。根据它们的XOR距离，节点被分类到𝑘桶中。桶被安排为二进制树，其中最短的前缀决定了桶的位置。如果一个新的节点属于一个包含𝑘节点（包括它自己）的桶，该桶就会被分割成更小的桶，否则新的节点就会被放弃。图3显示了一个具有8位标识符的示例性Kademlia树。 ","date":"2022-10-20","objectID":"/ipfs_friends/:2:2","tags":["IPFS","L1","Web3.0"],"title":"IPFS和朋友们","uri":"/ipfs_friends/"},{"categories":["Blockchain"],"content":"C. ICN (信息中心网络) 另一个值得一提的先驱是信息中心网络（ICN）。尽管ICN不是一个P2P数据网络，但它的一些想法和概念至少与一些数据网络相似。与P2P数据网络相反，ICN建议改变网络层。数据包的路由和流动应该从点对点的位置搜索改变为直接从网络上请求内容。作为一个例子，让我们假设我们想检索一些数据，例如一个网站，并且我们知道这个网站在example.com上。首先，我们通过DNS请求该网站的主机位置，即IP地址。之后，我们建立一个连接来检索该网站。在ICN中，我们会直接请求数据，而不会对数据所在的主机进行寻址。任何存储网站的节点都可以立即提供数据。 Jacobson等人[48]提出以内容为中心的网络，这些内容请求是兴趣包。然后，内容的所有者可以用包含内容的数据包直接回答兴趣包。这需要在基础设施层面上的流量控制、路由和安全等其他机制。兴趣包被广播，分享数据兴趣的对等体可以共享资源。有多个项目在处理ICN，例如，命名数据网络[49]（NDN）。通过Ntorrent[50]，Mastorakis等人提出了一个NDN的扩展，在NDN中实现类似BitTorrent的机制。关于ICN的进一步一般信息可以在[13]中找到。由于数据网络以内容为中心的性质，它们可以被广泛地解释为ICN的叠加实现。 ","date":"2022-10-20","objectID":"/ipfs_friends/:2:3","tags":["IPFS","L1","Web3.0"],"title":"IPFS和朋友们","uri":"/ipfs_friends/"},{"categories":["Blockchain"],"content":"D. Self-Certifying Names 从以主机为中心的通信到以内容为中心的通信的变化引入了新的安全问题。此外，随着缓存成为网络的一个主要特征，需要考虑特定的威胁，例如缓存中毒或针对缓存的拒绝服务攻击。更广泛地说，ICN的安全问题一般包括内容认证、授权和访问控制，以及隐私[51]。 目前，安全研究的主要焦点在于认证。由于缓存的广泛使用，数据提供者不一定是一个对象的原始来源（数据所有者）了。这就需要建立机制，使接收者能够评估对象的有效性（完整性）、来源（内容来源）和相关性。 确保有效性和相关性的一种方法是Self-Certifying Names。通过使用散列指针（或更一般的内容散列）来引用内容，可以启用Self-Certifying Names。一个文件的内容被用作加密哈希函数的输入，例如SHA-3[52]。由此产生的摘要可以用来识别内容，客户端可以在本地验证文件的完整性。哈希函数的加密特性，最重要的是预像和抗碰撞，确保没有人可以在不改变其摘要的情况下替换或修改输入数据。在这种情况下，名称提供了完整性和相关性，然而，谁负责验证对象，如客户端和/或中间人，仍然是有疑问的。此外，一个Self-Certifying Names本身不能提供出处或证明对象的来源。加密签名可以保证对象来源的真实性，但需要一个公钥基础设施或信任网络来验证签名。虽然这允许验证对象来源的真实性，但仍有可能发送畸形的对象，因此需要机制来确保完整性。通过缓存来延长内容的寿命，需要仔细的密钥管理，以防止密码证书被破坏。 访问控制也有类似的问题：一旦数据被发布，就很难限制访问或撤销发布。加密可以限制访问，但可能需要带外的密钥分配。关于安全、隐私、访问控制和ICN的其他挑战的进一步见解，可以在[53, 54]中找到 ","date":"2022-10-20","objectID":"/ipfs_friends/:2:4","tags":["IPFS","L1","Web3.0"],"title":"IPFS和朋友们","uri":"/ipfs_friends/"},{"categories":["Blockchain"],"content":"E. 区块链 2008年，比特币[11]的引入为分布式应用带来了新的可能性。比特币是一个巧妙的、错综复杂的组合，它融合了链接时间戳、数字现金、P2P网络、拜占庭容错和密码学等领域的思想[55, 56]。比特币带来的关键创新之一是一个开放的共识算法，积极激励对等人遵守。因此，它使用了硬币的概念，在这个过程中产生，即挖矿。 虽然区块链一词通常指的是整个系统及其协议，但它也指的是一个特定的数据结构，类似于哈希链或哈希树。也就是说，区块链订购的区块用加密哈希值与它们的前辈相连。这种链接的数据结构确保了区块链数据的完整性，例如，交易。区块链的一致性由一个共识算法来保证，例如，在比特币中的中本聪共识。关于比特币和区块链的更多细节，我们参考了[56]。 由于区块链存在可扩展性等问题，人们开发了不同的设计来缓解这些问题。这些不同的设计开辟了一个新的类别，被称为分布式账本技术（DLT）。DLT提供了分布式的、拜占庭容错的、不可变的和有序的日志。不幸的是，由于一系列的可扩展性问题和有限的链上存储容量，纯粹的基于DLT的数据网络的可行性是有限的[57, 58]。此外，在被设计为交换媒介和价值存储的区块链，即比特币等加密货币中存储大量数据，会导致高额的交易费用。然而，DLT的研究和开发显示了基于区块链的数据网络的可行性，例如Arweave（参见第四节E）。 然而，一般来说，允许去中心化支付的加密货币可以在P2P数据网络中作为一种激励结构使用。正如我们将在下文中阐述的那样，这种激励结构可以提高数据网络的稳健性和可用性，从而解决前几代的弱点 ","date":"2022-10-20","objectID":"/ipfs_friends/:2:5","tags":["IPFS","L1","Web3.0"],"title":"IPFS和朋友们","uri":"/ipfs_friends/"},{"categories":["Blockchain"],"content":"INTERPLANETARY FILE SYSTEM (IPFS) 星际文件系统（IPFS）[14]是一个子协议束，也是一个由协议实验室推动的项目。IPFS的目的是提高网络的效率，使网络更加分散和有弹性。IPFS使用基于内容的寻址，内容不是通过位置而是通过其内容寻址。IPFS存储和寻址数据的方式及其重复数据删除的特性，允许有效地存储数据。 通过IPFS，有可能以分散的方式存储和共享文件，增加其内容的抗审查性。IPFS可以用来部署网站，建立一个分布式网络。它被用作补充区块链的存储服务，在IPFS之上实现不同的应用。 由于IPFS使用基于内容的寻址，它主要关注不可变的数据。然而，IPFS通过整合InterPlanetary Name System（IPNS）支持内容的可更新地址。IPNS允许将一个名称（公钥的哈希值）与文件的内容标识符联系起来。IPNS条目由私钥签署，可以任意地（重新）发布到网络上（默认为4小时）。每个对等体维护其自己的LRU缓存的解决条目（默认为128个条目）。一个IPNS条目有一个特定的寿命，之后它将从缓存中删除（默认为24小时）。通过改变固定名称到内容标识符的映射，可以实现文件更新。请注意，内容标识符是唯一的，并且是特定的文件。 此外，IPFS采用了自己的激励层，即Filecoin[59]，以确保网络中文件的可用性。然而，IPFS独立于Filecoin工作，反之亦然。这是一个典型的例子，说明如何整合加密货币来激励同行。 ","date":"2022-10-20","objectID":"/ipfs_friends/:3:0","tags":["IPFS","L1","Web3.0"],"title":"IPFS和朋友们","uri":"/ipfs_friends/"},{"categories":["Blockchain"],"content":"A. 一般功能 IPFS使用模块化的P2P网络栈libp2p[60]。事实上，libp2p是在开发IPFS时出现的。在IPFS中，节点是由一个节点ID识别的。节点ID是其公钥的哈希值。为了加入网络，IPFS开发团队部署了一些引导节点。通过联系这些节点，一个对等体可以学习新的对等体。与一个节点相连的对等体，表示为它的蜂群(swarm)。对等体可以通过基于Kademlia的DHT和本地节点发现来找到。连接之间的通信可以是加密的。虽然IPFS使用Kademlia，但其连接并不完全由Kademlia决定。在IPFS中，一个节点与新发现的节点建立连接，试图将它们放入桶中[34]。一旦达到HighWater阈值（默认为900），空闲的连接就会被修剪，直到达到LowWater阈值（默认为600）。如果一个连接没有被明确保护，并且存在的时间超过了宽限期（默认为20𝑠），那么它就被认为是空闲的。受保护的连接是，例如，当前正在使用的连接，明确添加的对等体，或DHT功能所需的对等体。 IPFS中的一个对象（文件、列表、树、提交）被分割成若干块或区块。每个块都可以通过内容标识符（CID）来识别，它可以根据内容的配方来创建。从这些块中，一个Merkle有向无环图（DAG）被创建。Merkle DAG类似于Merkle树。Merkle DAG的每个节点都有一个由该节点的内容确定的标识符。然而，相比之下，Merkle DAG不需要平衡，一个节点可以携带一个有效载荷，而且一个节点可以有多个父节点。Merkle DAG的根可以用来检索文件。IPFS采用了重复数据块：每个存储的块都有不同的CID。这有利于文件的版本划分，即较新的文件版本与较旧的版本共享大量的块。在这种情况下，只需要存储各版本之间的差异，而不是两个完整的Merkle DAGs。这些块有一个附加的包装，指定了块的UNIXFS类型。 为了说明Merkle DAGs和重复数据删除的机制，让我们假设我们的调查论文和该论文的早期草稿都存储在IPFS上。图4显示了这两个文件的Merkle DAGs的简化表示。每个节点代表一个块，标签代表节点的CID，即内容散列。DAG是自下而上创建的，因为中间节点的CID取决于它的下级。实际数据位于叶子中。在最终版本中，我们假设额外的信息被附加到了内容中，这导致了不同的根节点和额外的节点。因此，在我们的例子中，𝐹是草案的根CID，𝐹′是完成的调查的根。 区块本身存储在设备或供应商上。DHT作为数据提供者的查询工具。如同在Kademlia中，节点id最接近CID的节点存储了内容提供商的信息。一个提供者可以宣布它正在存储特定的块。区块的占有在一个可配置的时间范围内被重新宣布（默认为12小时）。 Bitswap: 区块的实际交换是由Bitswap协议处理的。每个节点都有一个 “想要”、“拥有 “和 “不想要 “的列表。不同的列表包含该节点想要/拥有或不想要的CID。不想要的列表中的CID甚至不被缓存，只是在接收时被丢弃。一个节点将其想要的列表上的CIDs发送给它的群组。拥有该区块的邻居会发送该区块和创建CID的recipe。然后，该节点可以通过从recipe中建立CID来验证该内容。如果没有邻居拥有想要的CID，IPFS会进行DHT查询。在DHT查找成功后，拥有该CID的节点被添加到蜂群(swarm)中，并发送想要的列表。 对于一个对等体来说，要下载一个文件，它需要知道根CID。在获得一个对象的Merkle DAG根的CID后，它可以把这个根CID放在想要的列表上，而之前描述的Bitswap/DHT就会接手。根块给出其节点的信息，导致必须请求新的CID。随后的CID请求不会发送给所有邻居。回答根CID的邻居被优先考虑，并被分组到一个会话中。从0.5版本开始，Bitswap对会话中的多个对等体的后续请求发送WANT-HAVE消息，对一个对等体发送乐观的WANT-BLOCK消息。WANT-HAVE消息询问对等体是否拥有该区块，WANT-BLOCK消息直接请求该区块。如果收到了一个区块，其他悬而未决的请求可以用CANCEL消息取消[36]。以前，邻居同时请求区块，导致可能多次收到一个区块。一旦获得树的所有叶子，文件就可以在本地使用。文件不会被上传到网络上，只有占有被宣布。 图5说明了一个使用IPFS的典型文件交换。这里，一篇调查报告的作者使用IPFS与审稿人交换。节点身份为𝑁3的作者通过IPFS提供调查报告，IPFS将其分割成Merkle DAG（也见图4）。作者通过带外信道与审稿人分享DAG的结果根CID𝐹。审查者，其节点的身份是𝑁11，从网络上请求𝐹。Bitswap处理交换询问邻居的块，随后请求DAG。由于除了调查的作者之外，没有人能够回答审查者的请求，作者最终使用Bitswap向审查者提供文件。当审查者获得所有区块时，她就会将文件组装起来，并可以阅读调查报告。 可用性: IPFS没有任何隐含的机制来修复和维护文件或确保网络的冗余和可用性。在我们前面的例子中，只有作者𝑁3和审稿人𝑁11持有调查的所有块。由于协议的原因，没有主动复制。然而，文件可以被 “钉住” (Pin)，以防止一个节点在本地删除块。否则，内容只被缓存，可以在任何时间点通过垃圾收集删除。此外，文件不能在其他节点上被故意删除，删除总是只发生在本地。对于一个文件的消失，它需要从每个缓存和每个钉子节点中删除。 存在Filecoin[59]来保证存储。Filecoin采用了一个存储和检索市场来存储和检索文件。存储市场负责存储数据，例如，将客户与存储矿工相匹配，并在账本上记录他们的交易，奖励/惩罚存储矿工，并验证持续存储。检索市场负责检索文件。检索矿工提供数据以换取Filecoin，并且只在提供请求时需要数据。为了确保客户和检索矿工这两方都能合作并得到补偿，数据检索是通过支付渠道来保证的，数据被分成小块发送，并在发送下一块数据之前用小额支付进行补偿。 虽然存储和检索市场处理其任务略有不同，但主要原则是相同的。有三种不同的订单：出价，要价，和交易。竞价订单是客户的服务请求，它想存储或检索文件。询问订单是存储或检索节点的服务报价，宣布存储或检索条件。交易订单是关闭买入和卖出订单之间交易的声明。订单被存储在订单簿中。对于存储市场，订单簿存储在链上，以确保客户的知情决策，并告知市场的趋势。订单被添加到清晰的揭示信息中。检索市场的订单簿是链外的，以提高检索速度。 交易的执行是使用具有Proof-of-Replication（PoRep）和Proof-of-Replication（PoST）的分布式账本进行维护。PoRep是一个存储节点复制数据的证明，确保数据存储在独立的物理存储上。PoST证明了随时间推移的连续存储。关于不同证明的更多信息，我们参考了技术报告[61]。 ","date":"2022-10-20","objectID":"/ipfs_friends/:3:1","tags":["IPFS","L1","Web3.0"],"title":"IPFS和朋友们","uri":"/ipfs_friends/"},{"categories":["Blockchain"],"content":"B. 特征和扩展 IPFS支持多种传输/网络协议，或加密哈希函数，以增加其适应性。这是通过使用多地址和多哈希数据结构实现的。多地址是一种用于编码寻址信息的路径结构。它们允许对等体宣布其联系信息（如IPv4和IPv6）、传输协议（如TCP和UDP）和端口。Multi-hash用于提供多个不同的哈希函数。摘要值的前缀是摘要长度和哈希函数类型。多重哈希被用于节点id和部分CID。 IPFS中的CID是用来识别块的。一个CID是其内容的加密哈希值，并添加了元数据。元数据包括使用的散列算法和它的长度（多散列）、编码格式（行星间关联数据）和版本。更具体的说，用编码信息预加的多重哈希是InterPlanetary Linked Data（IPLD），而用版本信息预加的IPLD是实际的IPFS CID。 **虽然IPFS本身没有确保冗余/可用性的机制，但IPFS Cluster允许创建和管理一个额外的节点叠加网络，与IPFS主网络分开。**IPFS Cluster有助于确保数据冗余和定义的群组中的数据分配。集群管理钉住的数据，维护配置的复制量，必要时重新钉住内容，并在选择钉住数据的节点时考虑自由存储空间。IPFS Cluster需要一个正在运行的IPFS节点。IPFS Cluster使用libp2p作为其网络层。 IPFS Cluster确保了文件的横向可扩展性，没有任何激励措施。它可以被内容提供商用来提高可用性，而不依赖网络中的缓存。FileCoin可以用来激励其他人存储文件。 ","date":"2022-10-20","objectID":"/ipfs_friends/:3:2","tags":["IPFS","L1","Web3.0"],"title":"IPFS和朋友们","uri":"/ipfs_friends/"},{"categories":["Blockchain"],"content":"C. 用例 在下文中，我们简要介绍了几个有代表性的领域，以展示IPFS的一些使用案例。然而，请注意，这并不是一个详尽的清单，也不是本文的重点。然而，它提供了对数据网络的当前用例和潜力的见解，特别是IPFS。 在许多有关数据交换的领域，IPFS经常与区块链相结合。在这种情况下，区块链可以实现各种目的。区块链可以提供完整性、真实性，或者作为数据的指针。应用范围包括医疗数据[26，62]，跟踪农产品[63]，或一般的物联网（IoT）数据[20]。区块链也可以作为一种机制，为IPFS数据提供访问控制[22, 23, 64]，或为数据提供审计跟踪[31]。一般来说，数据网络也可以用来改善区块链的存储问题，例如，通过脱链交易数据[21]。此外，一些研究人员提出了基于IPFS和区块链的新内容共享机制[24, 25, 65]。另一个提议的用例是使用IPFS公开科学论文，并使用区块链提供与审稿人、审稿和论文相匹配的审查机制[66]。 然而，IPFS也有不涉及区块链的用例。遵照其去中心化互联网的目标，IPFS可用于在InterPlanetary Wayback中对网站进行存档[67]。其他没有区块链的用例是与ICN结合作为内容交付网络[30]，将IPFS与用于Fog/Edge计算的扩展网络附加存储相结合[68]，或者与IPFS集群结合用于存储物联网数据以提高可用性[29]。 最后，也有可能将IPFS滥用于恶意活动，例如，将勒索软件作为一种服务[69]或用于协调僵尸网络[27]。 TODO …. ","date":"2022-10-20","objectID":"/ipfs_friends/:3:3","tags":["IPFS","L1","Web3.0"],"title":"IPFS和朋友们","uri":"/ipfs_friends/"},{"categories":["Blockchain"],"content":"WebAssembly 相关 ","date":"2022-10-11","objectID":"/webassembly/:0:0","tags":["wasm","L0","Web3.0"],"title":"WebAssembly","uri":"/webassembly/"},{"categories":["Blockchain"],"content":"WebAssembly 是什么 ","date":"2022-10-11","objectID":"/webassembly/:1:0","tags":["wasm","L0","Web3.0"],"title":"WebAssembly","uri":"/webassembly/"},{"categories":["Blockchain"],"content":"定义 来自MDN的解释: WebAssembly 是一种新型代码，可以在现代 Web 浏览器中运行，并提供新功能和主要性能提升。它的主要目的不是手写，而是设计为 C、C++、Rust 等源语言的有效编译目标。 这对 Web 平台有着巨大的影响——它提供了一种在 Web 上以接近本机的速度运行以多种语言编写的代码的方法，而客户端应用程序可以在 Web 上运行，而这是以前无法做到的。 更重要的是，您甚至不必知道如何创建 WebAssembly 代码来利用它。 WebAssembly 模块可以导入到 Web（或 Node.js）应用程序中，公开 WebAssembly 函数以通过 JavaScript 使用。 JavaScript 框架可以利用 WebAssembly 来提供巨大的性能优势和新功能，同时仍然使 Web 开发人员可以轻松使用这些功能。 来自webassembly.org的解释: WebAssembly（缩写为Wasm）是一种基于堆栈的虚拟机的二进制指令格式。Wasm被设计为编程语言的可移植编译目标，能够在网络上部署客户端和服务器应用程序。 通过上面的解释, 我们大概可以知道一下几点: WASM可以在浏览器中运行 WASM可以在本地服务器上运行 WASM是通过高级语言进行编译得到的一种二进制格式 WASM可用使用各式各样你拿手的高级语言进行代码编写, 然后再编译而成 WASM性能很棒 WASM可以和JS混用 WASM可移植性很强 有一个基于堆栈的虚拟机(Stack Based VM) ","date":"2022-10-11","objectID":"/webassembly/:1:1","tags":["wasm","L0","Web3.0"],"title":"WebAssembly","uri":"/webassembly/"},{"categories":["Blockchain"],"content":"目标 来自(https://developer.mozilla.org/en-US/docs/WebAssembly/Concepts#webassembly_goals):https://webassembly.github.io/spec/core/intro/introduction.html WebAssembly的设计目标如下 快速、安全、便携: Fast: 以接近原生代码的性能执行，利用所有当代硬件的共同能力。 Safe: 代码被验证并在内存安全2、沙盒环境中执行，防止数据损坏或安全漏洞。 Well-defined: 以一种易于非正式和正式推理的方式，充分而精确地定义了有效的程序及其行为。 Hardware-independent: 可以在所有现代架构、桌面或移动设备以及嵌入式系统上编译。 Language-independent: 不对任何特定的语言、编程模型或对象模型给予特权。 Platform-independent: 可以嵌入到浏览器中，作为一个独立的虚拟机运行，或集成到其他环境中。 Open: 程序能以简单和通用的方式与环境互操作。 高效和便携的代表: Compact: 有一种二进制格式，比典型的文本或本地代码格式更小，所以传输速度快。 Modular: 程序可以被分割成较小的部分，可以分别进行传输、缓存和消费。 Efficient: 可以在一个快速的单程中进行解码、验证和编译，同样也可以使用及时编译（JIT）或预先编译（AOT）。 Streamable: 允许在所有数据被看到之前，尽快开始解码、验证和编译。 Parallelizable: 允许将解码、验证和编译分割成许多独立的并行任务。 Portable: 不做任何在现代硬件中不被广泛支持的架构假设。 ","date":"2022-10-11","objectID":"/webassembly/:1:2","tags":["wasm","L0","Web3.0"],"title":"WebAssembly","uri":"/webassembly/"},{"categories":["Blockchain"],"content":"WebAssembly到底长啥样 上面的定义和目标听起来非常的抽象, 不如生成一个WebAssembly并使用一下,来具体感受一下. 我们选用Rust语言来写一个简单的demo 先根据官网安装Rust: https://www.rust-lang.org/learn/get-started fn main(){ println!(\"Hello, i'm Rust!\"); } 用rustc编译器编译和运行一下, 没有瑕疵: OSX MP16 ~/Dow/wasm_e/standalone ❯ rustc ./hello.rs -o hello.exe OSX MP16 ~/Dow/wasm_example/standalone ❯ ./hello.exe Hello, i'm Rust! ","date":"2022-10-11","objectID":"/webassembly/:2:0","tags":["wasm","L0","Web3.0"],"title":"WebAssembly","uri":"/webassembly/"},{"categories":["Blockchain"],"content":"“可以在本地服务器上运行\"的WebAssembly: 编译 rustup target add wasm32-wasi \u0026\u0026 rustc hello.rs --target wasm32-wasi -o hello_standalone.wasm 其中wasm32-wasi 表示 WebAssembly with WASI , WASI是WebAssembly的模块化系统接口 运行 运行编译出来的WebAssembly需要用到\"基于堆栈的虚拟机”, 这个虚拟机我们称之为\"运行时\" (WebAssembly Runtime). WebAssembly Runtime有很多, 这里有一个列表: https://github.com/appcypher/awesome-wasm-runtimes 我们选择wasmer https://github.com/wasmerio/wasmer , 先根据官方文档安装好. OSX MP16 ~/Dow/wasm_example/standalone ❯ wasmer ./hello_standalone.wasm Hello, i'm Rust! 跨平台运行 上面的hello_standalone.wasm我是在macos上编译出来的, 一个大胆的想法: 拿到windows上面去, 可以运行吗? 在windows上面安装好wasmer, 然后运行: PS C:\\Users\\Administrator\u003e wasmer \"Z:\\下载\\wasm_example\\standalone\\hello_standalone.wasm\" Hello, i'm Rust! 完全没有问题. 注: 用cargo新建和编译项目更为通用一些, 参考这里 https://docs.wasmtime.dev/wasm-rust.html 用到的主要命令 rustup target add wasm32-wasi cargo install cargo-wasi cargo new MyProject cargo wasi run ","date":"2022-10-11","objectID":"/webassembly/:2:1","tags":["wasm","L0","Web3.0"],"title":"WebAssembly","uri":"/webassembly/"},{"categories":["Blockchain"],"content":"“可以在浏览器中运行\"的WebAssembly 编写工程 我们将使用 wasm-pack 这个工具, 先到官网安装好该工具 https://rustwasm.github.io/wasm-pack/ 或使用 cargo install wasm-pack 安装 该工具会给我们生成很多JS和WebAssembly相结合的\"胶水代码”, 以便事情来得更简单. 新建项目: wasm-pack new wasm-web 到./src/lib.rs 中追加一个加法代码 #[wasm_bindgen] pub fn add(a: i32, b: i32) -\u003e i32 { a + b } 其中的wasm_bindgen是一个库, 在Cargo.toml中进行了声明 [dependencies] wasm-bindgen = \"0.2.63\" wasm-bindgen工具有点像为主机绑定建议等功能提供的polyfill，以及为JS和wasm编译的代码（目前主要来自Rust）之间的高级交互提供的功能。更具体地说，这个项目允许JS/wasm与字符串、JS对象、类等进行交流，而不是纯粹的整数和浮点数。例如，使用wasm-bindgen，你可以在Rust中定义一个JS类，或者从JS中获取一个字符串，或者返回一个字符串。其功能也在不断增加! 详细信息参考这里: https://rustwasm.github.io/wasm-bindgen/ 编译 wasm-pack build 其中生成的./pkg/wasm_web_bg.wasm就是\"可以在浏览器中运行\"的WebAssembly, 也就是大多数情况下所说的那种WebAssembly(非STANDALONE的, 需要JS来进行调用执行的, 类似于Library) 另外, 在pkg/wasm_web.js 和 pkg/wasm_web_bg.js生成了JS包装调用WebAssembly的胶水代码. /** * @param {number} a * @param {number} b * @returns {number} */ export function add(a, b) { const ret = wasm.add(a, b); return ret; } 可以看到JS中的add实际是对WebAssembly中的add函数的封装. 运行 在项目的根目录下添加index.html \u003c!DOCTYPE html\u003e \u003chtml lang=\"en-US\"\u003e \u003chead\u003e \u003cmeta charset=\"utf-8\" /\u003e \u003ctitle\u003eexample\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003clabel id=\"labelContent\"\u003e\u003c/label\u003e \u003cscript type=\"module\"\u003e import init, { greet, add } from \"./pkg/wasm_web.js\"; init().then(() =\u003e { document.getElementById(\"labelContent\").innerHTML = \"2+2=\" + add(2,2); }); \u003c/script\u003e \u003c/body\u003e \u003c/html\u003e 在项目根目录下运行一个httpserver: python -m SimpleHTTPServer 7777 ","date":"2022-10-11","objectID":"/webassembly/:2:2","tags":["wasm","L0","Web3.0"],"title":"WebAssembly","uri":"/webassembly/"},{"categories":["Blockchain"],"content":"WebAssembly底层原理 ","date":"2022-10-11","objectID":"/webassembly/:3:0","tags":["wasm","L0","Web3.0"],"title":"WebAssembly","uri":"/webassembly/"},{"categories":["Blockchain"],"content":"现代编程语言的编译/运行方式 AOT 预先编译 Ahead-of-Time compilation, 预先编译 将源代码编译成机器代码. C/C++, Rust, Go是使用这类编译方式的代表 编译器获取程序代码（源代码）并将源代码转换为机器语言模块（称为对象文件）。另一个专门的程序，称为链接器，将这个对象文件与其他先前编译的对象文件（特别是运行时模块）结合起来，创建一个可执行文件。 解释型(Interpreted) 解释语言的过程是不同的。解释器不是在创建可执行文件之前将源代码翻译成机器语言，而是在程序运行的同时将源代码转换为机器语言。Python, Ruby, Perl 等是采用这种方式 当每次运行一个解释型程序时，解释器必须将源代码转换为机器代码，并且还要拉入运行时库。这个转换过程使程序的运行速度比用编译语言编写的类似程序要慢。 由于解释器在程序运行过程中进行了从源代码到机器语言的转换，因此解释语言通常导致程序的执行速度比编译程序慢。但通常得到的回报是，解释型语言通常是独立于平台的，因为每个不同的操作系统都可以使用不同的解释器。 字节码解释器 (Bytecode interpreters) 在解释和编译之间有一系列的可能性，这取决于在程序执行前进行的分析量。例如，Emacs Lisp被编译成字节码，字节码是Lisp源代码的高度压缩和优化表示，但不是机器码（因此不与任何特定的硬件相联系）。这种 “编译 “的代码然后由字节码解释器（本身是用C语言编写的）来解释。在这种情况下，编译后的代码是虚拟机的机器代码，它不是在硬件中实现的，而是在字节码解释器中实现的。这种编译解释器有时也被称为编译器。 在字节码解释器中，每条指令以一个字节开始，因此字节码解释器最多有256条指令，尽管不一定都会使用。一些字节码可能需要多个字节，而且可能是任意的复杂。 JIT 及时编译 JIT: Just in Time 来自 https://en.wikipedia.org/wiki/Just-in-time_compilation 在计算机领域，及时编译（JIT）是一种执行计算机代码的方式，它涉及在程序执行期间（运行时）而不是在执行之前进行编译。这可能包括源代码翻译，但更常见的是字节码翻译成机器码，然后直接执行。实现JIT编译器的系统通常会持续分析正在执行的代码，并确定代码的哪些部分从编译或重新编译中获得的速度会超过编译该代码的开销。 JIT编译是两种传统的机器码翻译方法的结合–预先编译（AOT）和解释器，并且结合了两者的一些优点和缺点。粗略地说，JIT编译结合了编译代码的速度和解释的灵活性，以及解释器的开销和编译和链接（不仅仅是解释）的额外开销。JIT编译是动态编译的一种形式，并允许自适应优化，如动态重新编译和针对微架构的加速。解释和JIT编译特别适合动态编程语言，因为运行时系统可以处理迟来的数据类型并执行安全保证。 由于加载和编译字节码所需的时间，JIT在应用程序的初始执行中会造成轻微到明显的延迟。有时这种延迟被称为 “启动时间延迟 “或 “预热时间”。一般来说，JIT执行的优化越多，它生成的代码就越好，但初始延迟也会增加。因此，JIT编译器必须在编译时间和它希望生成的代码的质量之间做出权衡。启动时间除了JIT编译外，还可能包括增加的IO绑定操作：例如，Java虚拟机（JVM）的rt.jar类数据文件是40MB，JVM必须在这个上下文巨大的文件中寻找大量的数据 。 Sun公司的HotSpot Java虚拟机所使用的一种可能的优化是把解释和JIT编译结合起来。应用程序代码最初是被解释的，但JVM监控哪些字节码序列经常被执行，并将它们翻译成机器代码，以便在硬件上直接执行。对于只执行几次的字节码，这可以节省编译时间并减少初始延迟；对于经常执行的字节码，JIT编译被用来在缓慢解释的初始阶段后高速运行。此外，由于一个程序大部分时间都在执行其少数的代码，因此减少的编译时间是很重要的。最后，在最初的代码解释过程中，可以在编译前收集执行统计数据，这有助于进行更好的优化。 正确的权衡会因情况不同而不同。例如，Sun公司的Java虚拟机有两种主要模式–客户端和服务器。在客户端模式下，执行最小的编译和优化，以减少启动时间。在服务器模式下，会进行大量的编译和优化，通过牺牲启动时间，使应用程序运行后的性能最大化。其他的Java即时编译器使用方法执行次数的运行时间测量，结合方法的字节码大小，作为决定何时编译的启发式方法。还有一个使用执行次数结合循环的检测。[22] 一般来说，在短时运行的应用程序中准确预测哪些方法需要优化比在长时运行的应用程序中更难。 微软的Native Image Generator（Ngen）是另一种减少初始延迟的方法。 Ngen将通用中间语言图像(Image)中的字节码预编译（或 “预JIT”）为机器本地代码。因此，不需要在运行时进行编译。与Visual Studio 2005一起运送的.NET框架2.0在安装后立即对所有的微软库DLLs运行Ngen。预jitting提供了一种改善启动时间的方法。然而，它所产生的代码质量可能不如JIT化的代码，原因与静态编译的代码在没有剖析指导下的优化，在极端情况下不能像JIT编译的代码那样好的原因一样：缺乏剖析数据来驱动，例如，内联缓存。 也有一些Java实现将AOT（超前）编译器与JIT编译器（Excelsior JET）或解释器（GNU Compiler for Java）相结合。 JIT编译从根本上使用可执行数据，因此带来了安全挑战和可能的漏洞。 JIT编译的实施包括将源代码或字节码编译成机器码并执行。这通常是在内存中直接完成的：JIT编译器将机器代码直接输出到内存中并立即执行，而不是像通常的超前编译那样将其输出到磁盘，然后作为一个单独的程序调用。在现代架构中，由于可执行空间的保护，这遇到了一个问题：任意的内存不能被执行，否则就会出现潜在的安全漏洞。因此，内存必须被标记为可执行；出于安全考虑，这应该在代码被写入内存后进行，并标记为只读，因为可写/可执行的内存是一个安全漏洞）。 例如，Firefox的JIT编译器在Firefox 46的发布版本中引入了这种保护。JIT喷洒是一类计算机安全漏洞，它使用JIT编译进行堆喷洒：然后产生的内存是可执行的，如果执行可以移动到堆中，就可以进行漏洞攻击。 近年来，及时编译在语言实现者中获得了主流关注，Java、.NET框架、大多数现代JavaScript实现和Matlab现在都包括JIT编译器。 更多类型的参考 : https://en.wikipedia.org/wiki/Interpreter_(computing) ","date":"2022-10-11","objectID":"/webassembly/:3:1","tags":["wasm","L0","Web3.0"],"title":"WebAssembly","uri":"/webassembly/"},{"categories":["Blockchain"],"content":"WebAssembly的编译/运行方式 WebAssembly的编译/运行方式多种多样. 这取决于 浏览器引擎或runtime(运行时)的实现方式. 到 https://github.com/appcypher/awesome-wasm-runtimes , 参考每个运行时的Compilation / Execution modes 一节, 他们对JIT, AOT, Interpreted 都有部分或全部支持. 注:为啥还要AOT, 除了速度快以外, 更重要的是一些平台出于安全考虑是不支持JIT的, 比如IOS 另外还有一种叫\"动态分层编译”: https://groups.google.com/a/chromium.org/g/blink-dev/c/Xzr6PQflTFA 但总体而言 ┌────────────────────────┐ │ runtime │ └────────────────────────┘ ┌────────┐ ┌────┐ │.c/.cpp │─emcc───┐ ─ ─▶│AOT │ └────────┘ │ │ └────┘ ┌────────┐ │ ┌────┐ │ .rs │─rustc──┤ ┌──────────┐ ├───▶│JIT │ └────────┘ ├────────▶│ .wasm │───┘ └────┘ ┌────────┐ │ └──────────┘ │ ┌────┐ │ .go │─tinygo─┘ ─ ─▶│Inte│ └────────┘ └────┘ ┌────────┐ ┌────┐ │ ... │ │... │ └────────┘ └────┘ 将源代码编译成wasm过程中, 从编译器的角度而言, 我们可以将编译器分为三段: 编译器前端: 前端主要负责预处理、词 法分析、语法分析、语义分析，生成便于后续处理的中间表示 编译器中端: 中端对中间表示进行分析和各种优化 编译器后端: 生成平台目标代码 . 我们使用的rustup target add wasm32-wasi 就是增加了一个编译器后端. https://doc.rust-lang.org/nightly/rustc/platform-support.html ","date":"2022-10-11","objectID":"/webassembly/:3:2","tags":["wasm","L0","Web3.0"],"title":"WebAssembly","uri":"/webassembly/"},{"categories":["Blockchain"],"content":".wasm结构 WebAssembly对应的文件.wasm是一种紧凑的二进制格式, 以上面例子中的wasm_web_bg.wasm为例, 看看这个二进制是如何组成的. WebAssembly程序被组织成模块，它是部署、加载和编译的单位。一个模块收集了类型、函数、表、内存和全局变量的定义。此外，它可以声明import和export，并以数据和元素段的形式提供初始化，或提供一个启动函数。 模块由 magic-number + version + N个节(Section)组成, 其中Section由以下三部分组成: section id section 大小 section实际内容 Section Name Code Description Type 1 类型部分声明了所有将在模块中使用的函数签名。 Import 2 导入部分声明了所有将在模块中使用的导入。 Function 3 函数部分声明了模块中所有函数的签名（其定义出现在代码部分） Table 4 表部分包含零个或多个不同的表的定义 Memory 5 线性内存部分提供了一个线性内存的内部定义。在MVP中，每个内存都是默认内存，最多可能有一个线性内存导入或线性内存定义。 Global 6 全局部分提供了一个零个或多个全局变量的内部定义。 Export 7 导出声明 Start 8 如果模块定义了一个开始部分，它所指的函数应该在实例被初始化后被加载器调用，包括它的内存和表虽然数据和元素部分，并且在导出的函数可被调用之前。 Element 9 元素部分包含一个可能是空的元素段数组，指定一个给定表的固定（偏移量，长度）范围的初始内容，由其表索引指定。 Code 10 代码部分包含模块中每个函数的主体。在函数部分声明的函数和在这部分定义的函数体的数量必须相同，第i个声明对应第i个函数体。 Data 11 数据部分声明了加载到线性存储器中的初始化数据。 Name 0 自定义部分 更多的, 参考这里 https://webassembly.github.io/spec/core/binary/modules.html#binary-section 使用任意一个16进制查看器查看我们上面demo中的wasm_web_bg.wasm OSX MP16 ~/Dow/wasm_e/wasm-web/pkg master ?12 ❯ hexdump -C ./wasm_web_bg.wasm 00000000 00 61 73 6d 01 00 00 00 01 0f 03 60 02 7f 7f 00 |.asm.......`....| 00000010 60 00 00 60 02 7f 7f 01 7f 02 24 01 03 77 62 67 |`..`......$..wbg| 00000020 1c 5f 5f 77 62 67 5f 61 6c 65 72 74 5f 62 35 30 |.__wbg_alert_b50| 00000030 61 33 64 37 33 35 34 65 31 34 39 62 37 00 00 03 |a3d7354e149b7...| 00000040 03 02 01 02 05 03 01 00 11 07 18 03 06 6d 65 6d |.............mem| 00000050 6f 72 79 02 00 05 67 72 65 65 74 00 01 03 61 64 |ory...greet...ad| 00000060 64 00 02 0a 15 02 0b 00 41 80 80 c0 00 41 10 10 |d.......A..�.A..| 00000070 00 0b 07 00 20 00 20 01 6a 0b 0b 19 01 00 41 80 |.... . .j.....A.| 00000080 80 c0 00 0b 10 48 65 6c 6c 6f 2c 20 77 61 73 6d |.�...Hello, wasm| 00000090 2d 77 65 62 21 00 7b 09 70 72 6f 64 75 63 65 72 |-web!.{.producer| 000000a0 73 02 08 6c 61 6e 67 75 61 67 65 01 04 52 75 73 |s..language..Rus| 000000b0 74 00 0c 70 72 6f 63 65 73 73 65 64 2d 62 79 03 |t..processed-by.| 000000c0 05 72 75 73 74 63 1d 31 2e 36 34 2e 30 20 28 61 |.rustc.1.64.0 (a| 000000d0 35 35 64 64 37 31 64 35 20 32 30 32 32 2d 30 39 |55dd71d5 2022-09| 000000e0 2d 31 39 29 06 77 61 6c 72 75 73 06 30 2e 31 39 |-19).walrus.0.19| 000000f0 2e 30 0c 77 61 73 6d 2d 62 69 6e 64 67 65 6e 12 |.0.wasm-bindgen.| 00000100 30 2e 32 2e 38 33 20 28 65 62 61 36 39 31 66 33 |0.2.83 (eba691f3| 00000110 38 29 |8)| 00000112 整理一下: 前8个字节是magic number (.asm) 和 版本 后面的是N个Section, section的第一个字节是ID号, 第二个字节是该section的长度(16进制, 实际内容长度) 比如 01 0F 03 60 02 7F 7F 00 60 00 00 60 02 7F 7F 01 7F 表示section id 是 01, 也就是 Type section, 长度为0F (15), 实际内容就是后面紧跟着的15个字节03 60 02 7F 7F 00 60 00 00 60 02 7F 7F 01 7F 内容是函数声明: 03表示 3个函数声明, 60 02 7F 7F 00 表示一个函数声明, 60 是函数声明标记, 后面是参数数量02,表示有两个参数,分别是7F 7F ( 7F表示i32) 最后一个字节是函数返回值类型, 00表示没有返回值 60 00 00 表示参数数量为0, 也没有返回值 60 02 7F 7F 01 7F 表示有2个7F(i32)类型的参数, 返回值有1个, 类型也是7F ","date":"2022-10-11","objectID":"/webassembly/:3:3","tags":["wasm","L0","Web3.0"],"title":"WebAssembly","uri":"/webassembly/"},{"categories":["Blockchain"],"content":"WebAssembly 文本格式(wat) 上面的二进制格式人类阅读起来是非常痛苦的, 所以WebAssembly还提供了文本格式, 对应的后缀名是.wat (WebAssembly Text) 将.wasm转换为.wat需要用到 wabt 工具包中的 wasm2wat OSX MP16 ~/Dow/wasm_e/wasm-web/pkg master ?12 ❯ wasm2wat ./wasm_web_bg.wasm (module (type (;0;) (func (param i32 i32))) (type (;1;) (func)) (type (;2;) (func (param i32 i32) (result i32))) (import \"wbg\" \"__wbg_alert_b50a3d7354e149b7\" (func (;0;) (type 0))) (func (;1;) (type 1) i32.const 1048576 i32.const 16 call 0) (func (;2;) (type 2) (param i32 i32) (result i32) local.get 0 local.get 1 i32.add) (memory (;0;) 17) (export \"memory\" (memory 0)) (export \"greet\" (func 1)) (export \"add\" (func 2)) (data (;0;) (i32.const 1048576) \"Hello, wasm-web!\")) 在MDN上有该格式的详细解释: https://developer.mozilla.org/zh-CN/docs/WebAssembly/Understanding_the_text_format ","date":"2022-10-11","objectID":"/webassembly/:3:4","tags":["wasm","L0","Web3.0"],"title":"WebAssembly","uri":"/webassembly/"},{"categories":["Blockchain"],"content":"Stack Machine Wasm规范实际上也定义了一 台概念上的栈式虚拟机, 绝大多数的Wasm指令都是基 于一个虚拟栈工作:从栈顶弹出若干个数，进行计 算，然后把结果压栈。由于采用了栈式虚拟机，大部分Wasm指令(特别 是数值指令)都很短，只有一个操作码，这是因为操 作数已经隐含在栈上了。举例来说，i32.add指令只有 一个操作码0x6A。在执行时，这条指令从栈顶弹出两 个i32类型的整数，这两个整数相加，然后把结果(也是i32类型)压栈. 比如计算 $$ \\begin{align*} f(x) = 2x^2 + 1 \\end{align*} $$ 对应的wat (func $f (param $x i32) (result i32) ;; stack: [] (get_local $x) ;; stack: [x] (get_local $x) ;; stack: [x, x] (i32.mul) ;; stack: [x*x] (i32.const 2) ;; stack: [2, x*x] (i32.mul) ;; stack: [2*x*x] (i32.const 1) ;; stack: [1, 2*x*x] (i32.add)) ;; stack: [2*x*x+1] ) WebAssembly中的大多数指令都以某种方式修改值栈。在上面的函数中，get_local把参数x推到栈上。i32.mul从栈上弹出两个值，把它们相乘，然后把结果推回栈上。i32.const N把值N推到栈上。该函数隐含地返回堆栈顶部的值。理论上，当从左到右写堆栈时，最左边的值是堆栈的顶部。对于需要多个参数的操作，它们的顺序与从堆栈中取出的顺序相反。例如: (i32.const 1) (i32.const 2) (i32.sub) 这个程序计算出1-2 注意，虽然我们一直在使用i32，但WebAssembly理解不同大小的数字类型，包括整数（i8, i16, i32, i64, i128）和浮点数（f32, f64）。 那么, 我们在上一节中源代码 #[wasm_bindgen] pub fn add(a: i32, b: i32) -\u003e i32 { a + b } 对应的wat就很好理解了: 获取2个局部值将其压栈, 然后调用指令 i32.add 从栈中弹出2个值进行加法操作, 并将结果压栈 (func (;2;) (type 2) (param i32 i32) (result i32) local.get 0 local.get 1 i32.add) 更多指令参考这里 : 包括循环, 条件判断等现代语言的基本元素. https://github.com/sunfishcode/wasm-reference-manual/blob/master/WebAssembly.md#instruction-descriptions https://webassembly.github.io/spec/core/appendix/index-instructions.htm ","date":"2022-10-11","objectID":"/webassembly/:3:5","tags":["wasm","L0","Web3.0"],"title":"WebAssembly","uri":"/webassembly/"},{"categories":["Blockchain"],"content":"WASI 编程就绕不开和系统打交道, 比如文件系统, 磁盘读写, 网络通讯等. WebAssembly也一样, 但和其它编程语言不一样的是, WebAssembly面向的是一个概念性的机器,他需要跨各式各样的平台(可移植)并保证安全性. 所以便了以WASI (WebAssembly System Interface), 但值得注意的是其不是一个单一的标准系统接口，而是一个标准化的API的模块化集合。 这篇文章详细解释了为什么需要WASI以及如何实现和实现中遇到的问题: https://hacks.mozilla.org/2019/03/standardizing-wasi-a-webassembly-system-interface/ 更多的参考这里 https://github.com/WebAssembly/WASI 一个简单的教程: https://github.com/bytecodealliance/wasmtime/blob/main/docs/WASI-tutorial.md 有不少运行时(runtime)都支持WASI, 可以到 https://github.com/appcypher/awesome-wasm-runtimes 中查看 “Host APIs supported“字段 ","date":"2022-10-11","objectID":"/webassembly/:3:6","tags":["wasm","L0","Web3.0"],"title":"WebAssembly","uri":"/webassembly/"},{"categories":["Blockchain"],"content":"一些关于EVM的学习笔记 ","date":"2022-10-06","objectID":"/evm/:0:0","tags":["EVM","L0","Web3.0"],"title":"EVM","uri":"/evm/"},{"categories":["Blockchain"],"content":"什么是EVM 在web3的的L0中, 涉及到一个概念 Platform neutral language (有些地方也写做 Platform-neutral computation description language ) 平台中立的计算描述语言, 指一种在不同物理平台（架构、操作系统等）上执行相同程序的方法。 我们知道, 任何一个区块链都需要N个节点按照一定的规则来执行相同的运算, 可以想象成一个平台, 这个平台和硬件以及编程语言都不是强相关的, 在以太坊中, 其采用了虚拟机的形式. 它和我们平时用的VMware有些类似, 但又不同, 因为EVM是分布式的. 另外, 我们很多时候讨论EVM更多的是说的一套规则, 而不是某个具体的EVM实现, EVM的具体实现有很多, 比如golang实现的go-ethereum , c++实现的cpp-ethereum 等等, 更多的参考这里: https://github.com/pirapira/awesome-ethereum-virtual-machine 简言之, EVM提供了一个虚拟的沙盒环境, 为以太坊区块链提供了 一系列的功能 ","date":"2022-10-06","objectID":"/evm/:1:0","tags":["EVM","L0","Web3.0"],"title":"EVM","uri":"/evm/"},{"categories":["Blockchain"],"content":"EVM的主要功能 ","date":"2022-10-06","objectID":"/evm/:2:0","tags":["EVM","L0","Web3.0"],"title":"EVM","uri":"/evm/"},{"categories":["Blockchain"],"content":"分布式数据库 在其最基本的形式中，以太坊虚拟机是一个大型的分布式数据库， 用于保存以太坊的所有账户和余额 . 注: 以太坊使用的账户/余额模型, 而不是BTC的UTXO 基于账户的交易模式将资产表示为账户内的余额，类似于银行账户。以太坊使用这种交易模式。有两种不同类型的账户: 私钥控制的用户账户 合约代码控制的账户。 当你创建一个以太币钱包并收到你的第一笔交易时，一个私钥控制的账户被添加到全局状态并存储在网络上的所有节点。部署一个智能合约会导致创建一个代码控制的账户。智能合约可以自己持有资金，它们可以根据合约逻辑中定义的条件重新分配。以太坊的每个账户都有一个余额、存储空间，以及用于调用其他账户或地址的代码空间。 基于账户的模型中的交易会触发节点减少发送方账户的余额，增加接收方账户的余额。为了防止重放攻击，账户模型中的每笔交易都附有一个非授权码。重放攻击是指受款人广播一个欺诈性的交易，他们在其中获得第二次付款。如果欺诈性交易成功，该交易将被第二次执行–它被重放–并且发送者将被收取两倍于他们想要转移的金额。 为了打击这种行为，以太坊的每个账户都有一个公开的可查看的nonce，该nonce在每笔流出的交易中都会被递增1。这可以防止同一交易被多次提交给网络。 在账户模型中，交易费用的工作方式也有所不同。它们是根据完成状态转换所需的计算次数来计算的。以太坊的出发点是成为一个世界计算机。因此，他们决定，费用应该基于消耗的计算资源数量，而不是所占用的存储容量。 账户模型将所有余额作为一个全局状态进行跟踪。这个状态可以理解为所有账户、私钥和合约代码的数据库，以及他们在网络上不同资产的当前余额的控制。 用于保存智能合约 以太坊在链上有合约（称为智能合约），即代码被编译成字节码，产生的字节在交易中被发送，以坚持到以太坊区块链上。这在你部署智能合约时完成一次。在这之后，人们可以与智能合约与其他交易互动。 注: 关于数据存储, 以太坊区块链上并不适合大量数据存储, 参考这篇论文: Exploring Ethereum’s Data Stores: A Cost and Performance Comparison ","date":"2022-10-06","objectID":"/evm/:2:1","tags":["EVM","L0","Web3.0"],"title":"EVM","uri":"/evm/"},{"categories":["Blockchain"],"content":"分布式状态机 从基本层面上而言, ETH区块链是一个由交易和共识驱动的状态机, 状态需要永久地存储在区块链上. 随着交易的进行, 区块链会不断更新状态, 这里的状态有两种: 世界状态(World State): 以太坊地址和账户状态的映射 账户状态(Account State): 由4个字段组成 Nonce: 一个值, 每次从该地址发送交易时都会递增 余额: 这个值代表weis的数量，weis是以太坊中最小的货币单位（wei），由给定地址持有 Storage root : 这个字段代表一个MPT的根节点，编码账户的存储内容 Code hash: 这是一个不可变的字段，包含与账户相关的智能合约代码的哈希值。 在普通账户的情况下，这个字段包含空字符串的Keccak 256位哈希值 平时区分一个操作是否会改变区块链的状态, 可以简单地看改操作是否花费gas, 如果不花费gas则其不会改变. 对应到代码层面则参考: https://yinhui1984.github.io/对智能合约的读方法和写方法的调用/ ","date":"2022-10-06","objectID":"/evm/:2:2","tags":["EVM","L0","Web3.0"],"title":"EVM","uri":"/evm/"},{"categories":["Blockchain"],"content":"世界计算机 ETH最大的创新点是智能合约. 也就是我们可以编写程序代码来交给每个采矿节点上的EVM进行执行. 编写代码所使用的编程语言可以是 Solidity LLLL 等, 参考: https://github.com/pirapira/awesome-ethereum-virtual-machine#programming-languages-that-compile-into-evm 但一般指的都是 Solidity, EVM并不能直接执行Solidity，首先必须将代码编译成较低级别的机器指令，称为操作码(Opcodes) Solidity 与 Opcodes EVM被广泛地标记为图灵完备或更准确地说是准图灵完备。这意味着，EVM在理论上可以解决任何计算问题。这是通过执行称为EVM操作码的机器级指令来实现的。 EVM操作码协助EVM完成智能合约或交易的具体任务。目前，EVM大约有150个操作码可以执行。它们涵盖了一系列的操作，包括：算术、停止、记录、复制、推送、内存、比较和交换。以及用于检索块和环境信息。你可以找到一个操作代码的列表这里。 举一个HelloWorld的例子 // SPDX-License-Identifier: MIT pragma solidity ^0.8.0; contract Ex001HelloWorld { string public greet = \"Hello World!\"; } 使用solc进行编译: solc --bin --abi --optimize --overwrite -o ./output ./hello.sol 我们得到的*.abi和*.bin文件, 其中 bin只是编译后的字节码的紧凑二进制表示。操作码不是由PUSH、PULL或DELEGATECALL引用的，而是它们的二进制表示，用文本编辑器读取时看起来像随机数字。 cat Ex001HelloWorld.bin 60c0604052600c60809081526b48656c6c6f20576f726c642160a01b60a05260009061002b90826100dd565b5034801561003857600080fd5b5061019c565b634e487b7160e01b600052604160045260246000fd5b600181811c9082168061006857607f821691505b60208210810361008857634e487b7160e01b600052602260045260246000fd5b50919050565b601f8211156100d857600081815260208120601f850160051c810160208610156100b55750805b601f850160051c820191505b818110156100d4578281556001016100c1565b5050505b505050565b81516001600160401b038111156100f6576100f661003e565b61010a816101048454610054565b8461008e565b602080601f83116001811461013f57600084156101275750858301515b600019600386901b1c1916600185901b1785556100d4565b600085815260208120601f198616915b8281101561016e5788860151825594840194600190910190840161014f565b508582101561018c5787850151600019600388901b60f8161c191681555b5050505050600190811b01905550565b61019a806101ab6000396000f3fe608060405234801561001057600080fd5b506004361061002b5760003560e01c8063cfae321714610030575b600080fd5b61003861004e565b60405161004591906100dc565b60405180910390f35b6000805461005b9061012a565b80601f01602080910402602001604051908101604052809291908181526020018280546100879061012a565b80156100d45780601f106100a9576101008083540402835291602001916100d4565b820191906000526020600020905b8154815290600101906020018083116100b757829003601f168201915b505050505081565b600060208083528351808285015260005b81811015610109578581018301518582016040015282016100ed565b506000604082860101526040601f19601f8301168501019250505092915050565b600181811c9082168061013e57607f821691505b60208210810361015e57634e487b7160e01b600052602260045260246000fd5b5091905056fea26469706673582212208a0be23ced512b2079cbbc853392d671d17da38eaa87497f70ad2b7ef259ae1b64736f6c63430008110033 如果我们使用evm来反汇编, 就可以看到 evm disasm Ex001HelloWorld.bin evm disasm Ex001HelloWorld.bin ... 00000: PUSH1 0xc0 00002: PUSH1 0x40 00004: MSTORE 00005: PUSH1 0x0c 00007: PUSH1 0x80 00009: SWAP1 0000a: DUP2 0000b: MSTORE 0000c: PUSH12 0x48656c6c6f20576f726c6421 00019: PUSH1 0xa0 0001b: SHL 0001c: PUSH1 0xa0 0001e: MSTORE 0001f: PUSH1 0x00 00021: SWAP1 00022: PUSH2 0x002b 00025: SWAP1 ... 其中的0x48656c6c6f20576f726c6421 就是 Hello World!字符串 部署合约: #!/usr/bin/env python3 from web3 import Web3 # pip3 install web3 import solcx # pip3 install py-solc-x w3 = Web3(Web3.IPCProvider('../mychain/data/geth.ipc')) print('Connected to Ethereum client: %s' % w3.clientVersion) src = '../contracts/Ex001HelloWorld.sol' contract_src = open(src).read() print(contract_src) compiled_sol = solcx.compile_source(contract_src, output_values=['bin', 'abi']) contract_interface = compiled_sol['\u003cstdin\u003e:Ex001HelloWorld'] Ex001HelloWorld = w3.eth.contract(abi=contract_interface['abi'], bytecode=contract_interface['bin']) w3.eth.default_account = w3.eth.accounts[0] tx_hash = Ex001HelloWorld.constructor().transact() tx_receipt = w3.eth.waitForTransactionReceipt(tx_hash) print(\"tx_receipt:\\n %s\" % tx_receipt) print(\"-----------------------------------------------------\") print(\"合约地址:\" + tx_receipt.contractAddress) # write the contract address to a file with open(\"../contracts/Ex001HelloWorld.address\", \"w\") as f: f.write(tx_receipt.contractAddress) f.close() 调用合约 import Web3 from \"web3\"; import net from \"net\"; import * as","date":"2022-10-06","objectID":"/evm/:2:3","tags":["EVM","L0","Web3.0"],"title":"EVM","uri":"/evm/"},{"categories":["Blockchain"],"content":"EVM的特点 ","date":"2022-10-06","objectID":"/evm/:3:0","tags":["EVM","L0","Web3.0"],"title":"EVM","uri":"/evm/"},{"categories":["Blockchain"],"content":"确定的 如果一个程序对同一组输入给出相同的输出，无论执行多少次代码，它都是确定性的。确定性函数的一个完美例子是经典的数学运算。例如，假设所有的数字都是以10为基数，无论你重复多少次这个操作, 1+4总是5。 一个相反的例子的浮点数, 用C或者C++随意写关于浮点数计算的代码并且期望它们能够在不同的编译器或者不同架构的机器上得到完全一致的结果是非常非常天真的。 EVM上的Solidity也用同样的问题, 所以其干脆是不支持浮点数的. ","date":"2022-10-06","objectID":"/evm/:3:1","tags":["EVM","L0","Web3.0"],"title":"EVM","uri":"/evm/"},{"categories":["Blockchain"],"content":"可终止的 以太坊智能合约是图灵完备的。如果有足够的时间和资源，智能合约应该能够解决任何问题。然而，无法判断一个合约是否能在给定的时间限制内完成所有操作。这就是为什么智能合约应该有一个终止机制。以太坊智能合约使用 “gas “来定义\"寿命”。当一个执行合约的gas限制过后，它就会停止所有操作。 关于图灵完备, 有些地方也说的是其为\"准图灵完备”, 因为不可能无gas限制地运行一个智能合约. ","date":"2022-10-06","objectID":"/evm/:3:2","tags":["EVM","L0","Web3.0"],"title":"EVM","uri":"/evm/"},{"categories":["Blockchain"],"content":"孤立的 EVM运行智能合约时, 智能合约应该在一个完全隔离的环境中运行。如果改智能合约发生了一些错误，它不应该影响底层协议的其他部分. ","date":"2022-10-06","objectID":"/evm/:3:3","tags":["EVM","L0","Web3.0"],"title":"EVM","uri":"/evm/"},{"categories":["Blockchain"],"content":"EVM的主要问题 EVM是区块链行业的一项突破性创新，因为它使我们所知的dApps成为可能。同时，一些专家注意到它的设计缺陷。 字节码不是人类可以阅读的。这使得开发人员和独立观察员很难分析和验证智能合约代码。 难以调试。这是上一点的直接后果：你必须将字节码反编译成人类可读的形式，以了解dApp出了什么问题。 它的速度很慢，而且要收取大量的gas。注意，EVM的速度是指每秒处理的操作码数量，所以它与以太坊区块链处理交易的能力不一样–以太坊区块链的速度也很慢，每秒15笔交易。 它不够安全。EVM应该保护区块链和dApps免受 “坏 “代码的影响。然而，我们不断看到新的智能合约漏洞。特别危险的是重入式攻击，当黑客重复调用提款函数以耗尽合约的资金时。 合约是不可升级的。一旦你发现什么地方出了问题，你就无法修复它，因为以太坊智能合约在部署后不能被改变。你必须从头开始，部署一个新的合约，迁移用户等等。 EVM不支持本地库。库是一组与虚拟机一起分发的标准合约。开发人员可以使用库中的现成项目，而不是从头开始编写所有的代码，从而节省大量的时间。对于智能合约，使用库也可以节省gas–也就是节省金钱。但由于EVM默认不包括任何标准库（例如，不像Move VM），编写和部署智能合约变得非常昂贵。 ","date":"2022-10-06","objectID":"/evm/:4:0","tags":["EVM","L0","Web3.0"],"title":"EVM","uri":"/evm/"},{"categories":["Blockchain"],"content":"趋势 WebAssembly 使用WebAssembly(ETH的WebAssembly叫eWASM)代替EVM ","date":"2022-10-06","objectID":"/evm/:5:0","tags":["EVM","L0","Web3.0"],"title":"EVM","uri":"/evm/"},{"categories":["Blockchain"],"content":"一些关于UTXO的理解 在web3的的L0中, 涉及到一个概念 Platform neutral language (有些地方也写做 Platform-neutral computation description language ) 平台中立的计算描述语言, 指一种在不同物理平台（架构、操作系统等）上执行相同程序的方法。注意, 它是一种描述, 一种方式, 而不是具体的编程语言. 示例包括 EVM（以太坊）、UTXO（比特币）和 Wasm（Polkadot）。 这里先看看 UTXO : An unspent transaction output 未花费的交易输出 ","date":"2022-08-31","objectID":"/utxo/:0:0","tags":["UTXO","L0","Web3.0"],"title":"UTXO","uri":"/utxo/"},{"categories":["Blockchain"],"content":"什么UTXO 一个交易(TX)由一个或多个输入(Input)和一个或多个输出(Output)组成. 一个输出由两个状态: 未被使用 和 已被使用, 这个使用的意思是: 该输出作为另外一次交易的输入而被花掉(或花掉一部分) 你的账户上所有未被使用掉的输入(unspent transaction output ,UTXO)的总和就是我们平时所说的账户余额. 但在BTC的区块链账本中,我们并不像平时一样使用余额(balance)来进行记录, 而是使用若干个未被使用掉的输入,也就是UTXOs 假设我们现在的账户上还有两个UTXO, 一个0.2BTC, 另外一个0.4BTC, 要进行某次交易, 情况举例1: 交易需要花掉0.1BTC, 这个时候发现0.2BTC这个UTXO就够花了, 所以交易会使用0.2BTC作为input, 当这个交易完成时,这个0.2BTC就不再试UTXO, 其会被分解成2个0.1BTC的UTXO (我们这里先忽略旷工费), 其中一个0.1BTC的UTXO发送到了对方账户, 另外一个0.1BTC返还给我们自己. 这个时候我们账户上还存在2个UXTO, 一个0.1BTC, 一个0.4BTC 情况举例2: 交易需要花掉0.5BTC, 这个时候我们返回0.2和0.4这两个UTXO都不足以完成该次交易, 但0.2+0.4是足够的, 所以需要将他们同时作为该次交易的input,并生成2个UTXO, 一个0.5BTC到对方账户, 另外一个0.1BTC返还到自己账户. ","date":"2022-08-31","objectID":"/utxo/:1:0","tags":["UTXO","L0","Web3.0"],"title":"UTXO","uri":"/utxo/"},{"categories":["Blockchain"],"content":"TX构成 一个交易(TX)由如下这些字段组成 TX的字段 大小 (字节) 描述 version 4 它是指定网络交易类型的版本号。通过，节点可以确定用于验证该特定交易的规则集 input counter 1-9 input 数量, 指下面的input list 的长度 inputs list 不固定 输入列表 output counter 1-9 output 数量, 指下面的output list 的长度 outputs list 不固定 输出列表 lock time 4 它指定交易是否可以立即或在指定时间后包含在区块链中 其中Input由下面这些字段组成 Input的字段 大小 (字节) 描述 previous tx hash 32 上一次交易的hash (追溯这个input是从哪里来的) previous out index 4 上一次交易是其在outputs中的index号 Script length 1-9 解锁脚本的大小 Unlocking script 可变 解锁脚本是用于证明允许交易花费给定 UTXO 的脚本。这是通过首先执行解锁脚本，然后为交易输入引用的 UTXO 执行锁定脚本来完成的 Sequence number 4 通常是禁用或包含锁定时间 - 禁用表示为0xFFFFFFFF 其中 Output由下面这些字段组成 Output的字段 大小 描述 Value 8 将要转移的Satoshis总数（正整数） Script size 1 – 9 锁定脚本大小 Locking script 可变 锁定脚本 锁定和解锁脚本参考 这里 https://medium.com/@ackhor/ch-10-something-on-transaction-unlocking-locking-script-83228754c3f9 比特币交易通过用当前所有者的签名（或与公钥/脚本一起）解锁现有的UTXO（在输入端），并通过锁定新所有者的公钥/公钥哈希/脚本哈希生成新的UTXO（在输出端）。 “解锁 “和 “锁定 “实际上是由称为 “脚本 “的编程语言来完成的。脚本是一个基于堆栈的程序，由数据和操作代码（操作代码）组成。数据是用来 “推 “入堆栈和 “弹 “出堆栈的。请不要将这些数据与比特币交易数据混淆。脚本中的这些数据基本上是公钥、公钥哈希、脚本哈希和签名。另一方面，操作码从堆栈中’弹出’数据，对数据做一些处理，然后将结果’推’回堆栈中。如果结果是'1’，那么这个脚本就是有效的 ","date":"2022-08-31","objectID":"/utxo/:2:0","tags":["UTXO","L0","Web3.0"],"title":"UTXO","uri":"/utxo/"},{"categories":["Blockchain"],"content":"看懂一次交易 以这个交易为例: https://www.blockchain.com/btc/tx/d28ca5a59b2239864eac1c96d3fd1c23b747f0ded8f5af0161bae8a616b56a1d 可以看到这个交易由一个input加上2个output组成. input: 0.00137322btc output[0]: 0.00033324btc output[1]: 0.00093376btc 矿工费: 0.00010622 btc 0.00033324 + 0.00093376 + 0.00010622 = 0.00137322 ","date":"2022-08-31","objectID":"/utxo/:3:0","tags":["UTXO","L0","Web3.0"],"title":"UTXO","uri":"/utxo/"},{"categories":["Blockchain"],"content":"UTXOs集 BTC区块链中存在的全部UTXO表示为一个集合，并由每个比特币节点不断维护。 每笔交易都会消耗这个集合中的元素，并创建新的元素，然后添加到这个集合中。 因此，这个集合代表了一个特定加密货币系统中的所有代币。 每当区块链中接受一个新区块时，UTXO集就会更新。 网络中的每个比特币节点在其本地存储中都会有UTXO集的精确副本。 完整的UTXO集可以被加总，以计算出某一特定时间点的加密货币的总供应量。 在区块链交易有效的情况下，只有未花费的输出可以用于资助进一步的交易。 只有未使用的输出可用于进一步的交易，这一条件对于防止重复消费和欺诈是必要的。 ","date":"2022-08-31","objectID":"/utxo/:4:0","tags":["UTXO","L0","Web3.0"],"title":"UTXO","uri":"/utxo/"},{"categories":["Blockchain"],"content":"扩展的UTXO (EUTXO) 参考这里 https://iohk.io/en/blog/posts/2021/03/11/cardanos-extended-utxo-accounting-model/ ","date":"2022-08-31","objectID":"/utxo/:5:0","tags":["UTXO","L0","Web3.0"],"title":"UTXO","uri":"/utxo/"},{"categories":["devops"],"content":"删库跑路, 如何恢复 给代码打tag的时候, 发现 fatal: 'xxx/myproject.git' does not appear to be a git repository 服务器上一看, 被人删了, NB-PLUS 首先本地机的clone中查看远程路径 \u003e git remote -v origin root@XXX:/xxx/myproject.git (fetch) origin root@XXX:/xxx/myproject.git (push) 到服务器上创建对应的路径 mkdir -p /xxx/ 在服务上创建一个空的repository cd /xxx/ git init --bare myproject.git 到本地机clone中 添加现存代码到服务器 git add . git commit -m \"re-add all\" git push origin master ","date":"2022-08-30","objectID":"/git-master%E6%81%A2%E5%A4%8D/:0:0","tags":["git"],"title":"Git Master恢复","uri":"/git-master%E6%81%A2%E5%A4%8D/"},{"categories":["Blockchain"],"content":"来自 HASEEB QURESHI 的三篇关于P2P网络的博客的翻译 来自这三篇博客 https://nakamoto.com/p2p-networking/ https://nakamoto.com/gnutella/ https://nakamoto.com/bitcoins-p2p-network/ ","date":"2022-08-23","objectID":"/p2p/:0:0","tags":["p2p","L0","Web3.0"],"title":"P2P","uri":"/p2p/"},{"categories":["Blockchain"],"content":"P2P Networking 如果我们想从根本上了解加密货币是如何工作的，我们的工具包里需要的不仅仅是密码学。为了让加密货币发挥作用，它需要的不仅仅是密码学上的安全–它还需要去中心化。中本聪从21世纪初的点对点（P2P）网络历史中学到了很多东西。这些经验为比特币的网络层设计提供了参考。 在本模块中，我们将探讨比特币的网络模型，以及它如何实现其两个主要目标：去中心化和抗审查。 ","date":"2022-08-23","objectID":"/p2p/:1:0","tags":["p2p","L0","Web3.0"],"title":"P2P","uri":"/p2p/"},{"categories":["Blockchain"],"content":"网络架构 传统的网络服务是以集中的客户端-服务器模式进行架构的。一个中央服务器提供服务，每个客户端从这个中央服务器请求数据或工作。你在网络上使用的几乎所有应用程序都是这样的结构–Facebook、Google、Wordpress。今天，“中央服务器 “通常是在负载平衡器后面的一个服务器群，但在高层次上，他们从根本上是相同的架构。 客户端/服务器架构从根本上说是集中式的，并依赖于单一的一方。如果中央服务器关闭，该服务就会暂停（如发生在DigiCash的情况）。 P2P网络是一种分布式的网络模式，其中没有中央服务器。相反，每个对等体承担着网络的部分负荷。这意味着每个对等体可以向网络进行查询，但也必须对查询作出回应。你可以把P2P网络想象成一个 “群(swarm)\"，它融合了客户和服务器的角色。 P2P网络是引人注目的，因为它允许我们实现去中心化。一个去中心化的网络是一个不依赖任何单一节点的网络，因此对任何单一节点的关闭或离开网络都具有弹性。 因此，去中心化是很酷的，但是实质性的问题是–去中心化究竟是如何使一个系统变得更好？ 去中心化给我们带来两个理想的属性： 第一个属性是崩溃容错。崩溃容错意味着你能够承受单个节点的故障或失效–即使一个节点死了，系统仍然可以运行。这对可扩展性至关重要，因为大型网络一直都有节点故障。 译者注: 平时所说的容错算法, 主要指2种, 崩溃容错 和 拜占庭容错 崩溃容错 CFT: 有节点故障了, 整个系统还能继续正确运行 拜占庭容错 BFT: 有节点数据错误(说谎), 整个系统还能正确运行(达成一致性) 去中心化给我们的第二个属性是抗审查。如果一个节点被审查，但整个网络是去中心化的，那么没有关系–系统的其他部分继续运行。为了使审查制度有效，通常每个节点都必须串通起来执行审查制度，而这在一个大型网络中是很难做到的。如果我在一个去中心化的网络中搜索文件，只要有一个节点愿意为我的查询提供回应，整个事情还是可以的。 我们为什么要关心这些资产，这可能并不明显。毕竟，谁在破坏或审查这些网络？简单回顾一下P2P协议的历史，就会明白为什么中本聪重视比特币的这些特性。 ","date":"2022-08-23","objectID":"/p2p/:1:1","tags":["p2p","L0","Web3.0"],"title":"P2P","uri":"/p2p/"},{"categories":["Blockchain"],"content":"P2P 协议简史 在90年代，在大型分布式系统中协调大规模的计算任务是相当罕见的。当时MapReduce或HDFS还没有被发明出来，所以大规模的分布式计算是罕见的，也是昂贵的。P2P协议是第一个在计算机数量上达到大规模的分布式系统（除了互联网本身）。 Napster不是第一个P2P协议，但它是第一个展示P2P模式力量的主流公共成功。 Napster公司由两名大学生Sean Parker和Shawn Fanning于1999年创立。它提供了一个简单的价值主张：它让你从Napster网络中的任何用户那里下载MP3文件。 Napster的架构很简单。有一个中央Napster服务，这主要是一个巨大的搜索索引，保持跟踪所有的同行和他们的共享内容。它将内容元数据存储为以下三元组: 文件名、IP地址、端口号。 每当一个对等体(peer)加入Napster网络时，对等体就会向中央服务器发送一份它愿意分享的文件清单。然后，服务器将更新其搜索索引，以包括这些新共享的文件。 每当用户搜索一个文件时，服务器将查询其搜索索引，并向用户展示所有相关的点击。由于这些点击代表了其他对等体的文件，用户将ping每个相关对等体的IP，以确定他们的下载延迟和线路速度。 一旦用户选择了要下载的文件，他们的客户端将直接从与该文件相对应的IP上获取该文件。所有的文件传输都直接发生在对等体之间。在这一点上，Napster服务器本身已不再参与。 从某种意义上说，Napster是客户/服务器模式和P2P模式之间的交叉。服务器基本上是作为MP3下载者的一个匹配引擎。而事实证明，有一大批人想下载MP3。 在推出后不久，Napster就像野火一样起飞了。在其高峰期，该服务有超过8000万用户。2001年，它经常使大学宿舍的高速网络过载，并很快在许多大学被禁止使用。 2000年，Napster被Metallica、Dr.Dre起诉，随后又被A\u0026M唱片公司起诉侵犯版权。这些诉讼成功地为Napster公司带来了更多的新闻报道和宣传。但是，当法官对Napster公司发出禁令，停止受版权保护的音乐交易时，这场演出终于结束了。 ","date":"2022-08-23","objectID":"/p2p/:1:2","tags":["p2p","L0","Web3.0"],"title":"P2P","uri":"/p2p/"},{"categories":["Blockchain"],"content":"Napster公司的教训 虽然我们称Napster为P2P网络，但在文件发现方面，Napster的设计是传统的客户-服务器模式。只有文件传输实际上是P2P。这给他们的架构带来了单点故障，并意味着网络在Napster公司关闭后消失了。 在Napster中，也很少考虑安全问题。所有的信息和请求都是以明文形式发送的，所有的IP都是公开的，这使得该系统几乎没有隐私可言。 但最终，Napster公司棺材里的钉子是法律上的，而不是技术上的–Napster公司被认为对其用户的版权侵犯负有法律责任。尽管Napster公司没有直接侵犯任何版权，但法官裁定，Napster公司诱使其用户侵犯版权，因此 “替代性地侵犯 “了版权人的权利。 法院要求Napster公司遏制所有版权侵权行为。Napster公司声称，它可以实施一个解决方案，以阻止99.4%的侵权行为，但法院认为这还不够，除非他们能100%地阻止。 ","date":"2022-08-23","objectID":"/p2p/:1:3","tags":["p2p","L0","Web3.0"],"title":"P2P","uri":"/p2p/"},{"categories":["Blockchain"],"content":"后Naspter世界 Napster公司最终申请了破产。它的资产将被收购并重新命名为Rhapsody。但是，Napster公司的消亡将掀起一场巨大的风暴，以至于掩盖了它的渊源。LimeWire和KaZaA等网络接替了Napster，建立了性能更强、去中心化的P2P协议，比前者的限制更少。 随着时间的推移，所有这些协议最终都将被BitTorrent所取代。到2009年，P2P文件共享–主要是BitTorrent–占了所有互联网流量的70%。快进到今天，BitTorrent是世界上最大的单一P2P网络，也是大多数国家最大的上游流量来源。 值得停下来反思的是：为什么BitTorrent能够成功，而其他大多数协议却逐渐消失？ 首先，BitTorrent的带宽共享是以牙还牙的模式，这意味着对等者会给那些对他们慷慨的人提供更多的带宽。这种互惠的系统不鼓励搭便车，鼓励付出。(在现实中，以牙还牙的模式并不特别好用，但与以前的文件共享协议相比，它还是一个进步。） 当涉及到带宽消耗时，BitTorrent也恰好是非常有效的，特别是对于那些需求量大的文件。 但在许多方面，BitTorrent成功的核心真正归结于他们无可挑剔的信息传递。该协议的开发者从未主张将版权文件共享作为该服务的合法用途。他们把BitTorrent说成是 “为你的网站提供更好的服务”，他们的网站只提到无害的使用案例，如Linux发行版和下载魔兽世界的更新。 即使你想这样做，也没有集中的BitTorrent服务可以使用。只有一个由私人经营的BitTorrent追踪器组成的联合网络。因此，当其他P2P网络被执法部门关闭时，BitTorrent只能对个别追踪者采取行动。由于BitTorrent的DHT模式，许多torrents甚至可以在任何单个跟踪器被查封后存活。因此，针对BitTorrent的审查企图往往会演变成一场 “打地鼠 “游戏。 译者注: DHT: 分布式哈希表, 参考文章: https://luyuhuang.tech/2020/03/06/dht-and-p2p.html#23-分布式哈希表 https://colobu.com/2018/03/26/distributed-hash-table/ 举例: 在区块链中, 区块链本身的存储是不适合进行大量数据存储的, 所以其利用了DHT来进行大量数据存储, 比如IPFS 以太坊节点发现是基于Kademlia协议的, Kademlia是一个基于UDP的分布式哈希表协议 文件共享革命对我们与技术和媒体的关系产生了深刻的社会影响。但它的影响并没有结束–它还引发了对P2P协议的工程兴趣的复苏。这导致了许多学术项目，如Folding@home和SETI@home，个人可以将其计算能力借给世界规模的P2P科学计算项目。甚至还有像Skype这样成功的初创公司，最初也是建立在P2P架构之上。 但随着执法和法律斗争的加剧，P2P协议在公众心目中逐渐成为 “非法文件共享 “的同义词。在经历了足够多的负面头条新闻后，学术界的热情也随之枯竭。同时，分布式系统的改进使工程师能够建立更大规模的集中式系统，使P2P架构在大多数商业应用中没有必要。 此外，事实证明很难围绕P2P协议建立可持续的商业模式。大多数内容业务需要一个中央经纪人或DRM来跟踪使用情况并收取费用。几乎根据定义，P2P协议很难实现集中跟踪。uTorrent的前CEO丹尼尔-艾克（Daniel Ek）放弃了BitTorrent的世界，共同创建了音乐公司Spotify，这就是典型的例子。所有这些因素大体上促成了对P2P协议兴趣的下降。 这就是为什么到了2009年，P2P协议在很大程度上已经落伍了。在文件共享网络之外，采用大规模P2P系统的新应用不多。 尽管如此，中本聪明白，P2P架构是创建一个有弹性的、去中心化的货币协议的唯一可行的方法。中本聪写道: 政府善于砍掉像Napster这样的中央控制网络的脑袋，但像Gnutella和Tor这样的纯P2P网络似乎在坚持自己的观点。 ","date":"2022-08-23","objectID":"/p2p/:1:4","tags":["p2p","L0","Web3.0"],"title":"P2P","uri":"/p2p/"},{"categories":["Blockchain"],"content":"P2P架构的权衡因素是什么？ 去中心化并不是免费的。当中本聪为比特币选择P2P架构时，有三个大的障碍不得不接受。 第一个障碍是：在集中式架构中，你通常可以得到全局状态的一个连贯的快照（也就是说，你可以清楚地观察正在发生的一切）。但在P2P协议中，通常不可能得到这种全球快照。P2P节点只存储自己的本地知识，要把网络中正在发生的事情拼凑成一个一致的画面是相当有挑战性的。 例如，在IP路由中就是如此。在IP路由中，没有一个路由器拥有整个互联网的路由表。路由器将数据包传递给他们所知道的下一个最近的节点，相信拥有更多本地信息的节点能够将数据包更接近其目的地。 因此，呈现互联网中活动的全球快照被证明是相当具有挑战性的。 P2P协议的第二个缺点是，随着用户的上线和下线，它们的流失率往往很高。这意味着任何P2P协议必须具有高度的容错性才能使用。集中式架构通常不需要像P2P系统那样的容错程度。 但是，P2P协议所面临的最大障碍可能是它们不能轻易地实施质量控制。因为P2P的成员资格通常是完全开放的，任何恶意行为者都可以自由地加入网络并引起骚乱。在一个中心化的服务中，阻止这样的不良行为者是很直接的。但在一个去中心化的P2P网络中，谁来决定谁是坏人，谁是好人？一个设计不良的节制功能可能会让坏的行为者阻止好的用户。这意味着任何P2P网络都必须被精心设计，以便即使有恶意用户存在，网络也无法被颠覆。 尽管有这些权衡，对中本聪来说，P2P网络的特性对去中心化的货币来说是必要的。 至此，我们对P2P协议的历史概述结束。在下一节中，我们将深入研究一个著名但简单的P2P协议，Gnutella。Gnutella将为我们提供一个八卦协议的蓝图，最终将帮助我们理清比特币自己的网络模型。 ","date":"2022-08-23","objectID":"/p2p/:1:5","tags":["p2p","L0","Web3.0"],"title":"P2P","uri":"/p2p/"},{"categories":["Blockchain"],"content":"Gnutella: an Intro to Gossip Gnutella (/nʊˈtɛlə/) 努特拉 是Napster死后出现的第一批分散式文件共享协议之一。它在文件共享应用程序LimeWire中得到了最广泛的实施。 译者注: LimeWire重新上线后改为搞NFT了 作为一个相当简单的基于 gossip [/‘gɒsɪp/] 的 P2P 协议，Gnutella 的网络设计是理解比特币的一个很好的蓝图。在本课中，我们将从深入研究 gossip 协议的理论开始。然后我们将介绍 Gnutella 的设计。然后，在作业中，您将构建自己的 Gnutella 式协议。 Gnutella 是 gossip 的一个很好的入口点，因为它是生产中使用的最简单的 gossip 协议之一。但是gossip协议自 90 年代就已经存在，并已用于许多系统，例如无线网络、传感器，当然还有互联网路由。今天，许多分布式数据库，如 Cassandra、Riak 和 Voldemort，都使用 gossip 来传播内部状态更新。 那么为什么选择gossip呢？它有什么作用？ 提炼其本质，gossip只是一种进行分散消息传播的方式。 ","date":"2022-08-23","objectID":"/p2p/:2:0","tags":["p2p","L0","Web3.0"],"title":"P2P","uri":"/p2p/"},{"categories":["Blockchain"],"content":"多播(multicast, 组播)问题 你可能很熟悉广播(broadcast)这个词。广播是向网络中的每个节点发送消息。多播是指你想向许多方面发送消息，但不是整个网络中的每个人。如果你想在P2P文件共享网络中进行搜索查询，你实际上并不想把它发送给网络中的每个人–如果你这样做，网络会很快过载。只有网络中的一个子集需要对我们的查询做出实际回应。 那么，什么是执行这种多播的最佳方式呢？ 你首先想到的可能是遍历你想联系的每个人，然后向他们发送一个点对点的消息。 def simple_multicast(recipients, msg): for recipient in recipients: recipient.send(msg) 这很有效，但效率不高。它需要 O(N)时间来执行完整的组播。这也是不现实的：它要求网络中的每个人都要维护网络中每个其他节点的列表。在一个P2P系统中，这个列表可能是巨大的，并且会因为节点的流失而一直变化。(另外，如果发送者在这个长的组播过程中失败了，整个操作就会失败）。 那么，我们如何才能在此基础上进行改进呢？ 优化信息传播的一个方法是建立一个最小生成树。生成树是一棵覆盖图中每个节点的树。最小生成树是可能的最小生成树–换句话说，是用最少的边数（或最小的总边权重）建立的生成树。 下面是这个图的最小生成树。如果我们试图从绿色节点广播一条信息，那么我们所有的信息都将沿着这棵树被传送。（有多个高度为2的生成树，这只是其中之一）。 这应该是实现了一个广播在只有 O(logN) 跳，因为消息的传播时间将与树的深度成正比。此外，每个节点在该广播中只需要执行少量的操作，而不是由发送者执行一个大规模的 O(N)操作（这对一个大型网络来说是不可行的）。 这很好! 事实上，它是如此之好，以至于在理论上是最优的。最小生成树为我们提供了最大效率的路由，特别是如果生成树是在考虑到基础网络拓扑结构的情况下构建的。 但是生成树有一个很大的问题：它们非常脆弱。如果哪怕只有一个节点发生故障或退出网络，整个树的动脉就会被击断，变得无法到达。在P2P环境中，我们必须假设节点会崩溃，数据包会被丢弃，网络拓扑结构会随着时间而改变。当网络是静态的时候，生成树是很好的，但在P2P网络中(网络节点是动态的)，它是一个不可能的事情。 译者注: 最小生成树: https://zh.wikipedia.org/wiki/最小生成树 ","date":"2022-08-23","objectID":"/p2p/:2:1","tags":["p2p","L0","Web3.0"],"title":"P2P","uri":"/p2p/"},{"categories":["Blockchain"],"content":"进入gossip协议 [/‘gɒsɪp/] “流言算法”、“八卦算法”、“瘟疫算法” 如果我们想要生成树的可扩展性，而又没有脆性，我们要使用gossip。gossip协议的原理很简单，你可能已经有了它们如何工作的直觉。 在传统的gossip协议中，每个节点定期向K个随机目标\"传染”。这个K被称为感染因子（作为对流行病学的一个点子）。一旦这些 K 目标收到消息后，他们会随机选择另一个 K 的目标进行闲聊。这种情况一直持续到所有可到达的节点都收到消息，或者消息过期。 下图中k=3 (忽略重复) 感染因子越强，信息传播的速度越快，越彻底。另一方面，感染因子越高，网络中产生的噪音就越多，每条消息消耗的带宽就越多。 如果一个节点向他们所有的同伴传递消息，这就被称为泛滥(flooding)。比特币执行的是泛滥而不是随机感染。 像许多随机协议一样，gossip是不完美的，但它最终近似于最小生成树的属性（有很高的概率）。同时，它提供了更高的容错性。 gossip协议对P2P网络来说有几个理想的特性。 可靠性: 只有一小部分目标收件人无法收到你的广播。 低延时: O(logN) 非常高的容错率 这使得gossip成为像比特币这样的系统中信息传播的主要候选人。 所以，在我们掌握了一点gossip理论后，让我们看看Gnutella是如何工作的。 更多的,参考这里 https://managementfromscratch.wordpress.com/2016/04/01/introduction-to-gossip/ ","date":"2022-08-23","objectID":"/p2p/:2:2","tags":["p2p","L0","Web3.0"],"title":"P2P","uri":"/p2p/"},{"categories":["Blockchain"],"content":"Gnutella协议 /nʊˈtɛlə/ 努特拉 Gnutella的设计始于一个简单的想法：让我们采用一个像Napster一样的文件共享系统，但去掉中央服务器。 你会记得，Napster有一个中央服务器（或一组服务器），作为所有可用文件的搜索引擎运行，并允许对等者找到彼此。在Gnutella中，P2P群组将自己处理搜索请求和对等体的发现。 在Gnutella中，每个客户都同时作为客户和服务器（Gnutella称他们为 “服务者”）。客户端通过P2P叠加图(P2P overlay graph)直接连接到对方。 overlay graph是 “覆盖 “在实际基础网络之上的P2P网络。在这种情况下，底层网络是IP本身–这就是节点必须向对方发送数据包的方式。在底层网络中（也称为 “底层”），共享一个大前缀的两个IP将在物理上相互靠近。但P2P overlay graph不一定尊重基础距离。叠加图中的邻近同伴在物理世界中可能很远，而现实世界中的邻居在P2P图中可能很远。 只要覆盖网络对底层网络拓扑不敏感，你就会得到次优的路由，因为信息不是走现实世界的最短路径。更先进的P2P系统试图使用更聪明的路由模型，将底层网络考虑在内，但最简单的方法是建立一个非结构化的网络，它产生自己的随机拓扑结构，并在信息路由时遵循该结构。Gnutella是一个非结构化的网络，比特币也是如此（有一些注意事项我们将在后面讨论）。 ","date":"2022-08-23","objectID":"/p2p/:2:3","tags":["p2p","L0","Web3.0"],"title":"P2P","uri":"/p2p/"},{"categories":["Blockchain"],"content":"协议简述 现在你已经对Gnutella的工作原理有了一个高层次的概念。让我们深入了解一下更多的细节。 在Gnutella中，每个节点都跟踪一个对等体的列表（为简单起见，让我们说每个对等体不超过5个）。每个节点都会定期对其对等体进行ping，以确保它们仍然在线。如果一个节点注意到它的任何一个对等体已经消失了很久，该节点将取消与他们的对等体，并找到其他的对等体。 在Gnutella协议中，有五种消息类型。 Message type Description Query 搜索某个文件名 QueryHit 对搜索的肯定回复，说明“嘿，我有一个与该查询匹配的文件” Ping 探查peer以查看他们是否还活着 Pong A reply to a Ping Push 要求向请求者发送一个文件（如果文件所有者在防火墙后面，阻止了传入的连接）。 这就是全部。仅仅是这五种信息类型，你就可以做很多事情了! Ping和Pong是用来发现对等人和心跳的，所以我们现在先不考虑这些。 Push消息只用于协调文件所有者在防火墙后面的文件下载，所以也忽略它。 该协议的主要内容发生在Query和QueryHit消息中。 比方说，你在寻找一首Metallica的歌曲，所以你构建了一个Query消息。你想广泛地传播你的查询，所以你向随机的3个对等体gossip这个查询。这些同伴中的每一个人也会向他们的同伴中的随机3人gossip这个查询，以此类推。 请注意，如果这个转发过程无限期地继续下去，我们就会有一个问题：你的信息会在网络中永远循环。节点A会向B发送，B会向C发送，C会向A发送，以此类推。这显然不是我们想要的–我们需要某种形式的内存，这样一个节点就可以丢弃它已经看过的信息。 为了解决这个问题，我们将给每个消息一个UUID。通过简单地跟踪你已经转发的UUID，你可以忽略重复的消息，从而防止任何无限的消息循环。 但仍有一个问题：每条信息都会在P2P网络中传播，直到它实际上到达每个人手中。如果你想这样做，这很好，但对于文件共享来说，这就太过分了。这将迅速成为一个可扩展性瓶颈（每个节点都必须处理整个网络中的每一个搜索）。 为了解决这个问题，我们可以在每个消息上添加一个TTL（生存时间）。TTL是一个整数，每次转发消息时都会递减，一旦TTL为0，消息就会被丢弃。这意味着每条信息在消失之前只会传播这么远，就像一个衰落的波浪。 有了这些东西的实现，我们应该得到一些很好的类似gossip的消息传播，并在网络内进行搜索。 下图为 TTL 为 4 的gossip传播 ","date":"2022-08-23","objectID":"/p2p/:2:4","tags":["p2p","L0","Web3.0"],"title":"P2P","uri":"/p2p/"},{"categories":["Blockchain"],"content":"路由查询命中 现在让我们来看看另一面：假设我们收到一个关于metallica的查询，我们有一个匹配的文件。我们想给他们返回一个QueryHit响应。我们应该如何将响应传回给原发件人？ 最明显的做法是让搜索者在他们的查询中包括他们的IP，这样我们就可以直接响应他们，有点像一个返回地址。这有什么错呢？(真的想一想吧）。问题是这让被动的观察者知道到底是哪个IP在请求哪个文件。这将是一个巨大的隐私泄漏! 我们应该努力做得更谨慎一些，而不是仅仅公布每次搜索的源IP。 也许回应者可以把他们的IP说出来，这将有望让发件人知道应该联系谁。但是，这将侵犯响应者的隐私！这将导致网络中出现许多不必要的噪音。这也会导致网络中出现许多不必要的噪音，因为其他人都要八卦回响应者的IP，尽管只有发送者真正关心。 Gnutella使用的解决方案是相当巧妙的：递归地路由响应。 假设你有一个文件符合 “metallica “的查询。你向转发该信息的人发回一个QueryHit响应，并指定你所响应的UUID。节点C看到该UUID的QueryHit后，会将其发回给转发该查询的人，即节点B，然后节点B会将其发回给节点A，即原发件人。通过简单地让每个节点记住谁转发了他们的每个消息，QueryHits可以被递归地送回发件人。这最大限度地减少了网络中的隐私泄漏和不必要的噪音。 Query和QueryHit消息之间的这种功能是Gnutella文件发现的核心。然后通过直接的HTTP连接进行实际的下载。 正如你所看到的，Gnutella是一个优雅、简单的文件共享协议，在没有中心方的情况下工作。 ","date":"2022-08-23","objectID":"/p2p/:2:5","tags":["p2p","L0","Web3.0"],"title":"P2P","uri":"/p2p/"},{"categories":["Blockchain"],"content":"Gnutella的一些问题 尽管有其独创性，Gnutella也有其问题。第一个问题是带宽：Gnutella产生了大量的网络流量，其中大约50%是ping。有些问题可以通过积极的缓存和整合ping信息来缓解，但该协议的早期版本是非常耗费带宽的。 第二个问题是，70%的Gnutella用户是自由职业者，他们只下载文件，从不上传自己的文件。这使得下载者和上传者之间形成了不健康的平衡。 最后，Gnutella实际上不是这种基于gossip的网络设计的最佳人选。在Gnutella中，一半以上的网络收到每一个查询。这对文件共享来说是矫枉过正的，你不需要那么大一部分网络来接收每个消息–大多数搜索都是针对常见的文件，许多附近的节点都可以为你服务。 另一方面，比特币要求每个节点都知道每个区块，而交易是为了传播给每个人。可以说，这使得比特币比Gnutella更适合于基于gossip的协议。 这些问题由于Gnutella的扁平结构而变得更加复杂，它在网络拓扑结构中把每个节点都视为平等。但是，当涉及到带宽时，节点并不都是平等的–一些节点更稳定地保持在线，并有更多的带宽可以提供。如果一个系统绕过脆弱的节点并围绕高可靠性的节点进行自我组织，那么它的性能就会立即变得更强。 后来的文件共享客户端，如KaZaA或eMule，将使用更多的分层拓扑结构和更智能的路由。在这些系统中，表现良好的节点最终会成为 “超级节点”，在系统中承担更多的负载。相对于像Gnutella这样的扁平结构，这大大提高了它们的整体性能。 在下一课中，我们将看看gossip在比特币本身中是如何运作的，我们还将挖掘隐私在其网络层中的作用。 ","date":"2022-08-23","objectID":"/p2p/:2:6","tags":["p2p","L0","Web3.0"],"title":"P2P","uri":"/p2p/"},{"categories":["Blockchain"],"content":"作业 在这项作业中，你将实现一个简单的P2P协议 这项作业相当复杂，但也是对你推理P2P协议在实践中如何运作的能力的一次大考验。 前往repl.it上的作业，查看README.md。一旦你读完它，fork工作区，开始工作。这个任务没有测试套件；你只需要建立系统，直到协议正常工作。 一旦你完成了（而且只有在你完成之后！），你可以对照解决方案检查你的工作，你可以在Github repo的一个单独的分支中找到。一旦你完成了这项任务，你就可以继续前进了。 ","date":"2022-08-23","objectID":"/p2p/:2:7","tags":["p2p","L0","Web3.0"],"title":"P2P","uri":"/p2p/"},{"categories":["Blockchain"],"content":"比特币的P2P网络 我们已经抽象地看了gossip协议。现在是时候将这些抽象概念应用于比特币自己的P2P网络了。 在高层次上，几乎所有的加密货币都从比特币继承了相同的P2P网络设计。有了Gnutella作为背景，你现在应该完全有能力理解比特币的网络层。它与Gnutella真的很相似，只是在本课中我们会讲到一些增强的部分。 ","date":"2022-08-23","objectID":"/p2p/:3:0","tags":["p2p","L0","Web3.0"],"title":"P2P","uri":"/p2p/"},{"categories":["Blockchain"],"content":"进入网络 到目前为止，我们已经分析了稳定状态下的gossip网络。但是，一个人实际上是如何加入一个八卦网络的呢？你只是在互联网上随机查询节点，直到找到运行正确软件的人吗？(谢天谢地，不是的）。 每个P2P协议都需要一个引导节点来引导你进入网络，并帮助你初始化你的同伴列表。这个引导节点是你进入P2P网络的入口，然后你可以从这里有机地找到新的对等人。 当然，引导节点的危险在于，如果它没有经过认证，它可能是恶意的，并执行中间人或eclipse attack(日蚀攻击)。 在Bitcoin Core，即典型的比特币实现中，这些引导节点被硬编码为可信的DNS服务器，由核心开发者维护。 // From: https://github.com/bitcoin/bitcoin/blob/master/src/chainparams.cpp vSeeds.emplace_back(\"seed.bitcoin.sipa.be\"); // Pieter Wuille, only supports x1, x5, x9, and xd vSeeds.emplace_back(\"dnsseed.bluematt.me\"); // Matt Corallo, only supports x9 vSeeds.emplace_back(\"dnsseed.bitcoin.dashjr.org\"); // Luke Dashjr vSeeds.emplace_back(\"seed.bitcoinstats.com\"); // Christian Decker, supports x1 - xf vSeeds.emplace_back(\"seed.bitcoin.jonasschnelli.ch\"); // Jonas Schnelli, only supports x1, x5, x9, and xd vSeeds.emplace_back(\"seed.btc.petertodd.org\"); // Peter Todd, only supports x1, x5, x9, and xd vSeeds.emplace_back(\"seed.bitcoin.sprovoost.nl\"); // Sjors Provoost vSeeds.emplace_back(\"dnsseed.emzy.de\"); // Stephan Oeste 你可以通过UNIX命令行使用dig命令对这些引导节点之一进行DNS查询，从而自己检索到一个初始对等体列表。 # dig seed.bitcoin.sipa.be 32s ; \u003c\u003c\u003e\u003e DiG 9.10.6 \u003c\u003c\u003e\u003e seed.bitcoin.sipa.be ;; global options: +cmd ;; Got answer: ;; -\u003e\u003eHEADER\u003c\u003c- opcode: QUERY, status: NOERROR, id: 47846 ;; flags: qr rd ra; QUERY: 1, ANSWER: 25, AUTHORITY: 0, ADDITIONAL: 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 4096 ;; QUESTION SECTION: ;seed.bitcoin.sipa.be. IN A ;; ANSWER SECTION: seed.bitcoin.sipa.be. 4502 IN A 173.249.18.129 seed.bitcoin.sipa.be. 4502 IN A 46.6.8.230 seed.bitcoin.sipa.be. 4502 IN A 18.134.242.0 seed.bitcoin.sipa.be. 4502 IN A 52.59.216.190 seed.bitcoin.sipa.be. 4502 IN A 37.59.68.8 seed.bitcoin.sipa.be. 4502 IN A 220.133.39.61 seed.bitcoin.sipa.be. 4502 IN A 50.53.190.92 seed.bitcoin.sipa.be. 4502 IN A 135.181.109.135 seed.bitcoin.sipa.be. 4502 IN A 72.82.9.98 seed.bitcoin.sipa.be. 4502 IN A 71.204.231.91 seed.bitcoin.sipa.be. 4502 IN A 47.54.186.223 seed.bitcoin.sipa.be. 4502 IN A 3.37.231.206 seed.bitcoin.sipa.be. 4502 IN A 104.233.207.37 seed.bitcoin.sipa.be. 4502 IN A 162.250.191.222 seed.bitcoin.sipa.be. 4502 IN A 162.227.162.49 seed.bitcoin.sipa.be. 4502 IN A 136.32.173.8 seed.bitcoin.sipa.be. 4502 IN A 88.198.7.110 seed.bitcoin.sipa.be. 4502 IN A 124.176.25.123 seed.bitcoin.sipa.be. 4502 IN A 23.93.18.185 seed.bitcoin.sipa.be. 4502 IN A 85.10.206.119 seed.bitcoin.sipa.be. 4502 IN A 18.191.42.193 seed.bitcoin.sipa.be. 4502 IN A 194.118.88.162 seed.bitcoin.sipa.be. 4502 IN A 15.161.99.250 seed.bitcoin.sipa.be. 4502 IN A 168.119.104.7 seed.bitcoin.sipa.be. 4502 IN A 72.10.171.42 ;; Query time: 1834 msec ;; SERVER: fe80::5c70:17ff:fe74:3a64%19#53(fe80::5c70:17ff:fe74:3a64%19) ;; WHEN: Tue Aug 30 09:41:24 CST 2022 ;; MSG SIZE rcvd: 449 作为一个有趣的历史点，第一个版本的比特币通过IRC频道寻找对等者来引导其对等者名单。每个比特币节点都捆绑了一个小的IRC客户端，在第一次启动时，它会加入bitcoin00和bitcoin99之间的一个随机频道。如果它在这些频道中发现了其他IP，它就会尝试连接它们，直到填满它的初始对等体列表。 在IRC服务器（LFNet）关闭后，这种形式的引导最终被放弃了，这使比特币的对等体发现程序暂时失效。从那时起，比特币一直依赖这个基于DNS的系统来引导。 最初的对等体发现是所有P2P网络的一个固有的阻塞点。但在这个阶段之后，一个节点可以自由地用它选择的任何对等体来填充它的对等体表。 ","date":"2022-08-23","objectID":"/p2p/:3:1","tags":["p2p","L0","Web3.0"],"title":"P2P","uri":"/p2p/"},{"categories":["Blockchain"],"content":"比特币的垃圾信息保护 你会记得，P2P协议的一个弱点是质量控制。你如何阻止坏的行为者把网络上的垃圾信息搞死？我们早些时候对这个问题做了手脚。原来，比特币使用一个信誉系统来处理这个问题，由Gavin Andresen在2011年实施。 假设你是一个比特币节点，你刚刚启动了你的peer列表。你开始给你的每个对等人分配一个0分的垃圾信息。想想看，这就像一个P2P犯罪记录–在没有中央司法系统的情况下，网络中的每个人都必须对其他人的行为保持警惕。 小的违规行为，如在初始握手时没有发送版本信息，将使你的分数增加1分。更严重的DoS企图，如在INV（inventory）消息中发送超过50,000个ID，将使你被扣20分。 一旦一个peer积累了100分，你的客户端就会自动对他们进行24小时的影子禁言(shadowbans)，并停止对他们的gossip。这些垃圾信息的分数实际上没有在协议中跨对等体传播。(为什么你认为它们不是呢？)但即使如此，这个系统也是对行为不端的节点的一种适当的防御。 ","date":"2022-08-23","objectID":"/p2p/:3:2","tags":["p2p","L0","Web3.0"],"title":"P2P","uri":"/p2p/"},{"categories":["Blockchain"],"content":"网络层面的隐私 P2P网络有其内在的隐私权衡。想一想：网络中的每条信息都是公开喊出来的，任何人都可以自由地观察所有经过的信息。对于像比特币这样的金融网络，这种缺乏隐私的情况并不理想。 比特币由于其假名性，提供了一些金融隐私。如果全世界都知道账户1G9HFbCRikgPpQboURsdqszy9HbKtvceZ5在一家简陋的海外药店花了0.25BTC，也许我就没事。但是，如果有人能找出最初发送签名交易的我的IP，突然间我的隐私就被泄露了。 这很糟糕。P2P网络对审查制度有抵抗力，但对监视却一点也不抵抗。 让我们勾勒出一个复杂的窃听者如何监视网络的过程。 默认情况下，一个正常的比特币节点会与其他对等体建立8个出站连接。然而，比特币客户端是开源的，所以任何人都可以自由地修改他们的客户端，以连接到他们想要的更多对等体。现在比特币网络中大约有10,000个实时对等体，原则上，一个人可以连接到所有的对等体。这将使你成为一个超级节点。 有了超级节点，你就可以跟踪网络中任何地方发送的每一条信息，并从上帝的视角重建所有信息的历史。这基本上可以让你弄清楚哪些地址对应哪些IP，并对比特币交易进行匿名化处理。 gossip传播的设计不是为了维护隐私。请记住，在收到消息后的那一刻，每个节点都会立即将其淹没到所有的出站peer。这就留下了每个消息开始的明显痕迹。即使一个被动的观察者只连接到网络的50%，他们也会清楚地看到从发件人那里发出的 “信息波”。 2015年，比特币改变了它传播gossip信息的方式，以实现更好的隐私。它现在使用一种叫做扩散(diffusion)的方法。在扩散过程中，客户端不是立即向每个对等体泛滥，而是在向每个对等体说闲话之前等待一个随机指数延迟。这有掩盖P2P消息图的作用，使人们更难观察到 “消息波(message wave) “的来源。 你可以用这样的代码来勾勒它。 def gossip(msg): for peer in peers: schedule_send(peer, msg, wait=np.random.exponential(1.0 / theta)) 然而，即使如此，比特币网络层的隐私也远非完美。扩散(diffusion)仍然向被动的对手泄露了相当多的信息。此外，P2P信息不是双边加密的，所以被动的数据包嗅探器可以很容易地窥探到任何比特币流量的明文。 在改善比特币的网络级隐私方面，还有很多工作要做。一些有隐私意识的用户更喜欢比特币而不是Tor的网络隐私，但即使这样也有问题。 最近，CMU的研究人员想出了一个比扩散(diffusion)更完善的方案，称为蒲公英协议(Dandelion Protocol)，提供了更好的网络级隐私保证。 在蒲公英协议中，每一个交易广播都是从一个秘密的电话游戏开始的。发起人会把他们的交易悄悄告诉一个对等人，后者再把它悄悄告诉另一个对等人，如此循环。经过随机数的跳转，最后一个对等体将会像比特币一样把交易说出来。但这个对等体与发起人相距甚远，对于任何观察者来说，都不可能分辨出这条链是从谁开始的。 这对于混淆发起人的IP更为有效，但它的代价是消息的传播速度更慢。蒲公英现在被认为是对比特币gossip机制的一种可能的增强，并且已经在其他加密货币中实施。我们在补充阅读中提供了更多关于蒲公英的资源。 ","date":"2022-08-23","objectID":"/p2p/:3:3","tags":["p2p","L0","Web3.0"],"title":"P2P","uri":"/p2p/"},{"categories":["Blockchain"],"content":"P2P网络中的生活 你现在应该对信息在加密货币网络中的传播方式有一个更好的心理模型。由于其gossip架构，加密货币是 “最终一致”–它们不提供任何关于你的消息何时会被网络的其他部分看到的硬性保证。此外，并非所有节点都会在同一时间看到相同的状态。 下图: 50%（橙色）或 90%（蓝色）的网络需要多长时间才能收到最新的比特币区块 当这些网络达到一定规模时，信息的传播速度会相当缓慢。对于比特币来说，过去90%的网络需要30多秒才能收到最新的区块！现在，只需要几秒钟就能让整个网络同步到最新的区块。今天，它需要几秒钟，直到整个网络同步到最新的区块上。(矿工看到新区块的速度要快得多，这一点我们将在后面探讨比特币采矿时讨论）。 我们对比特币网络层的探索到此结束。现在你应该对流言协议的工作原理有了直观的认识，以及是什么让它们在规模上如此强大。你也应该明白为什么中本聪选择用P2P架构设计比特币网络。 有了这个基础，在下一个模块中，我们将探索共识–首先，我们将研究它的经典起源，导致中本聪的基本突破，使比特币成为可能。 ","date":"2022-08-23","objectID":"/p2p/:3:4","tags":["p2p","L0","Web3.0"],"title":"P2P","uri":"/p2p/"},{"categories":["Blockchain"],"content":"附加阅读 https://docs.libp2p.io/introduction/ LIBP2P库 Bitcoin Core 0.11: P2P Network, a Bitcoin Wiki walkthrough of Bitcoin Core’s P2P networking stack (2018) Anonymity Properties of the Bitcoin P2P Network, showing how passive observers can use statistical techniques to deanonymize Bitcoin transactions by monitoring P2P traffic, by Giulia Fanti and Pramod Viswanath (2017) The Dandelion Protocol (video), a message propagation technique with stronger anonymity properties, presented by Giulia Fanti (2018) ","date":"2022-08-23","objectID":"/p2p/:3:5","tags":["p2p","L0","Web3.0"],"title":"P2P","uri":"/p2p/"},{"categories":["Blockchain"],"content":"关于零知识证明的若干知识 ","date":"2022-08-22","objectID":"/%E9%9B%B6%E7%9F%A5%E8%AF%86%E8%AF%81%E6%98%8E/:0:0","tags":["ZKPs","L0","Web3.0"],"title":"零知识证明","uri":"/%E9%9B%B6%E7%9F%A5%E8%AF%86%E8%AF%81%E6%98%8E/"},{"categories":["Blockchain"],"content":"这是啥 我知道一个秘密, 不能告诉你, 但我又得向你证明我的确知道这个秘密 ","date":"2022-08-22","objectID":"/%E9%9B%B6%E7%9F%A5%E8%AF%86%E8%AF%81%E6%98%8E/:1:0","tags":["ZKPs","L0","Web3.0"],"title":"零知识证明","uri":"/%E9%9B%B6%E7%9F%A5%E8%AF%86%E8%AF%81%E6%98%8E/"},{"categories":["Blockchain"],"content":"为什么需要零知识证明 区块链太透明 区块链以透明著称, 但这会带来一些问题, 比如一些企业级应用中的数据并不适合这种透明性 Web2.0向Web3.0的过度 在Web3.0概念很火爆的今天, 不得不承认一个观点: 在向Web3.0进发的过程中, Web2.0的已有数据和生态将长期过程,然后融合. 一个简单的问题是: Web2.0数据如何传递到Web3.0中, 并在Web3.0的区块链上形成共识. 零知识证明提供了解决方案, 让Web2.0(以及一切链外数据)和Web3.0相互信任 所以零知识证明是Web3.0的基石. 其处于L0层. ","date":"2022-08-22","objectID":"/%E9%9B%B6%E7%9F%A5%E8%AF%86%E8%AF%81%E6%98%8E/:2:0","tags":["ZKPs","L0","Web3.0"],"title":"零知识证明","uri":"/%E9%9B%B6%E7%9F%A5%E8%AF%86%E8%AF%81%E6%98%8E/"},{"categories":["Blockchain"],"content":"阿里巴巴洞穴 如何向你的孩子解释零知识证明协议 https://link.springer.com/content/pdf/10.1007/0-387-34805-0_60.pdf 简单翻译一下: 哦，我的孩子们，你们要知道，很久以前，在东部城市巴格达，住着一个叫阿里巴巴的老人。每天阿里巴巴都会去集市上买东西或卖东西。这个故事部分是关于阿里巴巴的，部分也是关于一个山洞的，一个奇怪的山洞，其秘密和奇迹至今存在。但我想得太远了… 有一天，在巴格达集市上，一个小偷从阿里巴巴手中抢走了一个钱包，阿里巴巴马上开始追赶他。小偷逃进了一个山洞，山洞的入口分叉成两条黑暗的蜿蜒通道：一条向左，另一条向右。 山洞大概长这个样子😂 xxxxxxx xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx xxxxxxx xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx xxxxxxx xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx xxxxxxx xxxxxxxxxxxxxxxxxxxxxxxxx xxxxxxx xxxxxxx xxxxxxxxxxxxxxxxxxxxxxxxx xxxxxxxxxxx xxxxxxx xxxxxxxxxxxxxxxxxxxxxxxxx xxxxxxxxxxx xxxxxxx xxxxxxxxxxxxxxxxxxxx xxxxxxxxxxx xxxxxxx xxxxxxxxxxxxxxxxxxxx xxxxxxxxxxx xxxxxxx xxxxxxxxxxxxxxxxxxxx xxxxxxxxxxx xxxxxxx left xxxxxxxxxxx xxxxxxx xxxxxxxxxxx xxxxxxx xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx xxxxxxx xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx xxxxxxx xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx xxxxxxx xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx xxxxxxx xxxxxxxxxxxxxxxxxxxxxxx xxxxxxx xxxxxxxxxxxxxxxxxxxxxxx xxxxxxx right xxxxxxx xxxxxxx xxxxxxx xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 阿里巴巴没有看到小偷进入哪条通道。阿里巴巴不得不选择走哪条路，他决定向左走。左边的通道尽头是一个死胡同。阿里巴巴从岔路口一直找到死胡同，但他没有找到小偷。阿里巴巴对自己说，小偷也许在另一条通道上。于是他找了右边的通道，也是一个死胡同。但他再次没有找到小偷。“这个洞很奇怪，“阿里巴巴对自己说，“我的小偷去哪儿了？” 第二天，另一个小偷抓起阿里巴巴的篮子，像第一个小偷一样，逃进了那个奇怪的山洞。阿里巴巴追赶他，又一次没有看到小偷往哪边走。这一次，阿里巴巴决定向右搜索。他一直走到右侧通道的尽头，但没有找到那个小偷。他对自己说，和第一个小偷一样，第二个小偷也很幸运，走了阿里巴巴没有选择的通道。这无疑让小偷再次离开，悄悄地混入拥挤的集市。 日子一天天过去，每天都有小偷。阿里巴巴总是追着小偷跑，但他从未抓住过任何一个。第四十天，第四十个小偷抓起阿里巴巴的头巾，像之前的三十九个小偷一样，逃进了那个奇怪的山洞。阿里巴巴又一次没有看到小偷走了哪条路。这一次，阿里巴巴决定搜索左边的通道，但他又一次没有在通道尽头找到小偷。阿里巴巴非常疑惑。 他本可以像以前那样对自己说，第四十名小偷和其他三十九名小偷一样幸运。但这种解释非常牵强，甚至阿里-巴巴也不相信。四十名小偷的运气实在太好了，不可能是偶然的事情。一百万分之一的机会，这四十个人都能逃脱！所以阿里巴巴说，这四十个人的运气太好了，不可能是偶然的。所以阿里巴巴对自己说，一定有另一种更可能的解释。他开始怀疑，这个奇怪的山洞守护着一个秘密! 阿里巴巴开始探索这个奇怪山洞的秘密。他决定躲在右侧通道尽头的一些麻袋下面。经过一段非常不舒服的等待，他看到一个小偷来了，他感觉到自己被受害者追赶，就低声说了一句神奇的话，“芝麻开门”。阿里巴巴惊奇地看到洞壁滑开。小偷从洞口跑了出来。然后，墙又滑开了。追捕者赶到，发现通道的死胡同里只有阿里巴巴在麻袋下面，不由得大失所望。小偷已经逃走了。但阿里巴巴很高兴，因为他发现了奇异洞穴的秘密。 阿里巴巴用这些神奇的词语进行了实验。他惊奇地发现，当墙壁滑开时，右边的通道与左边的通道是相连的。现在，阿里巴巴知道了四十个小偷是如何从他手中逃脱的了。阿里巴巴用这些魔法词不断工作，最后他设法用新的魔法词取代它们，有点像你改变一些挂锁的密码。阿里巴巴把这个故事和他的发现记录在一本可爱的插图手稿中。他没有写下新的魔法词，但他包括了一些关于它们的微妙线索。 阿里巴巴的手稿在中世纪时抵达意大利。今天它在美国，靠近波士顿。在那里，它最近引起了一些好奇的研究人员的充分注意。通过对微妙线索的解密，这些研究人员甚至找回了新的魔力之词。 电视网络很快就知道了在巴格达发生的异常事件。一家大型美国电视网甚至获得了这个故事的独家报道。其中一位研究人员，某个叫米克-阿里的人，也许是阿里巴巴的后裔，想证明他知道这个秘密。但他并不想透露这个秘密。他的做法是这样的。 首先，一个电视摄制组拍摄了洞内两个死胡同的详细参观。然后所有人都走出了山洞。米克-阿里又独自进去，走了其中一条通道。然后，记者在摄像机的陪同下，只走到了岔路口。在那里，他抛出一枚硬币，在左右两边做出选择。如果硬币是正面，他就告诉米克从右边出来。如果硬币是反面，他就会告诉米克从左边出来。结果是正面，所以记者大声叫道：“米克，从右边出来。” 米克就这样做了。 为了纪念那四十个小偷，这个演示场景被播放了四十次。每一次大家都回到洞外，米克独自进入其中一个通道，一路走来。然后记者和摄像机一直走到岔路口，在那里他通过抛硬币选择给米克的命令。米克在所有40个场景中都成功了。 任何不知道山洞秘密的人都会在第一次失败时被暴露。每一次新的测试都会使不知道秘密的人的成功机会减少两倍。另一方面，这个秘密让米克每次都能从规定的出口出来。 ……. ","date":"2022-08-22","objectID":"/%E9%9B%B6%E7%9F%A5%E8%AF%86%E8%AF%81%E6%98%8E/:3:0","tags":["ZKPs","L0","Web3.0"],"title":"零知识证明","uri":"/%E9%9B%B6%E7%9F%A5%E8%AF%86%E8%AF%81%E6%98%8E/"},{"categories":["Blockchain"],"content":"零知识证明介绍 从上面的故事中, 可以看出 零知识证明 (Zero Knowledge Proofs, ZKPs) 是基于概率性的, 而不是确定性的, 随着测试的不断进行, 靠运气猜中的几率越来越低: 0.5 ^ n 零知识证明一般包括3个阶段: 证明者发送声明, 并将其发送给验证者 验证者选择一个问题, 发送给证明者 证明者生成答案, 发送给验证者, 验证者验证答案是否正确 但这里, 明显弊端就出来了: 它需要验证者和证明者不停的进行多次交互, 以降低运气概率, 提高可信度. 这样的证明方式也称为 交互式零知识证明 换一个验证者, 证明者又得需要重复上述过程 所以这又引入了另外一个概念简洁的非交互式零知识证明: “Zero-Knowledge Succinct Non-Interactive Argument of Knowledge”，或 “zk-SNARK”， ","date":"2022-08-22","objectID":"/%E9%9B%B6%E7%9F%A5%E8%AF%86%E8%AF%81%E6%98%8E/:4:0","tags":["ZKPs","L0","Web3.0"],"title":"零知识证明","uri":"/%E9%9B%B6%E7%9F%A5%E8%AF%86%E8%AF%81%E6%98%8E/"},{"categories":["Blockchain"],"content":"zk-SNARK 简洁的非交互式零知识证明: “Zero-Knowledge Succinct Non-Interactive Argument of Knowledge”: Succinct: 简洁, 意味着证明很短（例如，对于加密货币的人来说，让我们说，它可以很容易地存储在现有区块链的交易中），并且可以很容易地被验证（例如，它可以由区块链节点在验证区块时廉价地检查）。 Non-Interactive: 非交互式意味着我们可以编写和存储一个证明，而不需要像主页中的介绍性 “斯诺克球 “例子那样有问题/答案循环。因此，一个证明可以被计算出来并发布在区块链上，每个人都可以验证它。 zk-Snark通常以5个主要步骤的序列来实现: 要证明的计算的表示，作为一组变量之间的约束条件 将上述约束集还原为多项式方程 选择一个随机值，并将其和所有方程单向映射到一个 “同态 “空间，即一个线性组合（对系数的求和和乘法）仍然成立的空间，因此第2点中定义的方程在这个新空间中仍然成立。这是一个单向的映射，基于椭圆曲线数学，所以它是一种 “加密 “技术：如果你只知道被映射的加密点，那么计算原始值在计算上是不可行的。然后，原始选择的值将是一个秘密，永远不会被任何人知道。 证明创建，通过将在所选（秘密）值中计算的方程映射到同态空间。在这个阶段，随机值被用来进一步隐藏方程，同时保留方程结构。 通过计算方程是否成立来验证证明。验证不是直接在映射的空间中进行的，而是通过一个 “配对 “函数将数值再次映射到一个新的空间，该函数保留并允许检查原始变量之间的乘法。 是不是理解起来特别懵逼😳 通过一个来自这里的漫画更容易理解点 : https://github.com/KevinSmall/zk-SNARKs-Explainer/blob/master/translations/zh-TW/README.md 这里就看到了几个关键函数, 而他们实际是相当复杂的, 有能力的看这里 https://www.di.ens.fr/~nitulesc/files/Survey-SNARKs.pdf ","date":"2022-08-22","objectID":"/%E9%9B%B6%E7%9F%A5%E8%AF%86%E8%AF%81%E6%98%8E/:5:0","tags":["ZKPs","L0","Web3.0"],"title":"零知识证明","uri":"/%E9%9B%B6%E7%9F%A5%E8%AF%86%E8%AF%81%E6%98%8E/"},{"categories":["Blockchain"],"content":"扩展阅读 Awesome zero knowledge proofs (zkp) https://github.com/matter-labs/awesome-zero-knowledge-proofs zkapps https://docs.minaprotocol.com/en/zkapps ","date":"2022-08-22","objectID":"/%E9%9B%B6%E7%9F%A5%E8%AF%86%E8%AF%81%E6%98%8E/:6:0","tags":["ZKPs","L0","Web3.0"],"title":"零知识证明","uri":"/%E9%9B%B6%E7%9F%A5%E8%AF%86%E8%AF%81%E6%98%8E/"},{"categories":["tools"],"content":"censys https://search.censys.io 堪称神器, 翻译了一下帮助文档 ","date":"2022-08-19","objectID":"/censys%E6%96%87%E6%A1%A3/:0:0","tags":["censys"],"title":"Censys文档","uri":"/censys%E6%96%87%E6%A1%A3/"},{"categories":["tools"],"content":"Search Language ","date":"2022-08-19","objectID":"/censys%E6%96%87%E6%A1%A3/:1:0","tags":["censys"],"title":"Censys文档","uri":"/censys%E6%96%87%E6%A1%A3/"},{"categories":["tools"],"content":"全文搜索 当没有指定字段时，Censys会尝试对所有字段进行全文搜索。 例如，搜索Dell将返回location.city为 “Dell Rapids “的主机，以及service.software.vendor为 “Dell “的主机。如果你对戴尔制造的设备感兴趣，你会希望指定存储该信息的字段。 ","date":"2022-08-19","objectID":"/censys%E6%96%87%E6%A1%A3/:1:1","tags":["censys"],"title":"Censys文档","uri":"/censys%E6%96%87%E6%A1%A3/"},{"categories":["tools"],"content":"指定字段和值 有效的搜索将指定一个属性所存储的字段。为此，你需要知道你要搜索的数据集中的字段。 在数据定义标签下查看字段及其价值类型的完整列表，或者选择在详情页上查看原始数据，例如谷歌公共DNS的[主机表视图]（https://search.censys.io/hosts/8.8.8.8/data/table）。 一个典型的搜索至少提供一个字段–它反映了使用点符号的JSON模式的嵌套（例如，services.http.response.headers.server.headers） — 和一个值。如果值的类型是文本，将返回一个模糊匹配的结果；如果值的类型是关键词，只返回一个精确的匹配。 例如，你可以通过指定字段和值来搜索所有有HTTP服务返回HTTP状态码的主机。services.http.response.status_code: 500 . ","date":"2022-08-19","objectID":"/censys%E6%96%87%E6%A1%A3/:1:2","tags":["censys"],"title":"Censys文档","uri":"/censys%E6%96%87%E6%A1%A3/"},{"categories":["tools"],"content":"Wildcards 通配符 默认情况下，Censys搜索的是完整的值。例如，搜索 “Del “不会返回包含 “Dell “的记录。通配符可以用来扩大搜索范围，以便在结果中包括部分匹配。 有两个通配符。 ? - 这个通配符表示一个字符。 * - 这个通配符表示零个或多个字符。 组合通配符也是非常有用的。 下面的查询利用CPE软件格式的知识，搜索运行微软IIS webservers的服务，其主要版本\u003c10（因为? 只代表一个字符）和确定的次要版本（因为存在句号）。*通配符占CPE格式的其余部分： services.software.uniform_resource_identifier: cpe:2.3:a:microsoft:iis:?.* *通配符的另一个用途是检查一个字段是否存在，这对服务未知的主机很有帮助。例如，这个查询将返回至少有一个服务已经与Censys完成TLS握手的主机：services.tls: * ","date":"2022-08-19","objectID":"/censys%E6%96%87%E6%A1%A3/:1:3","tags":["censys"],"title":"Censys文档","uri":"/censys%E6%96%87%E6%A1%A3/"},{"categories":["tools"],"content":"网络协议和端口 使用CIDR符号搜索IP地址块（例如，ip：23.20.0.0/14）或通过提供一个范围：ip：[23.20.0.0 to 23.20.5.34/]。通过搜索服务名称字段来搜索运行特定协议的主机： services.service_name: S7 。通过搜索端口字段来搜索具有特定端口的主机：services.port: 3389 ","date":"2022-08-19","objectID":"/censys%E6%96%87%E6%A1%A3/:1:4","tags":["censys"],"title":"Censys文档","uri":"/censys%E6%96%87%E6%A1%A3/"},{"categories":["tools"],"content":"用布尔逻辑组合搜索条件 使用 “AND”、“OR”、“NOT “和括号来组合多个搜索条件。布尔是不区分大小写的。 默认情况下，由布尔表达式组合的条件是针对主机整体进行评估的。 AND 搜索services.port: 8880 and services.service_name: HTTP将返回打开8880端口的主机（上面运行着任何服务）和运行在任何端口的HTTP服务。 要搜索运行在8880端口的HTTP服务，请使用same_service()函数。same_service(services.port: 8880 and services.service_name: HTTP) . OR 搜索services.port: 21 or services.service_name: FTP将返回任何打开21号端口（在其上运行任何服务）和在任何端口运行FTP服务的主机。 NOT 搜索not same_service(service_name: HTTP and port: 443)将返回那些没有在443上运行HTTP的主机。 搜索[same_service(service_name: \"HTTP\" and not port:443)](https://search.censys.io/search?q=same_service(service_name%3A+\"HTTP “+and+not+port%3A443)\u0026resource=hosts)将返回任何有HTTP服务但不在443端口运行的主机。这可以包括在443上有HTTP的主机，只要有一个不同端口号的其他HTTP服务。 ","date":"2022-08-19","objectID":"/censys%E6%96%87%E6%A1%A3/:1:5","tags":["censys"],"title":"Censys文档","uri":"/censys%E6%96%87%E6%A1%A3/"},{"categories":["tools"],"content":"范围 搜索数字的范围，用[ 和 ]表示包容范围，用{和}表示排他范围。例如，services.http.response.status_code:[500 to 503] 。日期应使用以下语法进行格式化[2012-01-01 to 2012-12-31]。也可以指定单边限制[2012-01-01 to *] . to操作符不区分大小写。 ","date":"2022-08-19","objectID":"/censys%E6%96%87%E6%A1%A3/:1:6","tags":["censys"],"title":"Censys文档","uri":"/censys%E6%96%87%E6%A1%A3/"},{"categories":["tools"],"content":"正则表达式 正则表达式仅限于付费客户使用。完整的重新编码语法是可在此获得。 注意 Censys的正则搜索是不区分大小写的，除非使用精确匹配操作符=。 例如，services.software.vendor:/De[l]+/将返回该词大写或小写的结果，而services.software.vendor=/De[l]+/将只返回大写词的结果。 ###Unicode 转义序列 以下序列将被解释为unicode转义序列，以使用户能够在它们经常出现的地方搜索这些特殊字符，如服务标语和HTTP正文。 Escape Sequence Character Represented \\a Alert \\b Backspace \\e Escape character \\f Formfeed / Page break \\n Newline \\r Carriage return \\t Horizontal tab \\v Vertical tab 例如，services.banner=\"Hello\\nWorld\"将把\\n解释为换行，而不是转义的n。 ","date":"2022-08-19","objectID":"/censys%E6%96%87%E6%A1%A3/:1:7","tags":["censys"],"title":"Censys文档","uri":"/censys%E6%96%87%E6%A1%A3/"},{"categories":["tools"],"content":"保留字符 以下字符将被解释为控制字符，除非它们被反斜杠转义（即前面）或被封装在一个由反斜杠包围的字符串中。 = \u003e \u003c ) } ] \" * ? : \\ / 例如，星号在CPE软件标识符中很常见，而转义每个星号是很繁琐的，所以URI周围的反引``号将转义其中所有的星号。 (services.software.uniform_resource_identifier: `cpe:2.3:a:cloudflare:cloudflare_load_balancer:*:*:*:*:*:*:*:*`) ","date":"2022-08-19","objectID":"/censys%E6%96%87%E6%A1%A3/:1:8","tags":["censys"],"title":"Censys文档","uri":"/censys%E6%96%87%E6%A1%A3/"},{"categories":["tools"],"content":"例子 ","date":"2022-08-19","objectID":"/censys%E6%96%87%E6%A1%A3/:2:0","tags":["censys"],"title":"Censys文档","uri":"/censys%E6%96%87%E6%A1%A3/"},{"categories":["tools"],"content":"在该范围内的主机 23.0.0.0/8 or 8.8.8.0/24: ip: {\"23.0.0.0/8\", \"8.8.8.0/24\"} ","date":"2022-08-19","objectID":"/censys%E6%96%87%E6%A1%A3/:2:1","tags":["censys"],"title":"Censys文档","uri":"/censys%E6%96%87%E6%A1%A3/"},{"categories":["tools"],"content":"在德国运行 FTP 或 Telnet 的主机: location.country_code: DE and services.service_name: {\"FTP\", \"Telnet\"} ","date":"2022-08-19","objectID":"/censys%E6%96%87%E6%A1%A3/:2:2","tags":["censys"],"title":"Censys文档","uri":"/censys%E6%96%87%E6%A1%A3/"},{"categories":["tools"],"content":"HTTP 正文中带有 powershell.exe 的主机: services.http.response.body: powershell.exe ","date":"2022-08-19","objectID":"/censys%E6%96%87%E6%A1%A3/:2:3","tags":["censys"],"title":"Censys文档","uri":"/censys%E6%96%87%E6%A1%A3/"},{"categories":["tools"],"content":"“Sitting on the Dock of the Bay”的准确 SNMP 位置值: services.snmp.oid_system.location = \"Sitting on the Dock of the Bay\" ","date":"2022-08-19","objectID":"/censys%E6%96%87%E6%A1%A3/:2:4","tags":["censys"],"title":"Censys文档","uri":"/censys%E6%96%87%E6%A1%A3/"},{"categories":["tools"],"content":"带有短语“Schneider Electric”或 Dell 在 23.20.0.0/14 范围内的主机： (\"Schneider Electric\" OR Dell) AND ip:23.20.0.0/14 ","date":"2022-08-19","objectID":"/censys%E6%96%87%E6%A1%A3/:2:5","tags":["censys"],"title":"Censys文档","uri":"/censys%E6%96%87%E6%A1%A3/"},{"categories":["tools"],"content":"打开以下任何一个端口的主机：22、23、24、25: services.port: {22, 23, 24, 25} ","date":"2022-08-19","objectID":"/censys%E6%96%87%E6%A1%A3/:2:6","tags":["censys"],"title":"Censys文档","uri":"/censys%E6%96%87%E6%A1%A3/"},{"categories":["tools"],"content":"没有运行 HTTP 服务的主机: NOT services.service_name: HTTP ","date":"2022-08-19","objectID":"/censys%E6%96%87%E6%A1%A3/:2:7","tags":["censys"],"title":"Censys文档","uri":"/censys%E6%96%87%E6%A1%A3/"},{"categories":["tools"],"content":"主机出示任何证书: services.tls.certificates.leaf_fp_sha_256: * ","date":"2022-08-19","objectID":"/censys%E6%96%87%E6%A1%A3/:2:8","tags":["censys"],"title":"Censys文档","uri":"/censys%E6%96%87%E6%A1%A3/"},{"categories":["tools"],"content":"呈现字符串 “hello “的主机由任何值继承（正则表达式）。 /hello.*/ ","date":"2022-08-19","objectID":"/censys%E6%96%87%E6%A1%A3/:2:9","tags":["censys"],"title":"Censys文档","uri":"/censys%E6%96%87%E6%A1%A3/"},{"categories":["tools"],"content":"提出名称为foo1, foo2, foo3…foo100的主机，由任何数值（常规表达式）继承。 services.tls.certificates.leaf_data.names=/foo\u003c1-100\u003e.*/ ","date":"2022-08-19","objectID":"/censys%E6%96%87%E6%A1%A3/:2:10","tags":["censys"],"title":"Censys文档","uri":"/censys%E6%96%87%E6%A1%A3/"},{"categories":["tools"],"content":"指定范围内的主机： ip: [1.12.0.0 TO 1.15.255.255] ","date":"2022-08-19","objectID":"/censys%E6%96%87%E6%A1%A3/:2:11","tags":["censys"],"title":"Censys文档","uri":"/censys%E6%96%87%E6%A1%A3/"},{"categories":["tools"],"content":"在端口 22 和 2222 以外的端口上运行 SSH 服务的主机： same_service(services.service_name: \"SSH\" AND NOT (services.port: 22 OR services.port: 2222)) ","date":"2022-08-19","objectID":"/censys%E6%96%87%E6%A1%A3/:2:12","tags":["censys"],"title":"Censys文档","uri":"/censys%E6%96%87%E6%A1%A3/"},{"categories":["tools"],"content":"在端口 443 上运行 elasticsearch 的主机： same_service(services.service_name: \"ELASTICSEARCH\" AND services.port: 443) ","date":"2022-08-19","objectID":"/censys%E6%96%87%E6%A1%A3/:2:13","tags":["censys"],"title":"Censys文档","uri":"/censys%E6%96%87%E6%A1%A3/"},{"categories":["tools"],"content":"有服务的主机，最后一次被NTT ISP内的Censys扫描器扫描过的。 services.perspective_id: \"PERSPECTIVE_NTT\" ","date":"2022-08-19","objectID":"/censys%E6%96%87%E6%A1%A3/:2:14","tags":["censys"],"title":"Censys文档","uri":"/censys%E6%96%87%E6%A1%A3/"},{"categories":["tools"],"content":"在NTT或TELIA ISP内，具有Censys扫描器最后扫描的服务的主机。 services.perspective_id: \"PERSPECTIVE_NTT\" OR services.perspective_id: \"PERSPECTIVE_TELIA\" 在HTTP服务上有一个包含 “dashboard “一词的页面标题的主机。 services.http.response.html_title: dashboard ","date":"2022-08-19","objectID":"/censys%E6%96%87%E6%A1%A3/:2:15","tags":["censys"],"title":"Censys文档","uri":"/censys%E6%96%87%E6%A1%A3/"},{"categories":["tools"],"content":"具有响应服务器错误状态代码的 HTTP 服务的主机： services.http.response.status_code: 500 ","date":"2022-08-19","objectID":"/censys%E6%96%87%E6%A1%A3/:2:16","tags":["censys"],"title":"Censys文档","uri":"/censys%E6%96%87%E6%A1%A3/"},{"categories":["tools"],"content":"具有特定 HTTP 标头-值对的 HTTP 服务的主机： services.http.response.headers.connection: close AND services.http.response.headers.content_type: text/plain ","date":"2022-08-19","objectID":"/censys%E6%96%87%E6%A1%A3/:2:17","tags":["censys"],"title":"Censys文档","uri":"/censys%E6%96%87%E6%A1%A3/"},{"categories":["tools"],"content":"具有提供证书的 RDP 服务的主机： same_service(services.service_name: RDP AND services.certificate: *) ","date":"2022-08-19","objectID":"/censys%E6%96%87%E6%A1%A3/:2:18","tags":["censys"],"title":"Censys文档","uri":"/censys%E6%96%87%E6%A1%A3/"},{"categories":["tools"],"content":"具有任何运行SSLv3的服务的主机。 services.tls.version_selected: SSLv3 ","date":"2022-08-19","objectID":"/censys%E6%96%87%E6%A1%A3/:2:19","tags":["censys"],"title":"Censys文档","uri":"/censys%E6%96%87%E6%A1%A3/"},{"categories":["tools"],"content":"具有在 subject_dn 中提供带有字符串“localhost”的 TLS 证书的服务的主机： services.tls.certificates.leaf_data.subject_dn: \"localhost\" ","date":"2022-08-19","objectID":"/censys%E6%96%87%E6%A1%A3/:2:20","tags":["censys"],"title":"Censys文档","uri":"/censys%E6%96%87%E6%A1%A3/"},{"categories":["tools"],"content":"具有运行微软IIS 7.5的服务的主机。 services.software.product: IIS AND services.software.vendor: Microsoft AND services.software.version: 7.5 ","date":"2022-08-19","objectID":"/censys%E6%96%87%E6%A1%A3/:2:21","tags":["censys"],"title":"Censys文档","uri":"/censys%E6%96%87%E6%A1%A3/"},{"categories":["tools"],"content":"具有呈现操作系统和应用软件特定组合的服务的主机: same_service(services.software.uniform_resource_identifier: `cpe:2.3:o:canonical:ubuntu_linux:18.04:*:*:*:*:*:*:*` AND services.software.uniform_resource_identifier: `cpe:2.3:a:openbsd:openssh:7.6p1:*:*:*:*:*:*:*`) ","date":"2022-08-19","objectID":"/censys%E6%96%87%E6%A1%A3/:2:22","tags":["censys"],"title":"Censys文档","uri":"/censys%E6%96%87%E6%A1%A3/"},{"categories":["tools"],"content":"运行 Raspberry Pi 产品的主机: services.software.product: \"Raspberry Pi\" ","date":"2022-08-19","objectID":"/censys%E6%96%87%E6%A1%A3/:2:23","tags":["censys"],"title":"Censys文档","uri":"/censys%E6%96%87%E6%A1%A3/"},{"categories":["tools"],"content":"包含单词 University 的 ASes 中的主机： autonomous_system.description: University ","date":"2022-08-19","objectID":"/censys%E6%96%87%E6%A1%A3/:2:24","tags":["censys"],"title":"Censys文档","uri":"/censys%E6%96%87%E6%A1%A3/"},{"categories":["tools"],"content":"字段定义 https://search.censys.io/search/definitions?resource=hosts ","date":"2022-08-19","objectID":"/censys%E6%96%87%E6%A1%A3/:3:0","tags":["censys"],"title":"Censys文档","uri":"/censys%E6%96%87%E6%A1%A3/"},{"categories":["golang"],"content":"golang中用get()或httpClient 进行get时得到的静态页面, 如果页面中的内容是获取到本地后动态生成的话, 应该如何得到呢 ","date":"2022-08-18","objectID":"/golang%E8%8E%B7%E5%BE%97%E5%8A%A8%E6%80%81%E7%BD%91%E9%A1%B5%E5%86%85%E5%AE%B9/:0:0","tags":["http","crawler"],"title":"Golang获得动态网页内容","uri":"/golang%E8%8E%B7%E5%BE%97%E5%8A%A8%E6%80%81%E7%BD%91%E9%A1%B5%E5%86%85%E5%AE%B9/"},{"categories":["golang"],"content":"举例 有一些连接你通过http.get方法只能得到网页的一个框架, 其中并没有实质的查询结果, 和你通过浏览器直接访问得到的html是不一样的. 使用chromedp: https://github.com/chromedp/chromedp 通过chromedp.WaitVisible(selector),来等待动态生成的内容出现 其中 selector字符串通过浏览器的开发者控制台, 右击html, 选择 copy selector来得到 // GetHttpHtmlContent 获取网站上爬取的数据 func GetHttpHtmlContent(url string, selector string, sel interface{}) (string, error) { options := []chromedp.ExecAllocatorOption{ chromedp.Flag(\"headless\", true), // debug使用 chromedp.Flag(\"blink-settings\", \"imagesEnabled=false\"), chromedp.UserAgent(`Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36`), } //初始化参数，先传一个空的数据 options = append(chromedp.DefaultExecAllocatorOptions[:], options...) c, _ := chromedp.NewExecAllocator(context.Background(), options...) // create context chromeCtx, cancel := chromedp.NewContext(c, chromedp.WithLogf(log.Printf)) // 执行一个空task, 用提前创建Chrome实例 _ = chromedp.Run(chromeCtx, make([]chromedp.Action, 0, 1)...) //创建一个上下文，超时时间为40s 此时间可做更改 调整等待页面加载时间 timeoutCtx, cancel := context.WithTimeout(chromeCtx, 40*time.Second) defer cancel() var htmlContent string err := chromedp.Run(timeoutCtx, chromedp.Navigate(url), chromedp.WaitVisible(selector), chromedp.OuterHTML(sel, \u0026htmlContent, chromedp.ByJSPath), ) if err != nil { //log.Fatal(\"Run err : %v\\n\", err) return \"\", err } //log.Println(htmlContent) return htmlContent, nil } func main() { selector := \"#resultset \u003e div:nth-child(2)\" param := `document.querySelector(\"body\")` url := \"https://search.censys.io/search?resource=hosts\u0026virtual_hosts=EXCLUDE\u0026q=%28services.http.response.headers.location%3A+account.jetbrains.com%2Ffls-auth%29+and+services.port%3D%6080%60\" html, _ := GetHttpHtmlContent(url, selector, param) log.Println(html) } ","date":"2022-08-18","objectID":"/golang%E8%8E%B7%E5%BE%97%E5%8A%A8%E6%80%81%E7%BD%91%E9%A1%B5%E5%86%85%E5%AE%B9/:1:0","tags":["http","crawler"],"title":"Golang获得动态网页内容","uri":"/golang%E8%8E%B7%E5%BE%97%E5%8A%A8%E6%80%81%E7%BD%91%E9%A1%B5%E5%86%85%E5%AE%B9/"},{"categories":["golang"],"content":"更详细的 参考这个文章: https://segmentfault.com/a/1190000039349417 ","date":"2022-08-18","objectID":"/golang%E8%8E%B7%E5%BE%97%E5%8A%A8%E6%80%81%E7%BD%91%E9%A1%B5%E5%86%85%E5%AE%B9/:2:0","tags":["http","crawler"],"title":"Golang获得动态网页内容","uri":"/golang%E8%8E%B7%E5%BE%97%E5%8A%A8%E6%80%81%E7%BD%91%E9%A1%B5%E5%86%85%E5%AE%B9/"},{"categories":["aviation"],"content":"ARINC-429 定义了商用飞机航空电子系统之间(局域网)数字数据传输的标准要求和协议。设备制造商遵循这些标准，从而实现航空电子设备的互换性. ARINC 429 也称为 Mark 33 数字信息传输系统 (DITS) 总线。虽然主要用于航空电子领域，但这些总线也用于地面车辆、武器系统和其他商业和军事设备领域。 ","date":"2022-08-12","objectID":"/arinc429/:0:0","tags":["arinc429"],"title":"ARINC-429","uri":"/arinc429/"},{"categories":["aviation"],"content":"ARINC-429 文件组织结构 PART1 : 提供了ARINC 429功能的基本描述以及支持的物理和电气接口。还提供了数据字格式、标准标签和地址分配以及示例。 PART2: 定义了ARINC 429离散量字和按标签顺序的位分配。 PART3: 描述了ARINC 429数据传输协议和以大块和/或文件格式传输数据的消息定义。 PART4: 是多年来发表的ARINC 429第1部分补编（1至17）的档案。它是作为ARINC 429第18号补编更新的一部分而推出的（2012年）。 ","date":"2022-08-12","objectID":"/arinc429/:1:0","tags":["arinc429"],"title":"ARINC-429","uri":"/arinc429/"},{"categories":["aviation"],"content":"A429特点 ARINC 429 数据传输的独特之处在于其简单的单向总线通信数据流。虽然典型的数据总线在一组电线上的各个总线点之间提供多向数据传输。 ARINC-429 并非如此, 传说是为了系统可靠性。 ┌──────────┐ ┌─────────┐ ┌────────────┐ │RECEIVER_1│ │ ... │ │ RECEIVER_N │ └──────────┘ └─────────┘ └────────────┘ ┌─────────┐ ▲ ▲ ▲ │ SENDER │───────────┴────────────────┴──────────────────┘ └─────────┘ Sender可以支持最高20个Receiver 要想双向传输, 再添加一根线缆, Receiver变Sender Send和Receive通道在不同的端口上 以 32 位(bit)为一个数据字(WORD), 每个字代表一个工程单位，例如高度或气压 传输通道分为高速和低速两种, 前者100kb/s , 后者 12.5kb/s LRU 没有由 ARINC 429 分配的地址，而是一个设备 ID 号，允许设备管理和设备的文件传输被分组到系统中。 一个至少4位的空或零电压可以区分连续的字。通过使用字与字之间的空间隔，就不需要单独的时钟信号了。这就是为什么这个信号被称为自锁信号。 ","date":"2022-08-12","objectID":"/arinc429/:2:0","tags":["arinc429"],"title":"ARINC-429","uri":"/arinc429/"},{"categories":["aviation"],"content":"数据字结构 ┌──┬─────┬───────────────────────┬─────┬───────────────────────┐ │P │ SSM │ DATA │ SDI │ LABLE │ └──┴─────┴───────────────────────┴─────┴───────────────────────┘ ┌──┬──┬──┬──┬──┬──┬──┬──┬──┬──┬──┬──┬──┬──┬──┬──┬──┬──┬──┬──┬──┐ │32│31│30│29│28│27│..│14│13│12│11│10│9 │8 │7 │6 │5 │4 │3 │2 │1 │ └──┴──┴──┴──┴──┴──┴──┴──┴──┴──┴──┴──┴──┴──┴──┴──┴──┴──┴──┴──┴──┘ 数据以 32 位字通过 ARINC-429 总线发送，每个字代表一个工程单位，例如高度或气压。消息的不同部分如上图所示. LABEL: 8 位标签用于解释消息的其他字段——每种类型的设备都有一组由标签编号标识的标准参数，而与制造商无关。例如，任何航向参考系统的标签 372 将提供风向，任何空气数据计算机的标签 203 将提供气压高度, 312表示地面速度 SDI: 2位, 是源/目的地标识符 (Source Destination Identifiers)，由连接到多个接收器的发送器使用，以确定应由哪个接收器处理消息。如果不需要，这些位可以用于数据。 DATA: 19位数据 SSM: Sign-Status Matrix 符号状态矩阵 P: 奇偶校验位 : 使用奇数奇偶校验作为错误检查，以确保精确的数据接收。每个字中传输的逻辑1的数量是一个奇数，通过设置或清除第32位来获得奇数。ARINC 429没有规定纠错的方法，只规定了错误检测。 ","date":"2022-08-12","objectID":"/arinc429/:3:0","tags":["arinc429"],"title":"ARINC-429","uri":"/arinc429/"},{"categories":["aviation"],"content":"SSM 符号状态矩阵 根据LABEL的不同, SSM的意思可能不同, 比如可以表示错误状态 00 (0)：故障， 01 (1)：无计算数据或输出无效， 10 (2)：功能实验， 11 (3)：正常 #include \u003cstdio.h\u003e typedef unsigned int uint32_t; uint32_t getSSM(uint32_t x){ // 获取bit30和bit31的值 uint32_t ssm = (x \u003e\u003e 29) \u0026 0x3; return ssm; } uint32_t setSSM(uint32_t x, uint32_t ssm){ if (ssm \u003e 3) { printf(\"ssm is out of range, should be 0 or 1 or 2 or 3\\n\"); return x; } // 设置bit30和bit31的值 uint32_t mask = 0x3 \u003c\u003c 29; x = x \u0026 (~mask); x = x | (ssm \u003c\u003c 29); return x; } //打印出每一位 void print_bits(uint32_t x){ uint32_t i=0; for (i=0; i\u003c32; i++){ printf(\"%d\", (x \u0026 0x80000000) \u003e\u003e 31); x = x \u003c\u003c 1; } } int main(){ uint32_t x = 0x40012E92; print_bits(x); printf(\" ==\u003e %d\\n\", getSSM(x)); x = 0x60012E92; print_bits(x); printf(\" ==\u003e %d\\n\", getSSM(x)); x = 0x20012E92; print_bits(x); printf(\" ==\u003e %d\\n\", getSSM(x)); x = 0x12E92; print_bits(x); printf(\" ==\u003e %d\\n\", getSSM(x)); x = 0x1234; print_bits(setSSM(x, 0)); printf(\" \u003c== %d\\n\",0); print_bits(setSSM(x, 1)); printf(\" \u003c== %d\\n\",1); print_bits(setSSM(x, 2)); printf(\" \u003c== %d\\n\",2); print_bits(setSSM(x, 3)); printf(\" \u003c== %d\\n\",3); return 0; } 输出 01000000000000010010111010010010 ==\u003e 2 01100000000000010010111010010010 ==\u003e 3 00100000000000010010111010010010 ==\u003e 1 00000000000000010010111010010010 ==\u003e 0 00000000000000000001001000110100 \u003c== 0 00100000000000000001001000110100 \u003c== 1 01000000000000000001001000110100 \u003c== 2 01100000000000000001001000110100 \u003c== 3 ","date":"2022-08-12","objectID":"/arinc429/:4:0","tags":["arinc429"],"title":"ARINC-429","uri":"/arinc429/"},{"categories":["aviation"],"content":"奇数奇偶校验 ","date":"2022-08-12","objectID":"/arinc429/:5:0","tags":["arinc429"],"title":"ARINC-429","uri":"/arinc429/"},{"categories":["aviation"],"content":"设置校验位 A429采用的是奇校验 让整个32位中, 1的个数为奇数 初始值WORD的第32位为0 if WORD中1的个数为偶数 tempWORD = WORD 将tempWORD的第32位设置为1, 使其有奇数个1 return tempWORD typedef unsigned int uint32_t; // 获取位1的个数 int getBit1Count(uint32_t x){ uint32_t i=0, count = 0, temp = x; for (i=0; i\u003c32; i++){ if (1 == (temp \u0026 0x00000001) ){ count++; } temp = temp \u003e\u003e 1; } return count; } // 设置校验位 uint32_t setCheckBit(uint32_t x){ //如果为偶数个1 if (getBit1Count(x) % 2 == 0){ x = x ^ 0x80000000; // 0x80000000 = 10000000 00000000 00000000 00000000 }else{ x = x ^ 0x00000000; } return x; } ","date":"2022-08-12","objectID":"/arinc429/:5:1","tags":["arinc429"],"title":"ARINC-429","uri":"/arinc429/"},{"categories":["aviation"],"content":"校验和还原 校验就是看位上的值为1的个数是否为奇数 还原, 将第32位删除即可 //检查校验位并还原 uint32_t checkAndRestore(uint32_t x){ uint32_t bit1Count = getBit1Count(x); if (bit1Count % 2 == 0){ printf(\"错误! \"); return 0; }else{ //x = x ^ 0x80000000; printf(\"正确! \"); } //删掉最后一位校验位 x = x \u0026 0x7FFFFFFF; return x; } ","date":"2022-08-12","objectID":"/arinc429/:5:2","tags":["arinc429"],"title":"ARINC-429","uri":"/arinc429/"},{"categories":["aviation"],"content":"完整代码 #include \u003cstdio.h\u003e typedef unsigned int uint32_t; // 获取位1的个数 int getBit1Count(uint32_t x){ uint32_t i=0, count = 0, temp = x; for (i=0; i\u003c32; i++){ if (1 == (temp \u0026 0x00000001) ){ count++; } temp = temp \u003e\u003e 1; } return count; } // 设置校验位 uint32_t setCheckBit(uint32_t x){ //如果为偶数个1 if (getBit1Count(x) % 2 == 0){ x = x ^ 0x80000000; // 0x80000000 = 10000000 00000000 00000000 00000000 }else{ x = x ^ 0x00000000; } return x; } //打印出每一位 void print_bits(uint32_t x){ uint32_t i=0; for (i=0; i\u003c32; i++){ printf(\"%d\", (x \u0026 0x80000000) \u003e\u003e 31); x = x \u003c\u003c 1; } } //检查校验位并还原 uint32_t checkAndRestore(uint32_t x){ uint32_t bit1Count = getBit1Count(x); if (bit1Count % 2 == 0){ printf(\"错误! \"); return 0; }else{ //x = x ^ 0x80000000; printf(\"正确! \"); } //删掉最后一位校验位 x = x \u0026 0x7FFFFFFF; return x; } int main(){ uint32_t data[] = {0, 100, 101, 1001, 0x23456}; uint32_t i=0, set; for (i=0; i\u003c5; i++){ printf(\"设置校验位之前: \"); print_bits(data[i]); printf(\",%d个1, 0x%x\\n\", getBit1Count(data[i]), data[i]); set = setCheckBit(data[i]); printf(\"设置校验位之后: \"); print_bits(set); printf(\",%d个1, 0x%x\\n\",getBit1Count(set), set); printf(\"校验和还原:0x%x\\n\", checkAndRestore(set)); printf(\"-------\\n\"); } return 0; } 输出 设置校验位之前: 00000000000000000000000000000000,0个1, 0x0 设置校验位之后: 10000000000000000000000000000000,1个1, 0x80000000 正确! 校验和还原:0x0 ------- 设置校验位之前: 00000000000000000000000001100100,3个1, 0x64 设置校验位之后: 00000000000000000000000001100100,3个1, 0x64 正确! 校验和还原:0x64 ------- 设置校验位之前: 00000000000000000000000001100101,4个1, 0x65 设置校验位之后: 10000000000000000000000001100101,5个1, 0x80000065 正确! 校验和还原:0x65 ------- 设置校验位之前: 00000000000000000000001111101001,7个1, 0x3e9 设置校验位之后: 00000000000000000000001111101001,7个1, 0x3e9 正确! 校验和还原:0x3e9 ------- 设置校验位之前: 00000000000000100011010001010110,8个1, 0x23456 设置校验位之后: 10000000000000100011010001010110,9个1, 0x80023456 正确! 校验和还原:0x23456 ------- ","date":"2022-08-12","objectID":"/arinc429/:5:3","tags":["arinc429"],"title":"ARINC-429","uri":"/arinc429/"},{"categories":["aviation"],"content":"LABLE ┌────────────────────┬────────────────────┬─────────────┐ │ ones │ tens │ hundreds │ └────────────────────┴────────────────────┴─────────────┘ ┌──────┬──────┬──────┬──────┬──────┬──────┬──────┬──────┐ LSB │ 8 │ 7 │ 6 │ 5 │ 4 │ 3 │ 2 │ 1 │ MSB └──────┴──────┴──────┴──────┴──────┴──────┴──────┴──────┘ LSB: 最低有效位 MSB: 最高有效位 注意到, 上面的最低有效位和最高有效位 和我们平时定义的是相反的 并且, 8位被分成了三段, 百位数多为二进制11也就是3, 十位数和个位数最多为二进制111也就是7. 所以上面实际就是将8位分成3段, 每段来表示一个8进制数, 并且高低位相反. 这称为反向八进制 可以看出, Label最大为377 ","date":"2022-08-12","objectID":"/arinc429/:6:0","tags":["arinc429"],"title":"ARINC-429","uri":"/arinc429/"},{"categories":["aviation"],"content":"Label编码 举例: 312表示飞机的ground speed, 如何进行编码: 取百位数3, 用两位二进制表示为11, 调转高低位后为11 取十位数1, 用三位二进制表示为001, 调转高低位后为100 取个位数2, 用三位二进制表示为010,调转高低位后为010 ┌────────────────────┬────────────────────┬─────────────┐ │ ones │ tens │ hundreds │ ├────────────────────┼────────────────────┼─────────────┤ │ 2 │ 1 │ 3 │ ├──────┬──────┬──────┼──────┬──────┬──────┼──────┬──────┤ MSB │ 0 │ 1 │ 0 │ 1 │ 0 │ 0 │ 1 │ 1 │ LSB └──────┴──────┴──────┴──────┴──────┴──────┴──────┴──────┘ 对照ARINC429P1中的 ATTACHMENT 6中的值, 的确如此 #include \u003cstdio.h\u003e typedef unsigned int uint32_t; //打印出每一位 void print_bits(uint32_t x) { uint32_t i = 0; for (i = 0; i \u003c 32; i++) { printf(\"%d\", (x \u0026 0x80000000) \u003e\u003e 31); x = x \u003c\u003c 1; } } //翻转指定的数的指定位 //from: 从哪一位开始翻转(包括), 从低位开始, 从0开始计数 //to: 结束于哪一位(包括) // 比如 reverse_bits(1, 0, 2) // 将 00000000000000000000000000000001 中的 0,1,2位 进行翻转 // 得到 00000000000000000000000000000100 uint32_t reverse_bits(uint32_t x, uint32_t from, uint32_t to) { uint32_t result = 0; for (uint32_t i = from; i \u003c= to; i++) { result += (x \u003e\u003e i \u0026 1) \u003c\u003c (to - i); } return result; } uint32_t encodeLabel(uint32_t word, uint32_t x) { if (x \u003e 377) { printf(\"out of range\"); return 0; } //将word的前8位清零 word \u0026= 0xffffff00; //以x为312为例: //得到百位数3 (00000000000000000000000000000011) uint32_t hundreds = (x % 1000) / 100; //翻转0000000000000000000000000000011的低两位, //得到0000000000000000000000000000011 hundreds = reverse_bits(hundreds, 0, 1); //将 11 填入第0,1位 word = word | hundreds; //得到十位数1 (00000000000000000000000000000001) uint32_t tens = (x % 100) / 10; //翻转00000000000000000000000000000001的低三位, //得到00000000000000000000000000000100 tens = reverse_bits(tens, 0, 2); //将100填入第2,3,4位 word = word | (tens \u003c\u003c 2); //得到个位数2 (00000000000000000000000000000010) uint32_t ones = x % 10; //翻转00000000000000000000000000000010的低三位, //得到 00000000000000000000000000000010 ones = reverse_bits(ones, 0, 2); //将010填入第5,6,7位 word = word | (ones \u003c\u003c 5); return word; } int main() { print_bits(reverse_bits(0x4, 0, 2)); //100 -\u003e 001 printf(\"\\n\"); print_bits(reverse_bits(0x1, 0, 2)); //001 -\u003e 100 printf(\"\\n\"); print_bits(reverse_bits(0x1, 0, 31)); //1 -\u003e 10000000000000000000000000000000 printf(\"\\n------------\\n\"); uint32_t word = 0x22849800; print_bits(encodeLabel(word, 313)); printf(\"\\n\"); print_bits(encodeLabel(word, 323)); printf(\"\\n\"); return 0; } 输出 00000000000000000000000000000001 00000000000000000000000000000100 10000000000000000000000000000000 ------------ 00100010100001001001100011010011 00100010100001001001100011001011 ","date":"2022-08-12","objectID":"/arinc429/:6:1","tags":["arinc429"],"title":"ARINC-429","uri":"/arinc429/"},{"categories":["aviation"],"content":"Lable 解码 理解了编码, 解码就很简单了 uint32_t decodeLabel(uint32_t word) { //获取低8位 word \u0026= 0xff; //得到百位数 uint32_t hundreds = word \u0026 0x3; hundreds = reverse_bits(hundreds, 0, 1); //得到十位数 uint32_t tens = (word \u003e\u003e 2) \u0026 0x7; tens = reverse_bits(tens, 0, 2); //得到个位数 uint32_t ones = (word \u003e\u003e 5) \u0026 0x7; ones = reverse_bits(ones, 0, 2); return hundreds * 100 + tens * 10 + ones; } ","date":"2022-08-12","objectID":"/arinc429/:6:2","tags":["arinc429"],"title":"ARINC-429","uri":"/arinc429/"},{"categories":["aviation"],"content":"DATA ","date":"2022-08-12","objectID":"/arinc429/:7:0","tags":["arinc429"],"title":"ARINC-429","uri":"/arinc429/"},{"categories":["aviation"],"content":"可传输的数据类型 BNR 二进制补码小数 BCD 二进制编码十进制表示法 IOS5 IOS5编码的字母与数字 离散量 图形: 在地图和类似显示器上使用的线、圆、随机定位的字母/数字文本和其他符号。用于此目的的技术基本上类似于用于 ISO 5 字母/数字数据传输的技术。 ARINC Characteristic 744A：具有图形功能的全格式打印机提供了可以使用 ARINC 429 传输的附加信息和示例图形字符。 [TODO]… ","date":"2022-08-12","objectID":"/arinc429/:7:1","tags":["arinc429"],"title":"ARINC-429","uri":"/arinc429/"},{"categories":["Blockchain"],"content":"https://solidity-by-example.org 中的第二个练习, 并添加了注释 ","date":"2022-08-10","objectID":"/solidity-by-exampleex002firstapplication/:0:0","tags":["solidity"],"title":"[Solidity by Example]Ex002FirstApplication","uri":"/solidity-by-exampleex002firstapplication/"},{"categories":["Blockchain"],"content":"习题 https://solidity-by-example.org/first-app/ ","date":"2022-08-10","objectID":"/solidity-by-exampleex002firstapplication/:1:0","tags":["solidity"],"title":"[Solidity by Example]Ex002FirstApplication","uri":"/solidity-by-exampleex002firstapplication/"},{"categories":["Blockchain"],"content":"注释 // SPDX-License-Identifier: MIT pragma solidity ^0.8.0; contract Ex002FirstApplication { //1. // external - 外部函数是用来被其他合约调用的。它们不能用于内部调用。要在合约中调用外部函数，需要调用this.function_name()。状态变量不能被标记为外部变量。 // public - 公共函数/变量可以在外部和内部使用。对于公共状态变量，Solidity自动创建一个getter函数。 // internal - 内部函数/变量只能由内部或派生合约使用。 // private - 私有函数/变量只能在内部使用，甚至不能被派生合约使用。 //这个例子中有了get()函数, 可能count设置为private 或 internal 更恰当 //类型 参考这里 https://docs.soliditylang.org/en/v0.8.14/types.html // 或 https://solidity-cn.readthedocs.io/zh/develop/types.html uint public count; //2. // solidity 中函数可以用作变量赋值,参数传递等 // 函数分为内部/外部函数, 也就是external和internal, 默认是internal可以不写 // pure 不读数据, 也不写数据 不改变虚拟机状态 // view 读数据, 但不写数据 不改变虚拟机状态 // payable 支付, 写数据 改变虚拟机状态 // 参考这里 https://yinhui1984.github.io/对智能合约的读方法和写方法的调用/ function get() public view returns (uint){ return count; } //3. //与参数类型相比，返回类型不能为空——如果函数类型不应该返回任何内容，则整个返回 (\u003creturn types\u003e ) 部分必须省略。 //没有明确指明 pure view payable 则默认要改变虚拟机状态 function inc() public { count += 1; } function dec() public { count -= 1; } } ","date":"2022-08-10","objectID":"/solidity-by-exampleex002firstapplication/:2:0","tags":["solidity"],"title":"[Solidity by Example]Ex002FirstApplication","uri":"/solidity-by-exampleex002firstapplication/"},{"categories":["Blockchain"],"content":"合约调用 import Web3 from \"web3\" import net from \"net\" import * as fs from \"fs\" const web3 = new Web3(new Web3.providers.IpcProvider(\"../mychain/data/geth.ipc\", net)) const contractName = \"Ex002FirstApplication\" const abi = JSON.parse(fs.readFileSync(\"../contracts/build/\"+contractName+\".abi\").toString()) const address = fs.readFileSync(\"../contracts/\"+contractName+\".address\").toString() const contract = new web3.eth.Contract(abi,address) async function test(){ let accounts = await web3.eth.getAccounts() let account = accounts[0] await contract.methods.get().call().then(x =\u003e console.log(\"current value:\" + x)) //对inc调用call(), 并不会生效 await contract.methods.inc().call().then(()=\u003e{ contract.methods.get().call().then(x =\u003e console.log(\"after call inc(), current value:\" + x)) }) //对于改变状态机的函数, 要调用send() await contract.methods.inc().send({from:account, gas:3000000}).then(()=\u003e{ contract.methods.get().call().then(x =\u003e console.log(\"after send inc(), current value:\" + x)) }) //如果值为0,再调用inc()会报错 await contract.methods.dec().send({from:account, gas:3000000}).then(()=\u003e{ contract.methods.get().call().then(x =\u003e console.log(\"after send dec(), current value:\" + x)) }).catch(e =\u003e console.log(\"\\n\\ncatch an error : \\n \"+e)) return new Promise((resolve) =\u003e { setTimeout(()=\u003e{ resolve() } , 5000) }) } test().then(()=\u003e{ process.exit(0) }) ","date":"2022-08-10","objectID":"/solidity-by-exampleex002firstapplication/:3:0","tags":["solidity"],"title":"[Solidity by Example]Ex002FirstApplication","uri":"/solidity-by-exampleex002firstapplication/"},{"categories":["Blockchain"],"content":"输出 current value:0 after call inc(), current value:0 after send inc(), current value:1 after send dec(), current value:0 ","date":"2022-08-10","objectID":"/solidity-by-exampleex002firstapplication/:4:0","tags":["solidity"],"title":"[Solidity by Example]Ex002FirstApplication","uri":"/solidity-by-exampleex002firstapplication/"},{"categories":["Blockchain"],"content":"github https://github.com/yinhui1984/Explain-of-Solidity-by-Example ","date":"2022-08-10","objectID":"/solidity-by-exampleex002firstapplication/:5:0","tags":["solidity"],"title":"[Solidity by Example]Ex002FirstApplication","uri":"/solidity-by-exampleex002firstapplication/"},{"categories":["Blockchain"],"content":"https://solidity-by-example.org 中的第一个练习, 并添加了注释 ","date":"2022-08-10","objectID":"/solidity-by-exampleex001helloworld/:0:0","tags":["solidity"],"title":"[Solidity by Example]Ex001HelloWorld","uri":"/solidity-by-exampleex001helloworld/"},{"categories":["Blockchain"],"content":"习题: https://solidity-by-example.org/hello-world/ ","date":"2022-08-10","objectID":"/solidity-by-exampleex001helloworld/:1:0","tags":["solidity"],"title":"[Solidity by Example]Ex001HelloWorld","uri":"/solidity-by-exampleex001helloworld/"},{"categories":["Blockchain"],"content":"注释 // SPDX-License-Identifier: MIT pragma solidity ^0.8.0; //1. // 许可证标识符 SPDX-License-xxx: xxx // Solidity 0.6.8 引入了 SPDX 许可证标识符，因此开发人员可以指定合约使用的许可证 。 // 许可证列表参考这个表 https://spdx.org/licenses/ // 如果许可证标识符未包含在合约文件中，编译器现在将显示警告 // 如果包含了多个许可证标识符，编译器将报错 //2. // pragma solidity xxx // pragma solidity 用于指定合约的 Solidity 编译器版本 // 如果指定了不支持的 Solidity 版本，编译器将报错 // 如果指定了多个 Solidity 版本，编译器将报错 // 如果没有指定，则使用默认的 Solidity 版本 // pragma 指令始终位于源文件的本地，因此如果要在整个项目中启用它，则必须将 pragma 添加到所有文件中。 // 如果您导入另一个文件，该文件中的编译指示不会自动应用于导入文件。 // 例子: //pragma solidity 0.6.12 - 只用0.6.12版本的编译器编译 //pragma solidity ^0.6.12 - 大于等于0.6.12版本, 但小于0.7.0版本的编译器 //pragma solidity \u003e=0.4.0 \u003c0.6.0 - 在 大于等于0.4.0 和 小于0.6.0之间的编译器都可以 //3. // contract XXX // 合约声明, Solidity合约是一个代码（其功能）和数据（其状态）的集合。部署后其会驻留在区块链上的一个地址上. //4. // string public greet = \"Hello World!\"; 声明了一个字符串变量, 参考这里 https://www.tutorialspoint.com/solidity/solidity_strings.htm // external - 外部函数是用来被其他合约调用的。它们不能用于内部调用。要在合约中调用外部函数，需要调用this.function_name()。状态变量不能被标记为外部变量。 // public - 公共函数/变量可以在外部和内部使用。对于公共状态变量，Solidity自动创建一个getter函数。 // internal - 内部函数/变量只能由内部或派生合约使用。 // private - 私有函数/变量只能在内部使用，甚至不能被派生合约使用。 contract Ex001HelloWorld { string public greet = \"Hello World!\"; } ","date":"2022-08-10","objectID":"/solidity-by-exampleex001helloworld/:2:0","tags":["solidity"],"title":"[Solidity by Example]Ex001HelloWorld","uri":"/solidity-by-exampleex001helloworld/"},{"categories":["Blockchain"],"content":"合约调用 import Web3 from \"web3\"; import net from \"net\"; import * as fs from \"fs\"; const web3 = new Web3(new Web3.providers.IpcProvider(\"../mychain/data/geth.ipc\", net)); const contractName = \"Ex001HelloWorld\"; // read the contract abi from the file let abi = JSON.parse(fs.readFileSync(\"../contracts/build/\"+contractName+\".abi\").toString()); // read the contract address from the file const address = fs.readFileSync(\"../contracts/\"+contractName+\".address\").toString(); // create the contract object const contract = new web3.eth.Contract(abi, address); // get the value of the field \"greet\" contract.methods.greet.call().call().then((e) =\u003e { console.log(e); process.exit(0); }); ","date":"2022-08-10","objectID":"/solidity-by-exampleex001helloworld/:3:0","tags":["solidity"],"title":"[Solidity by Example]Ex001HelloWorld","uri":"/solidity-by-exampleex001helloworld/"},{"categories":["Blockchain"],"content":"Github https://github.com/yinhui1984/Explain-of-Solidity-by-Example ","date":"2022-08-10","objectID":"/solidity-by-exampleex001helloworld/:4:0","tags":["solidity"],"title":"[Solidity by Example]Ex001HelloWorld","uri":"/solidity-by-exampleex001helloworld/"},{"categories":["windows"],"content":"如何使用Visual Studio进行C++项目远程调试 这里说的是VS, 不是VS Code ","date":"2022-07-27","objectID":"/visutal-studio-%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95/:0:0","tags":["vs","vc++"],"title":"Visual Studio VC++ 远程调试","uri":"/visutal-studio-%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95/"},{"categories":["windows"],"content":"普通的实践 一般的思路是, 在远程机器上安装VS远程调试工具. 将调试文件拷贝到远程机器. 但这会带来一下问题 本地机器修改了代码,重新编译后需要重新拷贝到远程机器 如果将代码放在远程, 本机访问远程机器的共享文件夹进行编码, 然后编译. 会带来问题: 如果编译的项目稍大, 编译超慢. hotload更是没法用 ","date":"2022-07-27","objectID":"/visutal-studio-%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95/:1:0","tags":["vs","vc++"],"title":"Visual Studio VC++ 远程调试","uri":"/visutal-studio-%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95/"},{"categories":["windows"],"content":"最佳实践 思路: 本地机器共享文件夹, 远程机器公共访问共享文件夹来运行程序. 这样确保编译和运行在同一目录. 修改代码,编译,调试效率就会高很多. ","date":"2022-07-27","objectID":"/visutal-studio-%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95/:2:0","tags":["vs","vc++"],"title":"Visual Studio VC++ 远程调试","uri":"/visutal-studio-%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95/"},{"categories":["windows"],"content":"拷贝remote debuger 到VS的安装目录下拷贝remote debuger C:\\Program Files\\Microsoft Visual Studio xxx\\Common7\\IDE\\Remote Debugger 假设下面你的目录结构如下: ./to_debug ├── RemoteDebugger │ └── x64 │ └── msvsmon.exe └── my_code └── debug └── app.exe ","date":"2022-07-27","objectID":"/visutal-studio-%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95/:2:1","tags":["vs","vc++"],"title":"Visual Studio VC++ 远程调试","uri":"/visutal-studio-%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95/"},{"categories":["windows"],"content":"共享目录 将to_debug目录共享, 确保远程机器能访问改共享目录 假设本地ip为192.168.0.200 远程机器可以 \\\\192.168.0.200\\to_debug ","date":"2022-07-27","objectID":"/visutal-studio-%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95/:2:2","tags":["vs","vc++"],"title":"Visual Studio VC++ 远程调试","uri":"/visutal-studio-%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95/"},{"categories":["windows"],"content":"运行msvsmon.exe 在远程机器上访问共享文件夹, 然后运行msvsmon.exe 第一次运行时会弹窗, 把能勾上的全勾上.然后在设置中选择’无需授权验证’和’超时时间’设置为0 , 0表示不超时. 运行后, 会看到: MSvsoon启动了名为XXXX的新服务器 XXXX是服务器名称和端口, 等会儿会用到 ","date":"2022-07-27","objectID":"/visutal-studio-%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95/:2:3","tags":["vs","vc++"],"title":"Visual Studio VC++ 远程调试","uri":"/visutal-studio-%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95/"},{"categories":["windows"],"content":"配置项目 在VS解决方案资源管理器中, 右键用做启动项目的属性 配置属性 –\u003e 调试 –\u003e远程Windows调试器 配置: 远程命令: 在远程计算机上如何运行的你程序. 我们远程机器通过访问本地机器的共享目录来访问, 所以填写 \\\\192.168.0.200\\to_debug\\mycode\\debug\\app.exe 工作目录\\\\192.168.0.200\\to_debug\\mycode\\debug 远程服务名称: XXXX 就是上一步中的服务名称和端口, 例如 ADMIN-PC:4026 部署目录, 无需填写, 我们不需要部署和拷贝, 因为编译和运行本来就在同一目录 ","date":"2022-07-27","objectID":"/visutal-studio-%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95/:2:4","tags":["vs","vc++"],"title":"Visual Studio VC++ 远程调试","uri":"/visutal-studio-%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95/"},{"categories":["windows"],"content":"调试 平时我们调试时绿色箭头旁边选择的时本地调试器, 这里切换成远程Windows调试器 如果出现: 无法启动程序xxx。 被调用的对象已与其客户端断开连接。 则重启VS. ","date":"2022-07-27","objectID":"/visutal-studio-%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95/:2:5","tags":["vs","vc++"],"title":"Visual Studio VC++ 远程调试","uri":"/visutal-studio-%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95/"},{"categories":["golang"],"content":"go语言写的一个文件下载脚本 晚上想听点有声小说, 要两毛一集, 算了一下,一本书要几百块, 囊中羞涩, 于是拿出电脑搞个脚本 ","date":"2022-07-22","objectID":"/golang%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD/:0:0","tags":["http","crawler"],"title":"Golang文件下载","uri":"/golang%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD/"},{"categories":["golang"],"content":"单协程下载 package main import ( \"bufio\" \"io\" \"log\" \"net/http\" \"os\" ) func download(title string) { outputFile := \"./output/\" + title // if file exists, skip if _, err := os.Stat(outputFile); err == nil { log.Println(\"File exists, skip: \", outputFile) return } url := \"https://马赛克xxxx/牧神记/\" + title log.Println(\"Downloading: \", url) resp, err := http.Get(url) if err != nil { log.Println(\"error:\" + err.Error()) } defer func(Body io.ReadCloser) { err := Body.Close() if err != nil { log.Println(\"close body error:\" + err.Error()) } }(resp.Body) file, err := os.OpenFile(outputFile, os.O_CREATE|os.O_WRONLY, 0644) if err != nil { panic(err) } defer func(file *os.File) { err := file.Close() if err != nil { log.Println(\"close file error:\" + err.Error()) } }(file) _, err = io.Copy(file, resp.Body) if err != nil { log.Println(\"copy file error:\" + err.Error()) } //貌似不会封IP, 如果封ip可以使用 https://github.com/Python3WebSpider/ProxyPool //time.Sleep(time.Second * 3) } func main() { //mp3list.txt 从网站主页复制的小说每一集的标题列表 //0001_天黑别出门.mp3 //0002_四灵血.mp3 //0003_神通.mp3 //... //省略数千行 file, err := os.Open(\"mp3list.txt\") if err != nil { panic(err) } defer func(file *os.File) { _ = file.Close() }(file) //read file line by line scanner := bufio.NewScanner(file) for scanner.Scan() { title := scanner.Text() //download file download(title) } } ","date":"2022-07-22","objectID":"/golang%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD/:1:0","tags":["http","crawler"],"title":"Golang文件下载","uri":"/golang%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD/"},{"categories":["golang"],"content":"多协程下载 感觉单协程太慢, 20个协程同时下载多爽… golang实现起来超级简单 ","date":"2022-07-22","objectID":"/golang%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD/:2:0","tags":["http","crawler"],"title":"Golang文件下载","uri":"/golang%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD/"},{"categories":["golang"],"content":"golang chan 搞一个队列 var queue = make(chan int, 20) 下载前向队列里放一个元素 //download file queue \u003c- 1 go download(title) 队列最多放20个就会阻塞 下载完成或skip时就从队列中弹出 // if file exists, skip if _, err := os.Stat(outputFile); err == nil { log.Println(\"File exists, skip: \", outputFile) \u003c-queue return } //download finish \u003c-queue 队列为空时, 表示下载完成, 程序退出 for true { time.Sleep(time.Second * 2) //if queue is empty, exit if len(queue) == 0 { break } } ","date":"2022-07-22","objectID":"/golang%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD/:2:1","tags":["http","crawler"],"title":"Golang文件下载","uri":"/golang%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD/"},{"categories":["golang"],"content":"完整代码 package main import ( \"bufio\" \"io\" \"log\" \"net/http\" \"os\" \"time\" ) var queue = make(chan int, 20) func download(title string) { outputFile := \"./output/\" + title // if file exists, skip if _, err := os.Stat(outputFile); err == nil { log.Println(\"File exists, skip: \", outputFile) \u003c-queue return } url := \"https://马赛克xxxx/牧神记/\" + title log.Println(\"Downloading: \", url) resp, err := http.Get(url) if err != nil { log.Println(\"error:\" + err.Error()) } defer func(Body io.ReadCloser) { err := Body.Close() if err != nil { log.Println(\"close body error:\" + err.Error()) } }(resp.Body) file, err := os.OpenFile(outputFile, os.O_CREATE|os.O_WRONLY, 0644) if err != nil { panic(err) } defer func(file *os.File) { err := file.Close() if err != nil { log.Println(\"close file error:\" + err.Error()) } }(file) _, err = io.Copy(file, resp.Body) if err != nil { log.Println(\"copy file error:\" + err.Error()) } //貌似不会封IP, 如果封ip可以使用 https://github.com/Python3WebSpider/ProxyPool //time.Sleep(time.Second * 3) //download finish \u003c-queue } func main() { //open file mp3list.txt file, err := os.Open(\"mp3list.txt\") if err != nil { panic(err) } defer func(file *os.File) { _ = file.Close() }(file) //read file line by line scanner := bufio.NewScanner(file) for scanner.Scan() { title := scanner.Text() //download file queue \u003c- 1 go download(title) } for true { time.Sleep(time.Second * 2) //if queue is empty, exit if len(queue) == 0 { break } } } ","date":"2022-07-22","objectID":"/golang%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD/:2:2","tags":["http","crawler"],"title":"Golang文件下载","uri":"/golang%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD/"},{"categories":["golang"],"content":"代理池 我本次遇到的网站并没有WAF (Web Application Firewall), 所以可以狂下载 如果遇到被封IP的情况, 可以使用代理池: https://github.com/Python3WebSpider/ProxyPool ","date":"2022-07-22","objectID":"/golang%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD/:2:3","tags":["http","crawler"],"title":"Golang文件下载","uri":"/golang%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD/"},{"categories":["golang"],"content":"深入理解 欢迎阅读本博客中的 go语言中channel是如何工作的 ","date":"2022-07-22","objectID":"/golang%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD/:3:0","tags":["http","crawler"],"title":"Golang文件下载","uri":"/golang%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD/"},{"categories":["golang"],"content":"delve就是go语言的gdb delve就是go语言的gdb,虽然 gdb也可以调试go程序 (https://go.dev/doc/gdb). 但是, 用gdb调试go程序有这些已知问题: 已知问题 字符串pretty printing 只对字符串类型触发，而不是对其派生类型。 运行库的 C 部分缺少类型信息。 GDB 不理解 Go 的名称资格，并将 “fmt.Print “视为带有”. “的非结构化字面，需要加以引号。它对pkg.(*MyType).Meth形式的方法名反对得更厉害。 从Go 1.11开始，调试信息默认是压缩的。旧版本的gdb，例如MacOS上默认提供的版本，并不理解压缩。你可以使用go build -ldflags=-compressdwarf=false来生成未压缩的调试信息。(为了方便，你可以把-ldflags选项放在GOFLAGS环境变量中，这样你就不必每次都指定它)。 使用 delve https://github.com/go-delve/delve 更简单舒适 ","date":"2022-07-22","objectID":"/%E4%BD%BF%E7%94%A8delve%E5%AF%B9go%E4%BB%A3%E7%A0%81%E8%BF%9B%E8%A1%8C%E8%B0%83%E8%AF%95/:0:0","tags":["delev","gdb"],"title":"使用delve对go代码进行调试","uri":"/%E4%BD%BF%E7%94%A8delve%E5%AF%B9go%E4%BB%A3%E7%A0%81%E8%BF%9B%E8%A1%8C%E8%B0%83%E8%AF%95/"},{"categories":["golang"],"content":"首次安装 go install github.com/go-delve/delve/cmd/dlv@latest ","date":"2022-07-22","objectID":"/%E4%BD%BF%E7%94%A8delve%E5%AF%B9go%E4%BB%A3%E7%A0%81%E8%BF%9B%E8%A1%8C%E8%B0%83%E8%AF%95/:1:0","tags":["delev","gdb"],"title":"使用delve对go代码进行调试","uri":"/%E4%BD%BF%E7%94%A8delve%E5%AF%B9go%E4%BB%A3%E7%A0%81%E8%BF%9B%E8%A1%8C%E8%B0%83%E8%AF%95/"},{"categories":["golang"],"content":"基本使用 如果是调试主程序, cd到main.go所在目录, 运行 dlv debug 如果是调试测试代码, cd到*_test.go所在目录, 运行 dlv test 然后 和 gdb用法类似 break: 打断点 b packageName.functionName 或 b fileName:lineNumber 比如 b main.Add, b main.main continue: 开始执行或继续执行 c (开始执行也用c) next :执行下一行 n step: 单步进入 s stepout: 单步退出so print:打印 p thevar quit退出调试 q 更多的 https://github.com/go-delve/delve/blob/master/Documentation/cli/README.md ","date":"2022-07-22","objectID":"/%E4%BD%BF%E7%94%A8delve%E5%AF%B9go%E4%BB%A3%E7%A0%81%E8%BF%9B%E8%A1%8C%E8%B0%83%E8%AF%95/:2:0","tags":["delev","gdb"],"title":"使用delve对go代码进行调试","uri":"/%E4%BD%BF%E7%94%A8delve%E5%AF%B9go%E4%BB%A3%E7%A0%81%E8%BF%9B%E8%A1%8C%E8%B0%83%E8%AF%95/"},{"categories":["golang"],"content":"高级使用 dlv attach - 附加到正在运行的进程并开始调试。 dlv connect - 用终端客户端连接到headless debug server。 dlv core - 检查一个核心转储。 dlv dap - 启动一个通过调试适配器协议（DAP）通信的无头TCP服务器。 dlv debug - 编译并开始调试当前目录下的主包，或指定的包。 dlv exec - 执行一个预编译的二进制文件，并开始一个调试会话。 dlv replay - 回放一个rr跟踪。 dlv run - 废弃的命令。使用’debug’代替。 dlv test - 编译测试二进制文件并开始调试程序。 dlv trace - 编译并开始追踪程序。 dlv version - 打印版本。 dlv log - 关于记录标记的帮助 dlv backend - --backend flag的帮助 ","date":"2022-07-22","objectID":"/%E4%BD%BF%E7%94%A8delve%E5%AF%B9go%E4%BB%A3%E7%A0%81%E8%BF%9B%E8%A1%8C%E8%B0%83%E8%AF%95/:3:0","tags":["delev","gdb"],"title":"使用delve对go代码进行调试","uri":"/%E4%BD%BF%E7%94%A8delve%E5%AF%B9go%E4%BB%A3%E7%A0%81%E8%BF%9B%E8%A1%8C%E8%B0%83%E8%AF%95/"},{"categories":["golang"],"content":"一个简单的事件处理程序 demo目录结构 . ├── events │ └── event.go ├── go.mod └── main.go ","date":"2022-07-22","objectID":"/golang%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E4%BA%8B%E4%BB%B6%E5%A4%84%E7%90%86%E7%A8%8B%E5%BA%8F/:0:0","tags":["event"],"title":"Golang实现一个简单的事件处理程序","uri":"/golang%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E4%BA%8B%E4%BB%B6%E5%A4%84%E7%90%86%E7%A8%8B%E5%BA%8F/"},{"categories":["golang"],"content":"event.go package events type EventHandler func(event Event) type Event interface { GetName() string GetData() interface{} } type EventBus struct { handlers map[string]EventHandler } func NewEventBus() *EventBus { return \u0026EventBus{ handlers: make(map[string]EventHandler), } } func (bus *EventBus) Register(name string, handler EventHandler) { bus.handlers[name] = handler } func (bus *EventBus) Dispatch(event Event) { if handler, ok := bus.handlers[event.GetName()]; ok { handler(event) } } func (bus *EventBus) DispatchAsync(event Event) { go bus.Dispatch(event) } var defaultEventBus *EventBus = nil func init() { if defaultEventBus == nil { defaultEventBus = NewEventBus() } } func DefaultEventBus() *EventBus { return defaultEventBus } ","date":"2022-07-22","objectID":"/golang%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E4%BA%8B%E4%BB%B6%E5%A4%84%E7%90%86%E7%A8%8B%E5%BA%8F/:1:0","tags":["event"],"title":"Golang实现一个简单的事件处理程序","uri":"/golang%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E4%BA%8B%E4%BB%B6%E5%A4%84%E7%90%86%E7%A8%8B%E5%BA%8F/"},{"categories":["golang"],"content":"demo ","date":"2022-07-22","objectID":"/golang%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E4%BA%8B%E4%BB%B6%E5%A4%84%E7%90%86%E7%A8%8B%E5%BA%8F/:2:0","tags":["event"],"title":"Golang实现一个简单的事件处理程序","uri":"/golang%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E4%BA%8B%E4%BB%B6%E5%A4%84%E7%90%86%E7%A8%8B%E5%BA%8F/"},{"categories":["golang"],"content":"login.go 一个ticker事件 const TickEventName = \"TickerEvent\" type TickerEvent struct { } func (e TickerEvent) GetName() string { return TickEventName } func (e TickerEvent) GetData() interface{} { return time.Now() } ","date":"2022-07-22","objectID":"/golang%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E4%BA%8B%E4%BB%B6%E5%A4%84%E7%90%86%E7%A8%8B%E5%BA%8F/:2:1","tags":["event"],"title":"Golang实现一个简单的事件处理程序","uri":"/golang%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E4%BA%8B%E4%BB%B6%E5%A4%84%E7%90%86%E7%A8%8B%E5%BA%8F/"},{"categories":["golang"],"content":"main.go package main import ( \"fmt\" \"simpleEvent/events\" \"time\" ) const TickEventName = \"TickerEvent\" type TickerEvent struct { } func (e TickerEvent) GetName() string { return TickEventName } func (e TickerEvent) GetData() interface{} { return time.Now() } func makeEvents() { ticker := time.NewTicker(time.Second * 1) for true { \u003c-ticker.C //触发事件 events.DefaultEventBus().DispatchAsync(TickerEvent{}) } } func main() { go makeEvents() //监听事件 events.DefaultEventBus().Register(TickEventName, func(e events.Event) { fmt.Println(\"event received:\", e.GetData()) }) for true { time.Sleep(time.Second * 10) } } 输出: event received: 2022-08-08 11:22:48.61607 +0800 CST m=+1.000275696 event received: 2022-08-08 11:22:49.616192 +0800 CST m=+2.000391077 event received: 2022-08-08 11:22:50.616163 +0800 CST m=+3.000355464 event received: 2022-08-08 11:22:51.616159 +0800 CST m=+4.000344450 event received: 2022-08-08 11:22:52.616195 +0800 CST m=+5.000373565 ... ","date":"2022-07-22","objectID":"/golang%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E4%BA%8B%E4%BB%B6%E5%A4%84%E7%90%86%E7%A8%8B%E5%BA%8F/:2:2","tags":["event"],"title":"Golang实现一个简单的事件处理程序","uri":"/golang%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E4%BA%8B%E4%BB%B6%E5%A4%84%E7%90%86%E7%A8%8B%E5%BA%8F/"},{"categories":["windows"],"content":"如何让MFC窗体程序弹出命令行窗口并打印日志输出 习惯了linux上运行程序时在terminal中查看打印的日志. 但在MFC窗口程序中却不行. 折腾了一下, 结果如下 ","date":"2022-07-13","objectID":"/mfc%E7%AA%97%E4%BD%93%E7%A8%8B%E5%BA%8F%E5%BC%B9%E5%87%BA%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%AA%97%E5%8F%A3%E6%98%BE%E7%A4%BA%E6%97%A5%E5%BF%97%E8%BE%93%E5%87%BA/:0:0","tags":["vc++"],"title":"MFC窗体程序弹出命令行窗口显示日志输出","uri":"/mfc%E7%AA%97%E4%BD%93%E7%A8%8B%E5%BA%8F%E5%BC%B9%E5%87%BA%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%AA%97%E5%8F%A3%E6%98%BE%E7%A4%BA%E6%97%A5%E5%BF%97%E8%BE%93%E5%87%BA/"},{"categories":["windows"],"content":"弹出命令行窗口 在主程序的XXX::InitInstance()函数中添加 #ifdef _DEBUG if (!AllocConsole()) AfxMessageBox(\"Failed to create the console!\", MB_ICONEXCLAMATION); #endif 在对应的XXX::ExitInstance()中添加 #ifdef _DEBUG if (!FreeConsole()) AfxMessageBox(\"Could not free the console!\"); #endif 这样在DEBUG模式下启动程序时, 会弹出命令行窗口 ","date":"2022-07-13","objectID":"/mfc%E7%AA%97%E4%BD%93%E7%A8%8B%E5%BA%8F%E5%BC%B9%E5%87%BA%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%AA%97%E5%8F%A3%E6%98%BE%E7%A4%BA%E6%97%A5%E5%BF%97%E8%BE%93%E5%87%BA/:1:0","tags":["vc++"],"title":"MFC窗体程序弹出命令行窗口显示日志输出","uri":"/mfc%E7%AA%97%E4%BD%93%E7%A8%8B%E5%BA%8F%E5%BC%B9%E5%87%BA%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%AA%97%E5%8F%A3%E6%98%BE%E7%A4%BA%E6%97%A5%E5%BF%97%E8%BE%93%E5%87%BA/"},{"categories":["windows"],"content":"打印日志(含文件名, 代码行号) #define LOG2CONSOLE(X) \\ { \\ std::string file = __FILE__; \\ size_t index; \\ for (index = file.size()-1; index \u003e 0; index--) { \\ if (file[index] == '\\\\') break; \\ } \\ std::string fileName = file.substr(index + 1); \\ std::stringstream ss; \\ ss \u003c\u003c X; \\ std::string s = ss.str(); \\ _cprintf(\"%s:%i %s\\n\", fileName.c_str(), __LINE__, s.c_str()); \\ } 1, 注意要使用宏, 而不是函数, 否则代码文件名和代码行始终是定义的位置 2, 宏换行的话, 除了最后一个大括号, 每一行后面都要接一个 \\ ","date":"2022-07-13","objectID":"/mfc%E7%AA%97%E4%BD%93%E7%A8%8B%E5%BA%8F%E5%BC%B9%E5%87%BA%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%AA%97%E5%8F%A3%E6%98%BE%E7%A4%BA%E6%97%A5%E5%BF%97%E8%BE%93%E5%87%BA/:2:0","tags":["vc++"],"title":"MFC窗体程序弹出命令行窗口显示日志输出","uri":"/mfc%E7%AA%97%E4%BD%93%E7%A8%8B%E5%BA%8F%E5%BC%B9%E5%87%BA%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%AA%97%E5%8F%A3%E6%98%BE%E7%A4%BA%E6%97%A5%E5%BF%97%E8%BE%93%E5%87%BA/"},{"categories":["windows"],"content":"使用 LOG2CONSOLE(\"[Clicked] my button clicked. the xxx value is:\" \u003c\u003c something); ","date":"2022-07-13","objectID":"/mfc%E7%AA%97%E4%BD%93%E7%A8%8B%E5%BA%8F%E5%BC%B9%E5%87%BA%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%AA%97%E5%8F%A3%E6%98%BE%E7%A4%BA%E6%97%A5%E5%BF%97%E8%BE%93%E5%87%BA/:3:0","tags":["vc++"],"title":"MFC窗体程序弹出命令行窗口显示日志输出","uri":"/mfc%E7%AA%97%E4%BD%93%E7%A8%8B%E5%BA%8F%E5%BC%B9%E5%87%BA%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%AA%97%E5%8F%A3%E6%98%BE%E7%A4%BA%E6%97%A5%E5%BF%97%E8%BE%93%E5%87%BA/"},{"categories":["windows"],"content":"使用printf 上面的宏中使用的是 _cprintf, 我发现在某些时候, 即便输出的是ascii字符, 也会出现乱码. 改成printf又打印不出来, 为了让printf能打印出来, 修改: #ifdef _DEBUG if (!AllocConsole()) AfxMessageBox(\"Failed to create the console!\", MB_ICONEXCLAMATION); #endif 为 #ifdef _DEBUG AllocConsole(); //freopen(\"CONIN$\", \"r\", stdin); freopen(\"CONOUT$\", \"w\", stdout); freopen(\"CONOUT$\", \"w\", stderr); #endif ","date":"2022-07-13","objectID":"/mfc%E7%AA%97%E4%BD%93%E7%A8%8B%E5%BA%8F%E5%BC%B9%E5%87%BA%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%AA%97%E5%8F%A3%E6%98%BE%E7%A4%BA%E6%97%A5%E5%BF%97%E8%BE%93%E5%87%BA/:4:0","tags":["vc++"],"title":"MFC窗体程序弹出命令行窗口显示日志输出","uri":"/mfc%E7%AA%97%E4%BD%93%E7%A8%8B%E5%BA%8F%E5%BC%B9%E5%87%BA%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%AA%97%E5%8F%A3%E6%98%BE%E7%A4%BA%E6%97%A5%E5%BF%97%E8%BE%93%E5%87%BA/"},{"categories":["windows"],"content":"关于编译Windows MFC 项目遇到的Error : WINDOWS.H Already Included的解决方法 ","date":"2022-07-12","objectID":"/error--windows.h-already-included/:0:0","tags":["vc++"],"title":"Error : WINDOWS.H Already Included","uri":"/error--windows.h-already-included/"},{"categories":["windows"],"content":"现象 今天接到一个老旧的MFC项目, 安装windows虚拟机, VS2010 (真是老掉牙呀) , 最后编译时出现一堆如下报错: 1\u003e app.cpp 1\u003ec:\\program files (x86)\\microsoft visual studio 10.0\\vc\\atlmfc\\include\\afxv_w32.h(16): fatal error C1189: #error : WINDOWS.H already included. MFC apps must not #include \u003cwindows.h\u003e ","date":"2022-07-12","objectID":"/error--windows.h-already-included/:1:0","tags":["vc++"],"title":"Error : WINDOWS.H Already Included","uri":"/error--windows.h-already-included/"},{"categories":["windows"],"content":"解决方法 经过一番折腾, 直接说结论: #include “stdafx.h” 必须放在其他头文件之前 这涉及到一个很恶心的问题, 如果多个头文件层层include, 得耐心地慢慢调整顺序 ","date":"2022-07-12","objectID":"/error--windows.h-already-included/:2:0","tags":["vc++"],"title":"Error : WINDOWS.H Already Included","uri":"/error--windows.h-already-included/"},{"categories":["windows"],"content":"举例 比如 下面这个就会报错: //a.h #include \"b.h\" #include \"c.h\" //b.h #include \"xxx.h\" //c.h #include \"yyy.h\" #include \"stdafx.h\" 需要调整2处: 1, c.h 中 #include \"stdafx.h\" 需要放到 #include \"yyy.h\" 前面 2, a.h 中 #include \"c.h\" 需要放到 #include \"b.h\" 前面 最后这样: //a.h #include \"c.h\" #include \"b.h\" //b.h #include \"xxx.h\" //c.h #include \"stdafx.h\" #include \"yyy.h\" ","date":"2022-07-12","objectID":"/error--windows.h-already-included/:3:0","tags":["vc++"],"title":"Error : WINDOWS.H Already Included","uri":"/error--windows.h-already-included/"},{"categories":["Blockchain"],"content":"“如何达成共识\"是分布式系统的一个最基本的问题. 区块链作为一个分布式系统, 这也是最核心的问题. 共识算法很多, PoW、 BFT 、POS .. 以及的变体, 比如PBFT、 IBFT、Tendermint、DPoS、 HotStuff 等. 但作为区块链的鼻祖的BTC和元老的ETH都使用的PoW, ETH正在过度到PoS, 另外有一些区块链采用了PoS的一个变体DPoS.我们主要关注这几种. 今天先说说PoW ","date":"2022-07-08","objectID":"/pow/:0:0","tags":["pow","consensus"],"title":"PoW","uri":"/pow/"},{"categories":["Blockchain"],"content":"原理 PoW Proof of Work 工作量证明 在挖矿的时候通过作出\"一定的工作量\"来增加作恶成本. 其基本原理是通过一个简单但又费力的数学计算来体现工作量. 这样的数学计算有很多, 比如质因数分解, 计算hash等. ","date":"2022-07-08","objectID":"/pow/:1:0","tags":["pow","consensus"],"title":"PoW","uri":"/pow/"},{"categories":["Blockchain"],"content":"Hash 哈希函数用于为任意长的输入字符串创建固定长度的摘要,有各种系列的哈希函数，如MD、SHA1、SHA-2、SHA-3、RIPEMD和Whirlpool 特点: 哈希函数必须能够接受任何长度的输入文本，并输出一个固定长度的压缩信息. 哈希函数的计算速度非常快。如果消息太大，效率可能会下降，但该函数仍应足够快，以满足实际使用 哈希函数的输出必须的稳定的, 输入不变时输出也不会发生变化 哈希不能反向推导. 也就是说很难通过哈希值反向计算出原始值. 这个叫原像防御或者叫单向属性 不同的信息要得到不同的哈希值. 这叫抗碰撞性 实际上, 输入信息稍加改变, 输出的哈希值将会有很大的差异. 这叫 雪崩效应 我们一般使用的是 SHA-256 举例 OSX MP16 ~ ❯ echo \"this is a test\" | openssl dgst -sha256 91751cee0a1ab8414400238a761411daa29643ab4b8243e9a91649e25be53ada OSX MP16 ~ ❯ echo \"this is A test\" | openssl dgst -sha256 215ec5072f0ae6f05d9576d42c1a3fb5794aa51199cb44e7d087e679ff000d1 ","date":"2022-07-08","objectID":"/pow/:2:0","tags":["pow","consensus"],"title":"PoW","uri":"/pow/"},{"categories":["Blockchain"],"content":"Hash解密游戏 假设有这样一个游戏: 给定一个常量字符串str, 再加上一个可变数字num 得到 str+num, 通过不断变化num的值, 使得 hash(str+num)得到的哈希值满足一定的条件 就算成功. 假设我们需要满足的条件是: 哈希值以0000开头 func main() { str := \"this is a test string\" num := 0 for true { tempStr := str + strconv.Itoa(num) h := sha256.New() h.Write([]byte(tempStr)) sum := h.Sum(nil) s := hex.EncodeToString(sum) fmt.Println(\"try:\" + s) if s[0:4] == \"0000\" { fmt.Println(\"找到num: \", num) fmt.Println(\"找到hash: \", s) break } num++ } } 运行结果: try:2717e2d84df58353433bdef467f5f12766710aedc7114d409d04d6712b670edb try:a13b43128c8961d36d9f7aca7fd82018497d713e5305e86f1ba6c900e7870e61 try:5a968dcad3ab8564046abedff836a91242d77207b758f079865680b96e9e9b3a ... ... 找到num: 7521 找到hash: 0000e87f07402bc7592d63fc8876fc4685eb52649ceefa78915b33d7792be1f0 经过七千多次尝试, 找到了当num为7521时, 满足条件 ","date":"2022-07-08","objectID":"/pow/:3:0","tags":["pow","consensus"],"title":"PoW","uri":"/pow/"},{"categories":["Blockchain"],"content":"PoW 上面游戏中的给定字符串就算挖矿是的区块\"密封前\"的哈希值 ,包含前面的区块的哈希值和交易数据以及其它信息计算出来的哈希值, 但还没有成功挖矿,所以还没包含本区块的nonce等. 挖矿成功后, 会进行密封(Seal). 这里说的nonce也就是上面游戏中的num 游戏中还提到 一定的条件 , 在Pow中, 一定的条件就是找到的哈希值小于指定的 target , target是根据 难度 计算出来的. 所以我们可以得到这样一个简化版本的 PoW过程 package main import ( \"crypto/sha256\" \"fmt\" \"math/big\" \"strconv\" \"time\" ) func getTarget() *big.Int { //假设当前难度值 difficulty := 22341680 two256 := new(big.Int).Exp(big.NewInt(2), big.NewInt(256), big.NewInt(0)) return new(big.Int).Div(two256, big.NewInt(int64(difficulty))) } // getBlockHashBeforeSeal 获取区块在\"密封前\"的哈希值 func getBlockHashBeforeSeal() []byte { str := \"1312af178c253f84028d480a6adc1e25e81caa44c749ec81976192e2ec934c64\" //convert to bytes[] b := []byte(str) return b } func hash(s []byte) []byte { //使用sha256哈希函数 h := sha256.New() h.Write(s) sum := h.Sum(nil) return sum } func mine() uint64 { nonce := 0 target := getTarget() fmt.Println(\"target: \", target) powBuffer := new(big.Int) //旷工挖矿，需要进行暴力遍历 //通过不停地改变nonce以便让hash值变化，然后找到刚好满足一定条件的值 for true { var bytes = append(getBlockHashBeforeSeal(), strconv.Itoa(nonce)...) sum := hash(bytes) if powBuffer.SetBytes(sum).Cmp(target) \u003c 0 { fmt.Println(\"找到nonce: \", nonce) break } nonce++ } return uint64(nonce) } func verify(nonce uint64) bool { //对旷工挖矿得到的结果进行验证 //验证只需要进行一次计算 powBuffer := new(big.Int) target := getTarget() var bytes = append(getBlockHashBeforeSeal(), strconv.Itoa(int(nonce))...) sum := hash(bytes) return powBuffer.SetBytes(sum).Cmp(target) \u003c 0 } func main() { startTime := time.Now() nonce := mine() fmt.Println(\"计算耗时: \", time.Now().Sub(startTime)) ok := verify(nonce) fmt.Println(\"验证结果: \", ok) } ","date":"2022-07-08","objectID":"/pow/:4:0","tags":["pow","consensus"],"title":"PoW","uri":"/pow/"},{"categories":["Blockchain"],"content":"go-etherum go-etherum的PoW用到的算法名称叫 Ethash 其挖矿逻辑在 go-ethereum-1.10.20/consensus/ethash/sealer.go 中的 mine 方法 ","date":"2022-07-08","objectID":"/pow/:5:0","tags":["pow","consensus"],"title":"PoW","uri":"/pow/"},{"categories":["Blockchain"],"content":"对创世文件的介绍 在 https://yinhui1984.github.io/从零开始编写智能合约-手工打造/#编写创世文件中提到了genesis.json, 它是区块链的初始配置文件, 称为创世文件, 区块链中的第一个块(Block)需要用它来进行生成. 这个块称为创世块 ","date":"2022-07-06","objectID":"/genesis.json/:0:0","tags":["genesis.json"],"title":"genesis.json","uri":"/genesis.json/"},{"categories":["Blockchain"],"content":"Genesis struct 在go-ethereum中定义如下: //go-ethereum-1.10.20/params/config.go type Genesis struct { Config *params.ChainConfig `json:\"config\"` Nonce uint64 `json:\"nonce\"` Timestamp uint64 `json:\"timestamp\"` ExtraData []byte `json:\"extraData\"` GasLimit uint64 `json:\"gasLimit\" gencodec:\"required\"` Difficulty *big.Int `json:\"difficulty\" gencodec:\"required\"` Mixhash common.Hash `json:\"mixHash\"` Coinbase common.Address `json:\"coinbase\"` Alloc GenesisAlloc `json:\"alloc\" gencodec:\"required\"` // These fields are used for consensus tests. Please don't use them // in actual genesis blocks. Number uint64 `json:\"number\"` GasUsed uint64 `json:\"gasUsed\"` ParentHash common.Hash `json:\"parentHash\"` BaseFee *big.Int `json:\"baseFeePerGas\"` } 其中 Config字段: //go-ethereum-1.10.20/params/config.go // ChainConfig is the core config which determines the blockchain settings. // // ChainConfig is stored in the database on a per block basis. This means // that any network, identified by its genesis block, can have its own // set of configuration options. type ChainConfig struct { ChainID *big.Int `json:\"chainId\"` // chainId identifies the current chain and is used for replay protection HomesteadBlock *big.Int `json:\"homesteadBlock,omitempty\"` // Homestead switch block (nil = no fork, 0 = already homestead) DAOForkBlock *big.Int `json:\"daoForkBlock,omitempty\"` // TheDAO hard-fork switch block (nil = no fork) DAOForkSupport bool `json:\"daoForkSupport,omitempty\"` // Whether the nodes supports or opposes the DAO hard-fork // EIP150 implements the Gas price changes (https://github.com/ethereum/EIPs/issues/150) EIP150Block *big.Int `json:\"eip150Block,omitempty\"` // EIP150 HF block (nil = no fork) EIP150Hash common.Hash `json:\"eip150Hash,omitempty\"` // EIP150 HF hash (needed for header only clients as only gas pricing changed) EIP155Block *big.Int `json:\"eip155Block,omitempty\"` // EIP155 HF block EIP158Block *big.Int `json:\"eip158Block,omitempty\"` // EIP158 HF block ByzantiumBlock *big.Int `json:\"byzantiumBlock,omitempty\"` // Byzantium switch block (nil = no fork, 0 = already on byzantium) ConstantinopleBlock *big.Int `json:\"constantinopleBlock,omitempty\"` // Constantinople switch block (nil = no fork, 0 = already activated) PetersburgBlock *big.Int `json:\"petersburgBlock,omitempty\"` // Petersburg switch block (nil = same as Constantinople) IstanbulBlock *big.Int `json:\"istanbulBlock,omitempty\"` // Istanbul switch block (nil = no fork, 0 = already on istanbul) MuirGlacierBlock *big.Int `json:\"muirGlacierBlock,omitempty\"` // Eip-2384 (bomb delay) switch block (nil = no fork, 0 = already activated) BerlinBlock *big.Int `json:\"berlinBlock,omitempty\"` // Berlin switch block (nil = no fork, 0 = already on berlin) LondonBlock *big.Int `json:\"londonBlock,omitempty\"` // London switch block (nil = no fork, 0 = already on london) ArrowGlacierBlock *big.Int `json:\"arrowGlacierBlock,omitempty\"` // Eip-4345 (bomb delay) switch block (nil = no fork, 0 = already activated) GrayGlacierBlock *big.Int `json:\"grayGlacierBlock,omitempty\"` // Eip-5133 (bomb delay) switch block (nil = no fork, 0 = already activated) MergeNetsplitBlock *big.Int `json:\"mergeNetsplitBlock,omitempty\"` // Virtual fork after The Merge to use as a network splitter // TerminalTotalDifficulty is the amount of total difficulty reached by // the network that triggers the consensus upgrade. TerminalTotalDifficulty *big.Int `json:\"terminalTotalDifficulty,omitempty\"` // Various consensus engines Ethash *EthashConfig `json:\"ethash,omitempty\"` Clique *CliqueConfig `json:\"clique,omitempty\"` } ","date":"2022-07-06","objectID":"/genesis.json/:1:0","tags":["genesis.json"],"title":"genesis.json","uri":"/genesis.json/"},{"categories":["Blockchain"],"content":"ChainID 区块链ID, 每一个对外公开的链ID是唯一的, 这个ID可以在https://chainlist.org上进行查询和申请 之所以加这样一个ChainID是为了防止\"重放攻击\":是在一个区块链上进行交易，并恶意或欺诈性地在另一个区块链上重复该交易. 参考这里EIP155 或这里 EIP : Ethereum Improvement Proposals 以太坊改进提案 ","date":"2022-07-06","objectID":"/genesis.json/:1:1","tags":["genesis.json"],"title":"genesis.json","uri":"/genesis.json/"},{"categories":["Blockchain"],"content":"HomesteadBlock HomesteadBlock 以及后面的各种xxxBlock都是指的是ETH的硬分叉高度. 关于分叉,参考这里 这里可以看到主网的分叉历史 : https://ethereum.org/en/history/ 对于新建测试网而言, 应该设置为0 , 表示你没有分叉 ","date":"2022-07-06","objectID":"/genesis.json/:1:2","tags":["genesis.json"],"title":"genesis.json","uri":"/genesis.json/"},{"categories":["Blockchain"],"content":"TerminalTotalDifficulty TTD, 终端总难度, 网络达到的总难度 最近提到TTD的一个新闻是ETH将在Ropsten测试网的TTD达到一个值时触发链上合并, 以将其POW(工作量证明)升级为POS(权益证明, proof-of-stake) ","date":"2022-07-06","objectID":"/genesis.json/:1:3","tags":["genesis.json"],"title":"genesis.json","uri":"/genesis.json/"},{"categories":["Blockchain"],"content":"Ethash Ethash是Ethereum使用的POW算法。这是目前主网使用的算法. 具体参考 https://ethereum.org/en/developers/docs/consensus-mechanisms/pow/mining-algorithms/ 和 https://ethereum.org/en/developers/docs/consensus-mechanisms/pow/mining-algorithms/ethash/ 以及 https://ethereum.stackexchange.com/questions/14/what-proof-of-work-function-does-ethereum-use ","date":"2022-07-06","objectID":"/genesis.json/:1:4","tags":["genesis.json"],"title":"genesis.json","uri":"/genesis.json/"},{"categories":["Blockchain"],"content":"Clique Clique [/kliːk/] 是测试网使用的权益证明POS 算法, 主网一直在努力尽快切换到POS 具体参考这里 https://ethereum.org/en/developers/docs/consensus-mechanisms/pos/ ","date":"2022-07-06","objectID":"/genesis.json/:1:5","tags":["genesis.json"],"title":"genesis.json","uri":"/genesis.json/"},{"categories":["Blockchain"],"content":"Nonce 和 Mixhash Nonce是一个64位的哈希值, mixhash字段包含一个256位的哈希值，一旦与nonce结合，就可以用来证明为了创建这个区块，已经花费了足够的算力. 后面搞篇博客专门来讲工作量证明 ","date":"2022-07-06","objectID":"/genesis.json/:1:6","tags":["genesis.json"],"title":"genesis.json","uri":"/genesis.json/"},{"categories":["Blockchain"],"content":"Timestamp Unix时间戳 。利用块与块之间的时间戳来调整难度, 以保证出块时间的稳定性. 最后两个块之间的较小周期导致难度级别增加，因此需要额外的计算来找到下一个有效块。如果周期太大，则难度和下一个区块的预期时间会降低。时间戳还允许验证链中块的顺序. ","date":"2022-07-06","objectID":"/genesis.json/:1:7","tags":["genesis.json"],"title":"genesis.json","uri":"/genesis.json/"},{"categories":["Blockchain"],"content":"ExtraData 额外数据. 想写入区块链的任意数据, 但只有32 个字节 ","date":"2022-07-06","objectID":"/genesis.json/:1:8","tags":["genesis.json"],"title":"genesis.json","uri":"/genesis.json/"},{"categories":["Blockchain"],"content":"GasLimit 每个区块的Gas支出限额 ","date":"2022-07-06","objectID":"/genesis.json/:1:9","tags":["genesis.json"],"title":"genesis.json","uri":"/genesis.json/"},{"categories":["Blockchain"],"content":"Difficulty 难度. 它代表了证明PoW所需的哈希值的难度等级。 它定义了挖矿目标，可以根据前一个区块的难度级别和时间戳来计算。难度越高，矿工为了发现有效区块必须执行的统计计算就越多。该值用于控制区块链的出块时间，使出块频率保持在目标范围内 ","date":"2022-07-06","objectID":"/genesis.json/:1:10","tags":["genesis.json"],"title":"genesis.json","uri":"/genesis.json/"},{"categories":["Blockchain"],"content":"Coinbase 这是一个160位的地址，挖矿成功后，挖矿奖励就会发送到这里。 有些地方称之为 Etherbase, 比如 miner.setEtherbase(personal.listAccounts[0]) ","date":"2022-07-06","objectID":"/genesis.json/:1:11","tags":["genesis.json"],"title":"genesis.json","uri":"/genesis.json/"},{"categories":["Blockchain"],"content":"alloc 这个参数包含预先分配的钱包和余额列表. 初始化区块链的时候, 这个参数必须被填写, 否则没钱支付挖矿费用, 产生不了块. ","date":"2022-07-06","objectID":"/genesis.json/:1:12","tags":["genesis.json"],"title":"genesis.json","uri":"/genesis.json/"},{"categories":["Blockchain"],"content":"Number, GasUsed, ParentHash, BaseFee // These fields are used for consensus tests. Please don't use them // in actual genesis blocks. ","date":"2022-07-06","objectID":"/genesis.json/:1:13","tags":["genesis.json"],"title":"genesis.json","uri":"/genesis.json/"},{"categories":["Blockchain"],"content":"介绍了调用智能合约中\"读方法\"与\"写方法\"的区别 ","date":"2022-07-04","objectID":"/%E5%AF%B9%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6%E7%9A%84%E8%AF%BB%E6%96%B9%E6%B3%95%E5%92%8C%E5%86%99%E6%96%B9%E6%B3%95%E7%9A%84%E8%B0%83%E7%94%A8/:0:0","tags":["web3.py","web3.js"],"title":"对智能合约的读方法和写方法的调用","uri":"/%E5%AF%B9%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6%E7%9A%84%E8%AF%BB%E6%96%B9%E6%B3%95%E5%92%8C%E5%86%99%E6%96%B9%E6%B3%95%E7%9A%84%E8%B0%83%E7%94%A8/"},{"categories":["Blockchain"],"content":"方法(函数)的分类 智能合约中的方法可以粗暴的分为两类: 不会改变虚拟机状态的方法 会改变虚拟机状态的方法 假设我们将他们称为\"读方法\"和\"写方法\", 那么读方法而言, 其是不会创建交易和花费GAS的, 是免费的. 对于写方法而言, 需要收取’手续费’进行挖矿的. 关键字 描述 改变虚拟机状态? pure 不读数据, 也不写数据 NO view 读数据, 但不写数据 NO payable 支付以太, 肯定写数据 YES 未明确指示的 其它可能写数据的 YES ","date":"2022-07-04","objectID":"/%E5%AF%B9%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6%E7%9A%84%E8%AF%BB%E6%96%B9%E6%B3%95%E5%92%8C%E5%86%99%E6%96%B9%E6%B3%95%E7%9A%84%E8%B0%83%E7%94%A8/:1:0","tags":["web3.py","web3.js"],"title":"对智能合约的读方法和写方法的调用","uri":"/%E5%AF%B9%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6%E7%9A%84%E8%AF%BB%E6%96%B9%E6%B3%95%E5%92%8C%E5%86%99%E6%96%B9%E6%B3%95%E7%9A%84%E8%B0%83%E7%94%A8/"},{"categories":["Blockchain"],"content":"Web3.js的 call() 与Send() 对于上面两类方法, Web3.js中分别对应Call方法和Send方法来进行调用 创建交易 改变虚拟机状态 Call() NO NO Send() YES YES 实际上从语法层面上而言, 无论是读方法还是写方法, 都可以调用 call , 但对于写方法, 调用call虚拟机状态并不会改变, 并且不会报错. ","date":"2022-07-04","objectID":"/%E5%AF%B9%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6%E7%9A%84%E8%AF%BB%E6%96%B9%E6%B3%95%E5%92%8C%E5%86%99%E6%96%B9%E6%B3%95%E7%9A%84%E8%B0%83%E7%94%A8/:2:0","tags":["web3.py","web3.js"],"title":"对智能合约的读方法和写方法的调用","uri":"/%E5%AF%B9%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6%E7%9A%84%E8%AF%BB%E6%96%B9%E6%B3%95%E5%92%8C%E5%86%99%E6%96%B9%E6%B3%95%E7%9A%84%E8%B0%83%E7%94%A8/"},{"categories":["Blockchain"],"content":"举例 // SPDX-License-Identifier: MIT pragma solidity ^0.8.0; contract temp { int private counter; function add() public { counter ++; } function get() public view returns(int){ return counter; } } 调用代码 const base = require('./base'); const c = base.initContract('temp'); async function test(){ await c.methods.get().call().then(x=\u003e{ console.log(\"current value:\", x); }) await c.methods.add().call() await c.methods.get().call().then(x=\u003e{ console.log(\"after call add(): current value:\", x); }) let accounts = await base.web3Instance.eth.getAccounts(); await c.methods.add().send({from: accounts[0], gas: 3000000}) await c.methods.get().call().then(x=\u003e{ console.log(\"after send add(): current value:\", x); }) } test() 输出 current value: 0 after call add(): current value: 0 after send add(): current value: 1 可以看到使用 call 调用 add()后 值并没有变, 而用 send调用add()后, 值被累加1 ","date":"2022-07-04","objectID":"/%E5%AF%B9%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6%E7%9A%84%E8%AF%BB%E6%96%B9%E6%B3%95%E5%92%8C%E5%86%99%E6%96%B9%E6%B3%95%E7%9A%84%E8%B0%83%E7%94%A8/:3:0","tags":["web3.py","web3.js"],"title":"对智能合约的读方法和写方法的调用","uri":"/%E5%AF%B9%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6%E7%9A%84%E8%AF%BB%E6%96%B9%E6%B3%95%E5%92%8C%E5%86%99%E6%96%B9%E6%B3%95%E7%9A%84%E8%B0%83%E7%94%A8/"},{"categories":["Blockchain"],"content":"web3.py web3.py 中对应的是 call()和transact() ","date":"2022-07-04","objectID":"/%E5%AF%B9%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6%E7%9A%84%E8%AF%BB%E6%96%B9%E6%B3%95%E5%92%8C%E5%86%99%E6%96%B9%E6%B3%95%E7%9A%84%E8%B0%83%E7%94%A8/:4:0","tags":["web3.py","web3.js"],"title":"对智能合约的读方法和写方法的调用","uri":"/%E5%AF%B9%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6%E7%9A%84%E8%AF%BB%E6%96%B9%E6%B3%95%E5%92%8C%E5%86%99%E6%96%B9%E6%B3%95%E7%9A%84%E8%B0%83%E7%94%A8/"},{"categories":["Blockchain"],"content":"让自己使用geth运行的区块链像Ganche一样可以AUTOMINING 在做智能合约开发过程中, 如果使用Ganche的话, 可以发现其有一个非常爽的功能:AUTOMINING 自动挖矿 或按需挖矿, 也就是说不需要挖矿的时候就别挖, 否则非常耗电脑资源. 如果我们是自己使用geth运行的测试链, 则没有这个功能, 需要手动attach到控制台进行miner.start()和miner.stop, 非常不方便. ","date":"2022-07-03","objectID":"/%E4%BD%BF%E7%94%A8web3.py%E5%AE%9E%E7%8E%B0%E5%8C%BA%E5%9D%97%E9%93%BE%E6%8C%89%E9%9C%80%E6%8C%96%E7%9F%BF/:0:0","tags":["web3.py","python"],"title":"使用web3.py实现区块链按需挖矿","uri":"/%E4%BD%BF%E7%94%A8web3.py%E5%AE%9E%E7%8E%B0%E5%8C%BA%E5%9D%97%E9%93%BE%E6%8C%89%E9%9C%80%E6%8C%96%E7%9F%BF/"},{"categories":["Blockchain"],"content":"Web3.js 如果使用Web3.js,貌似没有看到miner控制的API, 不过Gitub上有一个扩展, 可以实现 https://github.com/DecentricCorp/web3admin 利用这个扩展可以实现我们想要的功能. ","date":"2022-07-03","objectID":"/%E4%BD%BF%E7%94%A8web3.py%E5%AE%9E%E7%8E%B0%E5%8C%BA%E5%9D%97%E9%93%BE%E6%8C%89%E9%9C%80%E6%8C%96%E7%9F%BF/:1:0","tags":["web3.py","python"],"title":"使用web3.py实现区块链按需挖矿","uri":"/%E4%BD%BF%E7%94%A8web3.py%E5%AE%9E%E7%8E%B0%E5%8C%BA%E5%9D%97%E9%93%BE%E6%8C%89%E9%9C%80%E6%8C%96%E7%9F%BF/"},{"categories":["Blockchain"],"content":"Web3.py Web3.py自带miner控制的API, 这就比较方便了. 每隔几秒轮询一下是否有pending的block, 如果有则挖, 否则停止挖矿 脚本如下 #!/usr/bin/env python3 import os import time from web3 import Web3 # pip3 install web3 # 按需挖矿 #使用前请先修改provide w3 = Web3(Web3.IPCProvider('../mychain/data/geth.ipc')) num_threads = os.cpu_count() def main(): # kill this script os.system(\"killall -9 python \u003e /dev/null 2\u003e\u00261\") print('Connected to Ethereum client: %s' % w3.clientVersion) print(\"启动自动挖矿...\") while True: time.sleep(3) if w3.eth.getBlock('pending').transactions: print( time.strftime(\"%H:%M:%S\", time.localtime()) + \":Mining for pending transactions: %s\" % w3.eth.getBlock( 'pending').transactions) w3.geth.miner.start(num_threads) else: print(time.strftime(\"%H:%M:%S\", time.localtime()) + ':No pending transactions, sleeping...', end='\\r') w3.geth.miner.stop() if __name__ == \"__main__\": try: main() except KeyboardInterrupt: print(\"\\n\\nCtrl+C, bye!\") w3.geth.miner.stop() exit(0) except Exception as e: print(\"发生错误: %s\" % e) exit(0) 运行时的样子 Connected to Ethereum client: Geth/v1.10.16-stable/darwin-amd64/go1.17.6 启动自动挖矿... 13:24:42:Mining for pending transactions: [HexBytes('0x0cecdc430a73adc915d9944798e71735a48940b90e38965a3e4a5c8db6b48cb5')] 13:24:57:No pending transactions, sleeping... ","date":"2022-07-03","objectID":"/%E4%BD%BF%E7%94%A8web3.py%E5%AE%9E%E7%8E%B0%E5%8C%BA%E5%9D%97%E9%93%BE%E6%8C%89%E9%9C%80%E6%8C%96%E7%9F%BF/:2:0","tags":["web3.py","python"],"title":"使用web3.py实现区块链按需挖矿","uri":"/%E4%BD%BF%E7%94%A8web3.py%E5%AE%9E%E7%8E%B0%E5%8C%BA%E5%9D%97%E9%93%BE%E6%8C%89%E9%9C%80%E6%8C%96%E7%9F%BF/"},{"categories":["Blockchain"],"content":"前面在 从零开始编写智能合约-使用traffle套件 中 使用 truffle套件从零开始搭建环境, 编写、部署、测试和调用智能合约, 这次我们只使用一些命令行工具来进行\"手工打造\" 配套代码: https://github.com/yinhui1984/stepByStepSmartContract ","date":"2022-07-01","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E6%89%8B%E5%B7%A5%E6%89%93%E9%80%A0/:0:0","tags":["solidity","ethereum","go-ethereum","python"],"title":"从零开始编写智能合约-手工打造","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E6%89%8B%E5%B7%A5%E6%89%93%E9%80%A0/"},{"categories":["Blockchain"],"content":"创建测试链 还是以ETH为例, 使用 Go Ethereum https://geth.ethereum.org 来创建 使用POW共识算法的一个简单私有链. ","date":"2022-07-01","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E6%89%8B%E5%B7%A5%E6%89%93%E9%80%A0/:1:0","tags":["solidity","ethereum","go-ethereum","python"],"title":"从零开始编写智能合约-手工打造","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E6%89%8B%E5%B7%A5%E6%89%93%E9%80%A0/"},{"categories":["Blockchain"],"content":"安装geth 官方教程 https://geth.ethereum.org/docs/install-and-build/installing-geth 或者自己下载安装包进行安装 https://geth.ethereum.org/downloads/ 安装完成后, 运行一下version表示成功 OSX MP16 ~/Downloads/privateNetwork ❯ geth version Geth Version: 1.10.16-stable Architecture: amd64 Go Version: go1.17.6 Operating System: darwin GOPATH= GOROOT=go ","date":"2022-07-01","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E6%89%8B%E5%B7%A5%E6%89%93%E9%80%A0/:1:1","tags":["solidity","ethereum","go-ethereum","python"],"title":"从零开始编写智能合约-手工打造","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E6%89%8B%E5%B7%A5%E6%89%93%E9%80%A0/"},{"categories":["Blockchain"],"content":"创建一个账户 下面的创世文件中的coinbase会用到这个账户, 用来接收挖矿的收入 为方便起见, 将账户密码写到password.txt , 当然这是不安全的行为. echo 123456 \u003e password.txt 新建账户: geth --datadir ./data/ account new --password ./password.txt 其中的datadir是数据存储目录, 后面的数据文件都将存到这个目录中 OSX MP16 ~/Downloads/privateNetwork ❯ geth --datadir ./data/ account new --password ./password.txt INFO [07-01|10:10:34.007] Maximum peer count ETH=50 LES=0 total=50 Your new key was generated Public address of the key: 0x79dF0D3c23f22370881dC92aF524A1D5E52e3552 Path of the secret key file: data/keystore/UTC--2022-07-01T02-10-34.008109000Z--79df0d3c23f22370881dc92af524a1d5e52e3552 - You can share your public address with anyone. Others need it to interact with you. - You must NEVER share the secret key with anyone! The key controls access to your funds! - You must BACKUP your key file! Without the key, it's impossible to access account funds! - You must REMEMBER your password! Without the password, it's impossible to decrypt the key! 打印内容中的 0x79dF0D3c23f22370881dC92aF524A1D5E52e3552是公钥, 也是我们的账户地址 ","date":"2022-07-01","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E6%89%8B%E5%B7%A5%E6%89%93%E9%80%A0/:1:2","tags":["solidity","ethereum","go-ethereum","python"],"title":"从零开始编写智能合约-手工打造","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E6%89%8B%E5%B7%A5%E6%89%93%E9%80%A0/"},{"categories":["Blockchain"],"content":"找一个网络ID chainId或者network ID 用于隔离以太坊对等网络。只有当两个对等点使用相同的创世块和网络 ID 时，区块链节点之间才会发生连接。使用 –networkid 命令行选项设置 geth 使用的网络 ID。 以太网主网 ID 为 1。如果您提供与主网不同的自定义网络 ID，您的节点将不会连接到其他节点并形成专用网络。如果您打算在 Internet 上连接到您的私有链，最好选择一个尚未使用的网络 ID。您可以在 https://chainid.network 找到由社区运行的以太坊网络注册表。 这里我们只是在本地运行, 随便使用一个ID就可以了, 比如1235 ","date":"2022-07-01","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E6%89%8B%E5%B7%A5%E6%89%93%E9%80%A0/:1:3","tags":["solidity","ethereum","go-ethereum","python"],"title":"从零开始编写智能合约-手工打造","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E6%89%8B%E5%B7%A5%E6%89%93%E9%80%A0/"},{"categories":["Blockchain"],"content":"编写\"创世文件\" 一个新的区块链在生成第一个区块, 也就是创世块的时候, 需要从创世文件来进行生成 touch genesis.json { \"nonce\": \"0x0000000000000042\", \"timestamp\": \"0x00\", \"parentHash\": \"0x0000000000000000000000000000000000000000000000000000000000000000\", \"extraData\": \"0x00\", \"gasLimit\": \"0x8000000\", \"difficulty\": \"0x0400\", \"mixhash\": \"0x0000000000000000000000000000000000000000000000000000000000000000\", \"coinbase\": \"0x79dF0D3c23f22370881dC92aF524A1D5E52e3552\", \"alloc\": { \"0x79dF0D3c23f22370881dC92aF524A1D5E52e3552\": { \"balance\": \"1000000000000000000000\" } }, \"config\": { \"chainId\": 1235, \"homesteadBlock\": 0, \"byzantiumBlock\": 0, \"constantinopleBlock\": 0, \"eip150Block\": 0, \"eip155Block\": 0, \"eip158Block\": 0 } } 关于创世文件中的各个字段的含义, 后面会有一篇专门的博客来讲 注意: 将coinbase 以及 alloc中的地址修改为上面创建账户时你所得到的地址 ","date":"2022-07-01","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E6%89%8B%E5%B7%A5%E6%89%93%E9%80%A0/:1:4","tags":["solidity","ethereum","go-ethereum","python"],"title":"从零开始编写智能合约-手工打造","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E6%89%8B%E5%B7%A5%E6%89%93%E9%80%A0/"},{"categories":["Blockchain"],"content":"初始化区块链 geth --datadir ./data init ./genesis.json 输出 INFO [07-01|10:50:50.915] Maximum peer count ETH=50 LES=0 total=50 INFO [07-01|10:50:50.919] Set global gas cap cap=50,000,000 INFO [07-01|10:50:50.919] Allocated cache and file handles database=/Users/zhouyinhui/Downloads/privateNetwork/data/geth/chaindata cache=16.00MiB handles=16 INFO [07-01|10:50:51.007] Writing custom genesis block INFO [07-01|10:50:51.010] Persisted trie from memory database nodes=0 size=0.00B time=\"21.005µs\" gcnodes=0 gcsize=0.00B gctime=0s livenodes=1 livesize=0.00B INFO [07-01|10:50:51.011] Successfully wrote genesis state database=chaindata hash=0ca0fb..b61b69 INFO [07-01|10:50:51.011] Allocated cache and file handles database=/Users/zhouyinhui/Downloads/privateNetwork/data/geth/lightchaindata cache=16.00MiB handles=16 INFO [07-01|10:50:51.090] Writing custom genesis block INFO [07-01|10:50:51.090] Persisted trie from memory database nodes=0 size=0.00B time=\"2.71µs\" gcnodes=0 gcsize=0.00B gctime=0s livenodes=1 livesize=0.00B INFO [07-01|10:50:51.091] Successfully wrote genesis state database=lightchaindata hash=0ca0fb..b61b69 OSX MP16 ~/Downloads/privateNetwork ❯ 生成的文件在 ./data/geth下 ","date":"2022-07-01","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E6%89%8B%E5%B7%A5%E6%89%93%E9%80%A0/:1:5","tags":["solidity","ethereum","go-ethereum","python"],"title":"从零开始编写智能合约-手工打造","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E6%89%8B%E5%B7%A5%E6%89%93%E9%80%A0/"},{"categories":["Blockchain"],"content":"运行区块链 geth --datadir ./data/ --networkid 1235 --port 8545 --http --http.api 'admin,eth,miner,net,txpool,personal,web3' --mine --allow-insecure-unlock --unlock '0x79dF0D3c23f22370881dC92aF524A1D5E52e3552' --password password.txt --datadir 数据文件目录 --networkid 网络ID --port RPC端口 --http 启用http-rpc服务 --http.api提供那些API --mine 启用挖矿 --allow-insecure-unlock 当账户相关的RPC被http暴露时，允许不安全的账户解锁 --unlock 解锁账户 (多个账户用逗号分割) --password 解锁账户用到的密码文件 成功运行后, 会看到很多打印信息, 其中值得注意的是下面这两行, 一个是ipc, 一个是http server, 我们会使用他们来和我们的区块链进行通讯 INFO [07-01|11:08:58.245] IPC endpoint opened url=/Users/zhouyinhui/Downloads/privateNetwork/data/geth.ipc INFO [07-01|11:08:58.245] HTTP server started endpoint=127.0.0.1:8545 prefix= cors= vhosts=localhost 另外一条是 我们作为区块链中的对等节点PEER NODE时的信息, 这里我们还用不到 Started P2P networking self=enode://de2537c5f309be45bcb2d011cd172138db40295f74a288b07e03635e2194e7c2987cf97c9d295dc502053d9f7adda11052597c7f1bc5a5ec3d8182777138a0f1@127.0.0.1:8545 请保持区块链在后台运行, 后面的代码都需要用到 ","date":"2022-07-01","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E6%89%8B%E5%B7%A5%E6%89%93%E9%80%A0/:2:0","tags":["solidity","ethereum","go-ethereum","python"],"title":"从零开始编写智能合约-手工打造","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E6%89%8B%E5%B7%A5%E6%89%93%E9%80%A0/"},{"categories":["Blockchain"],"content":"与测试链进行交互 attach到测试链, 就可以启动一个js console, 和truffle console功能一样 方式1, 通过IPC进行attach geth attach /Users/zhouyinhui/Downloads/privateNetwork/data/geth.ipc OSX MP16 ~/blockchain/private_net/tempchain ❯ geth attach /Users/zhouyinhui/Downloads/privateNetwork/data/geth.ipc Welcome to the Geth JavaScript console! .... To exit, press ctrl-d or type exit \u003e eth.chainId() \"0x4d3\" \u003e \"0x4d3\" 也就是 我们的 1235 其中 *.ipc 可以使用相对路径 方式2, 通过http服务进行attach geth attach http://127.0.0.1:8545 ","date":"2022-07-01","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E6%89%8B%E5%B7%A5%E6%89%93%E9%80%A0/:3:0","tags":["solidity","ethereum","go-ethereum","python"],"title":"从零开始编写智能合约-手工打造","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E6%89%8B%E5%B7%A5%E6%89%93%E9%80%A0/"},{"categories":["Blockchain"],"content":"一键生成测试链 上面那些繁琐的步骤可以搞成一个脚本, 一键生成, 这样来得更方便 脚本在这里: https://github.com/yinhui1984/stepByStepSmartContract/blob/main/autogen/autoGenChain.py (直接将代码贴到这里会导致GitHub Pages failed to build your site 😂) ","date":"2022-07-01","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E6%89%8B%E5%B7%A5%E6%89%93%E9%80%A0/:4:0","tags":["solidity","ethereum","go-ethereum","python"],"title":"从零开始编写智能合约-手工打造","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E6%89%8B%E5%B7%A5%E6%89%93%E9%80%A0/"},{"categories":["Blockchain"],"content":"编写智能合约 我们还是使用 上篇博客中的智能合约 mkdir ./contracts cd ./contracts touch Calculator.sol // SPDX-License-Identifier: MIT pragma solidity ^0.8.0; contract Calculator { function add(int a, int b) public pure returns (int) { return a + b; } function subtract(int a, int b) public pure returns (int) { return a - b; } } ","date":"2022-07-01","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E6%89%8B%E5%B7%A5%E6%89%93%E9%80%A0/:5:0","tags":["solidity","ethereum","go-ethereum","python"],"title":"从零开始编写智能合约-手工打造","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E6%89%8B%E5%B7%A5%E6%89%93%E9%80%A0/"},{"categories":["Blockchain"],"content":"编译智能合约 如果你的电脑上没有solc, 请事先安装, 它是solidity的编译器, 官方教程: https://docs.soliditylang.org/en/v0.8.15/installing-solidity.html#installing-solidity 编译: solc --bin --abi -o ./build ./Calculator.sol --bin 生成16进制文件 --abi生成abi文件 -o输出目录 可以写一个Makefile来干这个事情: all: solc --bin --abi --overwrite -o ./build ./Calculator.sol clean: rm -rf ./build/* OSX MP16 ~/Downloads/privateNetwork/contracts ❯ tree . ├── Calculator.sol ├── Makefile └── build ├── Calculator.abi └── Calculator.bin ","date":"2022-07-01","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E6%89%8B%E5%B7%A5%E6%89%93%E9%80%A0/:6:0","tags":["solidity","ethereum","go-ethereum","python"],"title":"从零开始编写智能合约-手工打造","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E6%89%8B%E5%B7%A5%E6%89%93%E9%80%A0/"},{"categories":["Blockchain"],"content":"部署智能合约 新建一个node.js 项目deploy mkdir -p deploy/ cd deploy/ npm init touch index.js 安装web3.js npm install web3 在index.js中加入如下代码: const fs = require('fs'); const Web3 = require('web3'); const web3 = new Web3('http://127.0.0.1:8545'); const bytecode = fs.readFileSync('../build/Calculator.bin').toString(); const abi = JSON.parse(fs.readFileSync('../build/Calculator.abi').toString()); (async function () { const accounts = await web3.eth.getAccounts(); const calculator = new web3.eth.Contract(abi); calculator.deploy({ data: bytecode }).send({ from: accounts[0], }).then((deployment) =\u003e { console.log('Contract was deployed at the following address:'); console.log(deployment.options.address); }).catch((err) =\u003e { console.error(err); }); })(); 注意, 上面的部署代码没有使用账户的私钥, 是因为在前面的步骤中, 账户已经解锁了 在部署之前需要先启动挖矿 OSX MP16 ~/Downloads/pri/mychain ❯ ./attach.sh ... \u003e miner.start() null \u003e eth.blockNumber 26 部署: OSX MP16 ~/Downloads/pri/c/d/deploy_js ❯ node ./index.js Contract was deployed at the following address: 0x1F55d61D5Aa8eC92FD1Da0f19FaC9D552A29DBBF 部署成功, 停掉挖矿, 否则电脑巨烫… \u003e miner.stop() null ","date":"2022-07-01","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E6%89%8B%E5%B7%A5%E6%89%93%E9%80%A0/:7:0","tags":["solidity","ethereum","go-ethereum","python"],"title":"从零开始编写智能合约-手工打造","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E6%89%8B%E5%B7%A5%E6%89%93%E9%80%A0/"},{"categories":["Blockchain"],"content":"调用智能合约 调用智能合约就和 从零开始编写智能合约-使用truffle套件中的一样了, 可以跳转到那里进行参考 ","date":"2022-07-01","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E6%89%8B%E5%B7%A5%E6%89%93%E9%80%A0/:8:0","tags":["solidity","ethereum","go-ethereum","python"],"title":"从零开始编写智能合约-手工打造","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E6%89%8B%E5%B7%A5%E6%89%93%E9%80%A0/"},{"categories":["Blockchain"],"content":"这篇文章将带你使用truffle套件从零开始搭建环境, 编写、部署、测试和调用智能合约。 配套代码在 https://github.com/yinhui1984/HelloTruffle ","date":"2022-06-29","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E4%BD%BF%E7%94%A8truffle%E5%A5%97%E4%BB%B6/:0:0","tags":["solidity","truffle","ganache","ethereum","go-ethereum"],"title":"从零开始编写智能合约-使用trtffle套件","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E4%BD%BF%E7%94%A8truffle%E5%A5%97%E4%BB%B6/"},{"categories":["Blockchain"],"content":"使用truffle套件 ","date":"2022-06-29","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E4%BD%BF%E7%94%A8truffle%E5%A5%97%E4%BB%B6/:1:0","tags":["solidity","truffle","ganache","ethereum","go-ethereum"],"title":"从零开始编写智能合约-使用trtffle套件","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E4%BD%BF%E7%94%A8truffle%E5%A5%97%E4%BB%B6/"},{"categories":["Blockchain"],"content":"1. 安装node.js https://nodejs.org/en/ 安装完成后, 查看是否版本以确保成功 npm -v node -v ","date":"2022-06-29","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E4%BD%BF%E7%94%A8truffle%E5%A5%97%E4%BB%B6/:1:1","tags":["solidity","truffle","ganache","ethereum","go-ethereum"],"title":"从零开始编写智能合约-使用trtffle套件","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E4%BD%BF%E7%94%A8truffle%E5%A5%97%E4%BB%B6/"},{"categories":["Blockchain"],"content":"2. 安装truffle和Ganache truffle是一套智能合约的开发测试环境 Ganache用于创建测试链(可以创建ETH FILECOIN等测试链), 用来跑自己创建的合约. https://trufflesuite.com 使用npm安装truffle npm install -g truffle 安装完成后, 查看版本以确保成功 truffle version 如果遇到permission denied: truffle 找到truffle文件 ll /usr/local/bin/truffle 可以看到其软连接到cli.bundled.js Permissions Size User Date Modified Name lrwxr-xr-x 48 zhouyinhui 29 Jun 14:06  /usr/local/bin/truffle -\u003e ../lib/node_modules/truffle/build/cli.bundled.js 给这个js加上执行权限即可 chmod +x /usr/local/lib/node_modules/truffle/build/cli.bundled.js 安装Ganache 到这里直接下载即可 https://trufflesuite.com/ganache/ ","date":"2022-06-29","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E4%BD%BF%E7%94%A8truffle%E5%A5%97%E4%BB%B6/:1:2","tags":["solidity","truffle","ganache","ethereum","go-ethereum"],"title":"从零开始编写智能合约-使用trtffle套件","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E4%BD%BF%E7%94%A8truffle%E5%A5%97%E4%BB%B6/"},{"categories":["Blockchain"],"content":"3. 使用truffle新建项目 新建一个目录, 比如~/Downloads/truffleTest 到这个目录下 OSX MP16 ~/Downloads/truffleTest ❯ truffle init Starting init... ================ \u003e Copying project files to /Users/zhouyinhui/Downloads/truffleTest Init successful, sweet! Try our scaffold commands to get started: $ truffle create contract YourContractName # scaffold a contract $ truffle create test YourTestName # scaffold a test http://trufflesuite.com/docs 其新建了这些文件 OSX MP16 ~/Downloads/truffleTest ❯ tree . ├── contracts │ └── Migrations.sol ├── migrations │ └── 1_initial_migration.js ├── test └── truffle-config.js contracts文件夹存放合约的地方, 在其中新建一个solidity源码文件, 比如Calculator.sol touch ./contracts/Calculator.sol 在Calculator.sol中添加如下代码来做个加减法 // SPDX-License-Identifier: MIT pragma solidity ^0.8.0; contract Calculator { function add(int a, int b) public pure returns (int) { return a + b; } function subtract(int a, int b) public pure returns (int) { return a - b; } } 其中的pure表示改函数既不读也不写状态机变量 https://hashnode.com/post/pure-vs-view-in-solidity-cl04tbzlh07kaudnv1ial1gio 复制上面代码时注意 pragma solidity ^0.8.0;这一行和 trffle-config.js中的下面的配置相匹配 // Configure your compilers compilers: { solc: { version: \"0.8.15\", //.... }, } pragma solidity ^0.8.0 表示编译器使用0.8到0.9版本之间的(不包含0.9), 那么trffle-config.js中配置的编译器版本要在这个范围内 ","date":"2022-06-29","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E4%BD%BF%E7%94%A8truffle%E5%A5%97%E4%BB%B6/:1:3","tags":["solidity","truffle","ganache","ethereum","go-ethereum"],"title":"从零开始编写智能合约-使用trtffle套件","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E4%BD%BF%E7%94%A8truffle%E5%A5%97%E4%BB%B6/"},{"categories":["Blockchain"],"content":"4.编译 truffle compile OSX MP16 ~/Downloads/truffleTest ❯ truffle compile Compiling your contracts... =========================== \u003e Compiling ./contracts/Calculator.sol \u003e Artifacts written to /Users/zhouyinhui/Downloads/truffleTest/build/contracts \u003e Compiled successfully using: - solc: 0.8.15+commit.e14f2714.Emscripten.clang 编译完成后, 会将结果放到build目录下: 我们这里关心的是Calculator.json OSX MP16 ~/Downloads/truffleTest ❯ tree . ├── build │ └── contracts │ ├── Calculator.json │ └── Migrations.json ├── contracts │ ├── Calculator.sol │ └── Migrations.sol ├── migrations │ └── 1_initial_migration.js ├── test └── truffle-config.js 5 directories, 6 files ","date":"2022-06-29","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E4%BD%BF%E7%94%A8truffle%E5%A5%97%E4%BB%B6/:1:4","tags":["solidity","truffle","ganache","ethereum","go-ethereum"],"title":"从零开始编写智能合约-使用trtffle套件","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E4%BD%BF%E7%94%A8truffle%E5%A5%97%E4%BB%B6/"},{"categories":["Blockchain"],"content":"5.部署到测试链 启动测试链 启动 ganache App, 点击QUICKSTART 其就自动创建了ETH测试链, 查看窗口上半部分显示的的RPC server信息, 比如 HTTP://127.0.0.1:8545 修改 truffle-config.js中的部署配置, 使其与上面的RPC server向匹配 networks: { //... development: { host: \"127.0.0.1\", // Localhost (default: none) port: 8545, // Standard Ethereum port (default: none) network_id: \"*\", // Any network (default: none) }, Note 请保持ganache在后台运行, 后面的代码都需要访问测试链 添加部署代码 touch migrations/2_deploy_contracts.js 在2_deploy_contracts.js中加入如下代码 var Calculator = artifacts.require(\"./Calculator.sol\"); module.exports = function(deployer) { deployer.deploy(Calculator); } 部署合约 运行 truffle migrate 命令进行部署 OSX MP16 ~/Downloads/truffleTest ❯ truffle migrate Compiling your contracts... =========================== \u003e Everything is up to date, there is nothing to compile. Starting migrations... ====================== \u003e Network name: 'development' \u003e Network id: 5777 \u003e Block gas limit: 6721975 (0x6691b7) 1_initial_migration.js ====================== Deploying 'Migrations' ---------------------- \u003e transaction hash: 0xc4b0bf65cbac8d1cf68b72fc6408bd443c18e6bf3e44c5985dede50b191a80d1 \u003e Blocks: 0 Seconds: 0 \u003e contract address: 0xe2fd5fA1303B9791417EF637AABd50aE9DB9Af44 \u003e block number: 1 \u003e block timestamp: 1656490514 \u003e account: 0xe149d5f732685669C9E494B233fDB4312d19b5cF \u003e balance: 99.99502292 \u003e gas used: 248854 (0x3cc16) \u003e gas price: 20 gwei \u003e value sent: 0 ETH \u003e total cost: 0.00497708 ETH \u003e Saving migration to chain. \u003e Saving artifacts ------------------------------------- \u003e Total cost: 0.00497708 ETH 2_deploy_contracts.js ===================== Deploying 'Calculator' ---------------------- \u003e transaction hash: 0xc8cce4b870d187dadf38353e6ef71aabd0751375a2f2b8c763ed4a35d8067a0c \u003e Blocks: 0 Seconds: 0 \u003e contract address: 0x6B62e4E253823FBC65E0B93d63ee149350158a18 \u003e block number: 3 \u003e block timestamp: 1656490515 \u003e account: 0xe149d5f732685669C9E494B233fDB4312d19b5cF \u003e balance: 99.98984578 \u003e gas used: 216344 (0x34d18) \u003e gas price: 20 gwei \u003e value sent: 0 ETH \u003e total cost: 0.00432688 ETH \u003e Saving migration to chain. \u003e Saving artifacts ------------------------------------- \u003e Total cost: 0.00432688 ETH Summary ======= \u003e Total deployments: 2 \u003e Final cost: 0.00930396 ETH ","date":"2022-06-29","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E4%BD%BF%E7%94%A8truffle%E5%A5%97%E4%BB%B6/:1:5","tags":["solidity","truffle","ganache","ethereum","go-ethereum"],"title":"从零开始编写智能合约-使用trtffle套件","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E4%BD%BF%E7%94%A8truffle%E5%A5%97%E4%BB%B6/"},{"categories":["Blockchain"],"content":"6. 测试合约 使用truffle console 手动调用 运行 truffle console 打开控制台 truffle(development)\u003e let cal = await Calculator.deployed() truffle(development)\u003e cal.add(1,2) BN { negative: 0, words: [ 3, \u003c1 empty item\u003e ], length: 1, red: null } truffle(development)\u003e cal.subtract(10, 2) BN { negative: 0, words: [ 8, \u003c1 empty item\u003e ], length: 1, red: null } 在控制台中可以使用TAB按键来提示成员变量或函数 使用js编写单元测试 touch test/testCalculator.test.js //testCalculator.test.js //开发框架导入合约 const Calculator = artifacts.require(\"Calculator\"); //接下来，我们定义用于测试的合约，然后将账户作为包含所有地址的参数传递。 contract(\"Calculator\", accounts =\u003e { //it包含对我们要运行的测试的简短描述， // 它是一个包含所有测试相关脚本的异步函数 it(\"should add two numbers\", async () =\u003e { //cal: 定义存储已部署合约的实例。 const cal = await Calculator.deployed(); const result = await cal.add(4, 2); assert.equal(result.toNumber(), 6); }).timeout(10000); it(\"should subtract two numbers\", async () =\u003e { const cal = await Calculator.deployed(); const result = await cal.subtract(3, 2); assert.equal(result.toNumber(), 1); }).timeout(10000); }); 运行 truffle test 跑测试 OSX MP16 ~/Downloads/truffleTest ❯ truffle test Using network 'development'. Compiling your contracts... =========================== \u003e Everything is up to date, there is nothing to compile. Contract: Calculator ✔ should add two numbers ✔ should subtract two numbers (48ms) 2 passing (126ms) ","date":"2022-06-29","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E4%BD%BF%E7%94%A8truffle%E5%A5%97%E4%BB%B6/:1:6","tags":["solidity","truffle","ganache","ethereum","go-ethereum"],"title":"从零开始编写智能合约-使用trtffle套件","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E4%BD%BF%E7%94%A8truffle%E5%A5%97%E4%BB%B6/"},{"categories":["Blockchain"],"content":"7. demoApp调用合约 使用web3.js 我们使用web3.js 创建一个app来实际使用我们的合约 初始化一个node.js app mkdir -p ./demo/jsApp cd ./demo/jsApp/ npm init 然后一路默认回车 touch index.js 安装web3.js npm install web3 在index.js中加入如下代码 const Web3 = require('web3'); //注意，这里有个坑， 有时候http://localhost:8545 用localhost可以，有时候连接不上 //最好用127.0.0.1 const web3 = new Web3(new Web3.providers.HttpProvider(\"http://127.0.0.1:8545\")); //web3.eth.getAccounts().then(console.log) //modify the following line to your own contract address let contractAddress = \"0x6B62e4E253823FBC65E0B93d63ee149350158a18\"; //copy abi from ./build/contracts/Calculator.json let abi = [ { \"inputs\": [ { \"internalType\": \"int256\", \"name\": \"a\", \"type\": \"int256\" }, { \"internalType\": \"int256\", \"name\": \"b\", \"type\": \"int256\" } ], \"name\": \"add\", \"outputs\": [ { \"internalType\": \"int256\", \"name\": \"\", \"type\": \"int256\" } ], \"stateMutability\": \"pure\", \"type\": \"function\", \"constant\": true }, { \"inputs\": [ { \"internalType\": \"int256\", \"name\": \"a\", \"type\": \"int256\" }, { \"internalType\": \"int256\", \"name\": \"b\", \"type\": \"int256\" } ], \"name\": \"subtract\", \"outputs\": [ { \"internalType\": \"int256\", \"name\": \"\", \"type\": \"int256\" } ], \"stateMutability\": \"pure\", \"type\": \"function\", \"constant\": true } ] let contract = new web3.eth.Contract(abi,contractAddress); contract.methods.add(4,2).call().then(console.log); contract.methods.subtract(3,2).call().then(console.log); 其中的 contractAddress是我们部署的Caculator合约地址 如何找到合约地址? 方式1, 在上面的truffle migrate进行合约部署时,会打印 方式2, 在Ganache软件界面的Transactions中找, 貌似不方便 方式3, 在Ganache软件界面 : Settings -\u003e Workspace 中点击ADD Project 添加 truffle-config.js文件关联项目, 然后点击RESTART重新回到主界面的CONTRACTS就可以看到了 方式4, 运行truffle console truffle(development)\u003e Calculator.address '0x6B62e4E253823FBC65E0B93d63ee149350158a18' 其中的abi是合约对应的abi 如何找到abi? 方式1, solc --abi ./contracts/Calculator.sol 方式2, 到./build/contracts/Calculator.json中, 找到\"abi\"对应的值 不要使用truffle console中的Calculator.abi 运行app OSX MP16 ~/Downloads/truffleTest/demo/jsApp ❯ node index.js 6 1 使用golang mkdir -p ./demo/goApp cd ./demo/goApp touch main.go go mod init goApp 需要使用到 \"github.com/ethereum/go-ethereum/ethclient\"这个包 go get \"github.com/ethereum/go-ethereum/ethclient\" 这个包如果要调用合约, 则需要一些额外的操作 额外的操作: 利用 abigen 从solidity源文件生成golang代码 OSX MP16 ~/Downloads/truffleTest/demo/goApp ❯ mkdir contracts abigen --pkg contracts --sol ../../contracts/Calculator.sol --out ./contracts/calculatorContract.go –pkg contracts : 指定生成的代码的 package name –sol ../../contracts/Calculator.sol : 指定合约代码位置 –out ./contracts/calculatorContract.go: 指定生成的代码位置 生成完成后, goApp的目录结构如下: tree ~/Downloads/truffleTest/demo/goApp /Users/zhouyinhui/Downloads/truffleTest/demo/goApp ├── contracts │ └── calculatorContract.go ├── go.mod ├── go.sum └── main.go 生成后的calculatorContract.go中import包,可能并不在go.mod中, 所以运行一次 go mod tidy以避免编译时找不到包 main.go中代码如下: package main import ( \"fmt\" \"github.com/ethereum/go-ethereum/accounts/abi/bind\" \"github.com/ethereum/go-ethereum/common\" \"github.com/ethereum/go-ethereum/ethclient\" \"goApp/contracts\" \"math/big\" ) //https://goethereumbook.org/client-setup/ func main() { client, err := ethclient.Dial(\"http://localhost:8545\") if err != nil { fmt.Println(\"could not connect to local node, err:\", err) return } contractAddress := common.HexToAddress(\"0x6B62e4E253823FBC65E0B93d63ee149350158a18\") calculator, err := contracts.NewCalculator(contractAddress, client) if err != nil { fmt.Println(\"could not instantiate contract, err:\", err) return } callOpts := bind.CallOpts{ Context: nil, Pending: false, } a := big.NewInt(1) b := big.NewInt(2) result, err := calculator.Add(\u0026callOpts, a, b) if err != nil { fmt.Println(\"could not call contract, err:\", err) return } fmt.Println(\"add result:\", result) result, err = calculator.Subtract(\u0026callOpts, a, b) if err != nil { fmt.Println(\"could not call contract, err:\", err) return } fmt.Println(\"subtract result:\", result) } 运行 OSX MP16 ~/Downloads/truffleTest/demo/goApp ❯ go run . add result: 3 subtract result: -1 ","date":"2022-06-29","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E4%BD%BF%E7%94%A8truffle%E5%A5%97%E4%BB%B6/:1:7","tags":["solidity","truffle","ganache","ethereum","go-ethereum"],"title":"从零开始编写智能合约-使用trtffle套件","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E4%BD%BF%E7%94%A8truffle%E5%A5%97%E4%BB%B6/"},{"categories":["Blockchain"],"content":"手工撸 这里: https://yinhui1984.github.io/从零开始编写智能合约-手工打造/ ","date":"2022-06-29","objectID":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E4%BD%BF%E7%94%A8truffle%E5%A5%97%E4%BB%B6/:2:0","tags":["solidity","truffle","ganache","ethereum","go-ethereum"],"title":"从零开始编写智能合约-使用trtffle套件","uri":"/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%BC%96%E5%86%99%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6-%E4%BD%BF%E7%94%A8truffle%E5%A5%97%E4%BB%B6/"},{"categories":["golang"],"content":"我们将用些简单的例子来尝试golang中sync包的各种有趣的情况 ","date":"2022-06-12","objectID":"/%E8%81%8A%E8%81%8Ago%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84sync/:0:0","tags":["go","sync"],"title":"聊聊go语言中的sync","uri":"/%E8%81%8A%E8%81%8Ago%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84sync/"},{"categories":["golang"],"content":"一个简单的DEMO package main import \"fmt\" var ( sharedCounter = 0 ) func add(count int) { for i := 0; i \u003c count; i++ { sharedCounter++ } } func sub(count int) { for i := 0; i \u003c count; i++ { sharedCounter-- } } func show() { fmt.Println(sharedCounter) } func main() { add(1000000) sub(1000000) show() } 程序很简单, 我们用一个共享变量sharedCounter作为一个计数器. add函数在计数器上循环添加一定的数值, sub则相反, show则是打印计数器当前的值. 程序运行结束后, sharedCounter应该为0, 上面代码的输出的确如此. ","date":"2022-06-12","objectID":"/%E8%81%8A%E8%81%8Ago%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84sync/:1:0","tags":["go","sync"],"title":"聊聊go语言中的sync","uri":"/%E8%81%8A%E8%81%8Ago%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84sync/"},{"categories":["golang"],"content":"使用一个协程 如果对计数器进行加减的调用在不同的协程里面, 会怎么样呢? func main() { add(1000000) go sub(1000000) show() } 会得到1000000 , 因为go sub(1000000)刚启动, 程序就退出了. 或许我们应该等到sub函数执行结束 ","date":"2022-06-12","objectID":"/%E8%81%8A%E8%81%8Ago%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84sync/:2:0","tags":["go","sync"],"title":"聊聊go语言中的sync","uri":"/%E8%81%8A%E8%81%8Ago%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84sync/"},{"categories":["golang"],"content":"等待协程结束 错误的方式 如果有C语言开发背景, 可能会想到通过设置一个flag来指示运算是否结束, 比如: func sub(count int, done *bool) { for i := 0; i \u003c count; i++ { sharedCounter-- } *done = true } //.... func main() { add(1000000) done := false go sub(1000000, \u0026done) for !done { time.Sleep(time.Millisecond * 10) } show() } 这虽然也能得到正确的输出, 但非常不优雅. 正确的方式1 可以使用一个无缓冲的信道(或者说容量为1的信道)来充当flag //... func sub(count int, done chan bool) { for i := 0; i \u003c count; i++ { sharedCounter-- } done \u003c- true } //.... func main() { add(1000000) done := make(chan bool) go sub(1000000, done) \u003c-subDone show() } 这里利用了信道的特点: 当从信道中读取数据时,如果信道为空,读取将被阻塞直到有数据到达. 所以 \u003c-subDone 会一直阻塞, 直到通过subDone \u003c- true向其中写入了数据 ","date":"2022-06-12","objectID":"/%E8%81%8A%E8%81%8Ago%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84sync/:2:1","tags":["go","sync"],"title":"聊聊go语言中的sync","uri":"/%E8%81%8A%E8%81%8Ago%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84sync/"},{"categories":["golang"],"content":"使用2个协程 上面的例子中, sub(1000000, done)是在新的协程中运行的, add(1000000)却不是, 如果他们都在新协程中运行, 主程序应该如何等待他们结束呢 很容易想到, 使用两次\u003c-done 也就是说向信道索要两个计算完成的标志, add和 sub 计算完成后分别向其中放入标志. package main import \"fmt\" var ( sharedCounter = 0 ) func add(count int, done chan bool) { for i := 0; i \u003c count; i++ { sharedCounter++ } fmt.Println(\"add done\") done \u003c- true } func sub(count int, done chan bool) { for i := 0; i \u003c count; i++ { sharedCounter-- } fmt.Println(\"sub done\") done \u003c- true } func show() { fmt.Println(sharedCounter) } func main() { done := make(chan bool) go add(1000000, done) go sub(1000000, done) \u003c-done \u003c-done show() } 为了明确知道main函数的确是等待两个协程执行完毕了的, 我们在其中加入了fmt.Println(\"sub done\")这样的输出 运行程序, 得到 add done sub done 824933 Opps, 虽然add和sub 都执行完毕了,但是结果不对(并且多次运行的结果还不相同), 期望接收应该是0 再运行一次, 得到: sub done add done -481342 原因是add和sub在交叉读取和写入sharedCounter这个变量, 他们共享了变量, 但在读取和写入的时候出现**“竞态”** ","date":"2022-06-12","objectID":"/%E8%81%8A%E8%81%8Ago%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84sync/:3:0","tags":["go","sync"],"title":"聊聊go语言中的sync","uri":"/%E8%81%8A%E8%81%8Ago%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84sync/"},{"categories":["golang"],"content":"竞态 有多个协程运行时, 对于每个协程而言,其内部代码时顺序执行的, 但无法确定协程之间的执行顺序, 那么就说这些协程是并发的 如果一段代码无论是顺序执行还是并发执行,其结果都是确定的,那么这个代码就是并发安全的. 相反, 并发不安全的代码,可能会出现死锁,活锁,竞态 竞态则表示代码可执行,但可能出现结果不一致(错误结果) ###解决方法1, 利用信道 func main() { done := make(chan bool) go add(1000000, done) \u003c-done //1 go sub(1000000, done) \u003c-done //2 show() } 在add执行完毕之前, 首先会堵塞在//1处, func add(count int, done chan bool) { //.... done \u003c- true } add函数执行最后一句 done \u003c- true 后 \u003c-done //1能取到值, 接触阻塞. 然后继续往下执行sub函数. 这虽然能得到正确输出, 但, 我们发现, 这实际是将并行执行修改成了串行执行. ","date":"2022-06-12","objectID":"/%E8%81%8A%E8%81%8Ago%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84sync/:3:1","tags":["go","sync"],"title":"聊聊go语言中的sync","uri":"/%E8%81%8A%E8%81%8Ago%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84sync/"},{"categories":["golang"],"content":"解决方法2, 利用 Mutex 或 RWMutex sync.Mutex 可能是同步包中使用最广泛的原语。它允许对共享资源进行互斥（不能同时访问). mutex := \u0026sync.Mutex{} mutex.Lock() //.... 更新共享变量 mutex.Unlock() 注意: 在官方文档中有这么一句 “Values containing the types defined in this package should not be copied.” (“包含这个包中定义的类型的值不应该被复制。”) . 我们直到值传递就是复制然后传递, 所以我们代码中的mutex用的是引用传递. package main import ( \"fmt\" \"sync\" ) var ( sharedCounter = 0 mutex = \u0026sync.Mutex{} ) func add(count int, done chan bool) { for i := 0; i \u003c count; i++ { mutex.Lock() sharedCounter++ mutex.Unlock() } fmt.Println(\"add done\") done \u003c- true } func sub(count int, done chan bool) { for i := 0; i \u003c count; i++ { mutex.Lock() sharedCounter-- mutex.Unlock() } fmt.Println(\"sub done\") done \u003c- true } func show() { fmt.Println(sharedCounter) } func main() { done := make(chan bool) go add(1000000, done) go sub(1000000, done) \u003c-done \u003c-done show() } 在读写sharedCounter之前先Lock(), 用完后Unlock() 如果我们在进行计算的时候加上点打印(仅测试用,非常影响速度) for i := 0; i \u003c count; i++ { mutex.Lock() fmt.Println(\"--\") // fmt.Println(\"++\") sharedCounter-- // sharedCounter++ mutex.Unlock() } 则可以看到 ++ 和 – 是交叉着打印的, 说明是并行执行的. 另外, 还有RWMutex (读写锁), 除了与Mutex相同的Lock()和Unlock()方法外, 其还有用于共享读操作的RLock()和RUnlock(), 在读取共享变量时允许同时多个读取器能提高效率. 所以在频繁读写操作的代码中, 使用RWMutex效率要比Mutex高 ","date":"2022-06-12","objectID":"/%E8%81%8A%E8%81%8Ago%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84sync/:3:2","tags":["go","sync"],"title":"聊聊go语言中的sync","uri":"/%E8%81%8A%E8%81%8Ago%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84sync/"},{"categories":["golang"],"content":"解决方法3, 利用原子操作 原子操作在\"sync/atomic\"包中. 利用这个包中提供的函数可实现\"无锁版\"的共享变量读写 原子操作即是进行过程中不能被中断的操作，针对某个值的原子操作在被进行的过程中，CPU绝不会再去进行其他的针对该值的操作。为了实现这样的严谨性，原子操作仅会由一个独立的CPU指令代表和完成。原子操作是无锁的，常常直接通过CPU指令直接实现。 事实上，其它同步技术的实现常常依赖于原子操作 package main import ( \"fmt\" \"sync/atomic\" ) var ( sharedCounter = int64(0) ) func add(count int, done chan bool) { for i := 0; i \u003c count; i++ { atomic.AddInt64(\u0026sharedCounter, 1) // } fmt.Println(\"add done\") done \u003c- true } func sub(count int, done chan bool) { for i := 0; i \u003c count; i++ { atomic.AddInt64(\u0026sharedCounter, -1) // } fmt.Println(\"sub done\") done \u003c- true } func show() { fmt.Println(sharedCounter) } func main() { done := make(chan bool) go add(1000000, done) go sub(1000000, done) \u003c-done \u003c-done show() } 原子操作的常用接口如下(以int32为例) //将addr指向的值和old进行比较, 如果相等,则将new赋值到addr指向的位置,并返回true, 如果不相等,则直接返回false func CompareAndSwapInt32(addr *int32, old, new int32) (swapped bool) //使用原子操作,将addr指向的位置增加一个delta func AddInt32(addr *int32, delta int32) (new int32) //原子读取 //当我们要读取一个变量的时候，很有可能这个变量正在被写入，这个时候，我们就很有可能读取到写到一半的数据。 所以读取操作是需要一个原子行为的。 func LoadInt32(addr *int32) (val int32) //读取是有原子性的操作的，同样写入atomic包也提供了相关的操作包 func StoreInt32(addr *int32, val int32) //此类型的值相当于一个容器，可以被用来“原子地\"存储（Store）和加载（Load）任意类型的值。当然这个类型也是原子性的。 //有了atomic.Value这个类型，这样用户就可以在不依赖Go内部类型unsafe.Pointer的情况下使用到atomic提供的原子操作。 // A Value must not be copied after first use. type Value struct { v interface{} } 原子操作与互斥锁的区别 首先atomic操作的优势是更轻量，比如CAS可以在不形成临界区和创建互斥量的情况下完成并发安全的值替换操作。这可以大大的减少同步对程序性能的损耗。 原子操作也有劣势。还是以CAS操作为例，使用CAS操作的做法趋于乐观，总是假设被操作值未曾被改变（即与旧值相等），并一旦确认这个假设的真实性就立即进行值替换，那么在被操作值被频繁变更的情况下，CAS操作并不那么容易成功。而使用互斥锁的做法则趋于悲观，我们总假设会有并发的操作要修改被操作的值，并使用锁将相关操作放入临界区中加以保护。 下面是几点区别： 互斥锁是一种数据结构，用来让一个线程执行程序的关键部分，完成互斥的多个操作 原子操作是无锁的，常常直接通过CPU指令直接实现 原子操作中的cas趋于乐观锁，CAS操作并不那么容易成功，需要判断，然后尝试处理 可以把互斥锁理解为悲观锁，共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程 不要轻易使用atomic https://texlution.com/post/golang-lock-free-values-with-atomic-value/ ","date":"2022-06-12","objectID":"/%E8%81%8A%E8%81%8Ago%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84sync/:3:3","tags":["go","sync"],"title":"聊聊go语言中的sync","uri":"/%E8%81%8A%E8%81%8Ago%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84sync/"},{"categories":["golang"],"content":"其它并发控制方法 上面的例子中, 我们都是使用的信道来进行并发控制 (done \u003c- true与\u003c-done), 这只是常用的方法之一 ","date":"2022-06-12","objectID":"/%E8%81%8A%E8%81%8Ago%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84sync/:4:0","tags":["go","sync"],"title":"聊聊go语言中的sync","uri":"/%E8%81%8A%E8%81%8Ago%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84sync/"},{"categories":["golang"],"content":"WaitGroup sync.WaitGroup 拥有一个内部计数器。如果此计数器等于 0，则 Wait() 方法立即返回。否则，它将被阻塞，直到计数器为 0。 要增加计数器，我们必须使用 Add(int)。要减少它，我们可以使用 Done() （将减少 1）或具有负值的相同 Add(int) 方法。 package main import ( \"fmt\" \"sync\" \"sync/atomic\" ) var ( sharedCounter = int64(0) ) func add(count int, wg *sync.WaitGroup) { for i := 0; i \u003c count; i++ { atomic.AddInt64(\u0026sharedCounter, 1) } fmt.Println(\"add done\") wg.Done() } func sub(count int, wg *sync.WaitGroup) { for i := 0; i \u003c count; i++ { atomic.AddInt64(\u0026sharedCounter, -1) } fmt.Println(\"sub done\") wg.Done() } func show() { fmt.Println(sharedCounter) } func main() { wg := sync.WaitGroup{} wg.Add(2) go add(1000000, \u0026wg) go sub(1000000, \u0026wg) wg.Wait() show() } 注意:传递 WaitGroup时要使用引用传递(指针), 其不应该被复制. func sub(count int, wg *sync.WaitGroup) ","date":"2022-06-12","objectID":"/%E8%81%8A%E8%81%8Ago%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84sync/:4:1","tags":["go","sync"],"title":"聊聊go语言中的sync","uri":"/%E8%81%8A%E8%81%8Ago%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84sync/"},{"categories":["golang"],"content":"context.Context Context提供了2个功能 控制子协程结束 传递值 其不在sync包中, 后面专门讲 ","date":"2022-06-12","objectID":"/%E8%81%8A%E8%81%8Ago%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84sync/:4:2","tags":["go","sync"],"title":"聊聊go语言中的sync","uri":"/%E8%81%8A%E8%81%8Ago%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84sync/"},{"categories":["golang"],"content":"sync.Pool 对象复用 其提供一个\"并发安全\"的可复用的对象池. 用来减少频繁GC所代理的压力. 其大概意思是: 如果有旧对象可用,则用旧的, 没有再New一个 参考这批文章: https://www.cnblogs.com/qcrao-2018/p/12736031.html 以及这里 https://geektutu.com/post/hpg-sync-pool.html 在实际开发工作中, 不要一上来就想做使用sync.Pool它通常会带来问题(因为其Get出来的对象的状态是不确定的), 而应该遵循下面的原则: 根据你收集到的需求设计你的代码（不要跳过这个步骤）。 编写最简单、最清晰、最愚蠢的设计实现。 如果客户满意，就停止 如果客户不满意，而且他们认为应用程序的性能不能满足他们的要求，那么就剖析。 解决最高性能的主导者 剖析并进入第五阶段。然后进入3 如果实在搞不定, 再想想sync.Pool ","date":"2022-06-12","objectID":"/%E8%81%8A%E8%81%8Ago%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84sync/:5:0","tags":["go","sync"],"title":"聊聊go语言中的sync","uri":"/%E8%81%8A%E8%81%8Ago%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84sync/"},{"categories":["golang"],"content":"sync.Once 只执行一次 sync.Once 提供了一种方法, 让相关代码只被执行一次 实际开发过程中, 经常有这样的场景: 你做了一个叫做lowLevelApi的包, 用于控制底层设备, 比如开关LED, 但在调用开关LED之前需要确保一些初始化工作已经完成, 所以你写了一个InitEnv的函数, 并告诉其它开发人员: 一定要先初始化哦. package lowLevelApi import \"fmt\" func InitEnv() { fmt.Println(\"init environment\") } func LedOn() { fmt.Println(\"LedOn\") } func LedOff() { fmt.Println(\"LedOff\") } 其它开发人员经常会问你: 这个初始化函数如果被重复调用不会出问题吧? 因为他们的代码通常会这样写: package main import ( \"fmt\" \"goplayground/lowLevelApi\" ) func turnLedOn() { fmt.Println(\"Turning LED on\") lowLevelApi.InitEnv() lowLevelApi.LedOn() fmt.Println(\"LED on\") } func turnLedOff() { fmt.Println(\"Turning LED off\") lowLevelApi.InitEnv() lowLevelApi.LedOff() fmt.Println(\"LED off\") } func main() { turnLedOn() turnLedOff() } 上面的代码会输出 Turning LED on InitEnv LedOn LED on Turning LED off InitEnv LedOff LED off 为了防止重复调用InitEnv()可能带来的问题, 则可以使用sync.Once var ( once sync.Once ) func InitEnv() { once.Do(func() { fmt.Println(\"InitEnv\") }) } 这样InitEnv()即使被多次调用, 其内部逻辑只会执行一次 Turning LED on InitEnv LedOn LED on Turning LED off LedOff LED off sync.Once 常应用于单例模式，例如初始化配置、保持数据库连接等。作用与 init 函数类似，但有区别。 init 函数是当所在的 package 首次被加载时执行，若迟迟未被使用，则既浪费了内存，又延长了程序加载时间。 sync.Once 可以在代码的任意位置初始化和调用，因此可以延迟到使用时再执行，并发场景下是线程安全的。 ","date":"2022-06-12","objectID":"/%E8%81%8A%E8%81%8Ago%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84sync/:6:0","tags":["go","sync"],"title":"聊聊go语言中的sync","uri":"/%E8%81%8A%E8%81%8Ago%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84sync/"},{"categories":["golang"],"content":"sync.Cond 条件变量 sync.Cond 用于协调多个协程访问共享资源, 其中某些协程处于阻塞状态, 另外一个协程在条件准备好的时候来讲其它协程唤醒. 下面的例子中 InitEnv函数需要一点时间在准备sharedCounter 的初始值, 在这期间Add和sub处于Wait状态, 当准备好后, 将通知 Add和Sub继续向下执行 package main import ( \"fmt\" \"sync\" \"time\" ) var ( sharedCounter int ) func InitEnv(c *sync.Cond) { fmt.Println(\"begin InitEnv\") time.Sleep(time.Second * 1) c.L.Lock() sharedCounter = 10 c.L.Unlock() fmt.Println(\"Init Env Done, broadcast...\") c.Broadcast() } func Add(cout int, c *sync.Cond) { c.L.Lock() c.Wait() sharedCounter += cout c.L.Unlock() fmt.Println(\"Add Done\") } func Sub(count int, c *sync.Cond) { c.L.Lock() c.Wait() sharedCounter -= count c.L.Unlock() fmt.Println(\"Sub Done\") } func main() { cond := sync.NewCond(\u0026sync.Mutex{}) go InitEnv(cond) go Add(5, cond) go Sub(2, cond) time.Sleep(2 * time.Second) fmt.Println(\"Final Counter:\", sharedCounter) } 输出 begin InitEnv Init Env Done, broadcast... Add Done Sub Done Final Counter: 13 c.Broadcast()唤醒所有等待的协程, 另外还有一个Signal()方法, 用于唤醒一个协程. sync.Cond一般用于一对多的情况, 如果是一对一的情况, 用一个信道就可以轻松解决了 ","date":"2022-06-12","objectID":"/%E8%81%8A%E8%81%8Ago%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84sync/:7:0","tags":["go","sync"],"title":"聊聊go语言中的sync","uri":"/%E8%81%8A%E8%81%8Ago%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84sync/"},{"categories":["golang"],"content":"sync.Map 内置的map不是并发安全的, 所以 sync.Map 提供了一个功能与map类似但是并发安全的版本 可以参考这篇文章 https://juejin.cn/post/6844903895227957262 ","date":"2022-06-12","objectID":"/%E8%81%8A%E8%81%8Ago%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84sync/:8:0","tags":["go","sync"],"title":"聊聊go语言中的sync","uri":"/%E8%81%8A%E8%81%8Ago%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84sync/"},{"categories":["golang"],"content":"go语言中net/http包对http服务与请求的处理 ","date":"2022-06-06","objectID":"/go%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84http%E6%9C%8D%E5%8A%A1%E5%99%A8/:0:0","tags":["go","http"],"title":"Go语言中的http服务器","uri":"/go%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84http%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"categories":["golang"],"content":"简单的文件服务器 package main import ( \"log\" \"net/http\" ) func main() { err := http.ListenAndServe(\":8080\", http.FileServer(http.Dir(\".\"))) if err != nil { log.Fatal(err) } } 上面这个例子创建了一个以当前目录为站点跟目录的文件服务器, 我一般用这个来作为局域网文件共享. 然后写一个函数放到bash.rc 或zshrc中 #文件服务器 function fileserver(){ echo \"start file server :12345\" cat \u003c\u003cEOF | tee /tmp/fileserver.go | go run /tmp/fileserver.go package main import ( \"log\" \"net/http\" ) func main() { err := http.ListenAndServe(\":12345\", http.FileServer(http.Dir(\".\"))) if err != nil { log.Fatal(err) } } EOF } OSX MP16 ~/Downloads ❯ fileserver start file server :12345 Python中有相同的功能 python3 -m SimpleHTTPServer 7777 或 python3 -m http.server ","date":"2022-06-06","objectID":"/go%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84http%E6%9C%8D%E5%8A%A1%E5%99%A8/:1:0","tags":["go","http"],"title":"Go语言中的http服务器","uri":"/go%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84http%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"categories":["golang"],"content":"一个简单的WebServer package main import ( \"log\" \"net/http\" ) func main() { http.HandleFunc(\"/\", func(w http.ResponseWriter, r *http.Request) { _, err := w.Write([]byte(\"Hello World!\\n\")) if err != nil { log.Println(err) } }) err := http.ListenAndServe(\":12345\", nil) if err != nil { log.Fatal(err) } } 访问一下试试: OSX MP16 ~/Downloads/goplayground ❯ curl http://localhost:12345 Hello World! ","date":"2022-06-06","objectID":"/go%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84http%E6%9C%8D%E5%8A%A1%E5%99%A8/:2:0","tags":["go","http"],"title":"Go语言中的http服务器","uri":"/go%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84http%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"categories":["golang"],"content":"http.HandleFunc http.HandleFunc(\"/\", func(w http.ResponseWriter, r *http.Request) { //... }) 该方法提供了一种指定如何处理特定路由的请求的方法, 第一个参数为路由, 第二个参数为处理函数. 处理函数可写成匿名函数, 也可以声明为一个独立的函数 func rootHandler(w http.ResponseWriter, r *http.Request) { _, err := w.Write([]byte(\"\u003ch1 style=\\\"color:Tomato;\\\"\u003eHello World\u003c/h1\u003e\")) if err != nil { log.Println(err) } } func main() { http.HandleFunc(\"/\", rootHandler) //... } 函数的第一个参数是http.ResponseWriter类型的值。这是用于向任何连接的HTTP客户端发送响应的机制。这也是响应标头的设置方式,比如w.WriteHeader(http.StatusOK)。第二个论点是指向http.Request的指针。这是从网络请求中检索数据的方式。例如，可以通过请求指针访问表单提交的详细信息 比如 下面的方法, 使用 http://127.0.0.1:12345/?key=date 时将返回当前的日期, 确实key=或key不正确时返回http.StatusBadRequest func rootHandler(w http.ResponseWriter, r *http.Request) { keys, ok := r.URL.Query()[\"key\"] if !ok || len(keys[0]) \u003c 1 { log.Println(\"Url Param 'key' is missing\") w.WriteHeader(http.StatusBadRequest) _, err := w.Write([]byte(\"Url Param 'key' is missing\")) if err != nil { log.Println(err) return } return } key := keys[0] switch key { case \"date\": w.WriteHeader(http.StatusOK) _, err := w.Write([]byte(time.Now().Format(\"2006-01-02\"))) if err != nil { log.Println(err) } default: w.WriteHeader(http.StatusBadRequest) _, _ = w.Write([]byte(\"Invalid key\")) log.Println(\"Invalid key\") } } ","date":"2022-06-06","objectID":"/go%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84http%E6%9C%8D%E5%8A%A1%E5%99%A8/:3:0","tags":["go","http"],"title":"Go语言中的http服务器","uri":"/go%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84http%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"categories":["golang"],"content":"http.ResponseWriter 用于向任何连接的HTTP客户端发送响应 设置相应标志头: w.WriteHeader(http.StatusOK) 获取或实则响应头 w.Header().Set(\"content-type\", \"application/json\") w.Header().Add(\"foo\", \"bar\") 写入相应数据: w.Write([]byte(time.Now().Format(\"2006-01-02\"))) 例子: package main import ( \"encoding/json\" \"log\" \"net/http\" ) type SystemInfo struct { Hostname string `json:\"hostname\"` Uptime string `json:\"uptime\"` } func rootHandler(w http.ResponseWriter, r *http.Request) { info := SystemInfo{ Hostname: \"test\", Uptime: \"2022-01-01 00:00:00\", } w.Header().Set(\"Content-Type\", \"application/json\") w.WriteHeader(http.StatusOK) bytes, _ := json.Marshal(info) _, err := w.Write(bytes) if err != nil { log.Println(\"Error writing response: \", err) } } func main() { http.HandleFunc(\"/\", rootHandler) err := http.ListenAndServe(\":12345\", nil) if err != nil { log.Fatal(err) } } OSX MP16 ~ ❯ curl localhost:12345 {\"hostname\":\"test\",\"uptime\":\"2022-01-01 00:00:00\"} ","date":"2022-06-06","objectID":"/go%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84http%E6%9C%8D%E5%8A%A1%E5%99%A8/:3:1","tags":["go","http"],"title":"Go语言中的http服务器","uri":"/go%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84http%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"categories":["golang"],"content":"*http.Request 指向http.Request的指针, 通过改指针可以获取请求中的各种数据, 比如 获取基本信息 func rootHandler(w http.ResponseWriter, r *http.Request) { fmt.Println(\"User Agent: \", r.UserAgent()) fmt.Println(\"Host: \", r.Host) fmt.Println(\"Remote Address: \", r.RemoteAddr) fmt.Println(\"Request URI: \", r.RequestURI) fmt.Println(\"Method: \", r.Method) fmt.Println(\"URL: \", r.URL) fmt.Println(\"Header: \", r.Header) w.WriteHeader(http.StatusOK) } 输出: User Agent: curl/7.79.1 Host: localhost:12345 Remote Address: 127.0.0.1:58967 Request URI: / Method: GET URL: / Header: map[Accept:[*/*] User-Agent:[curl/7.79.1]] 获取cookie func rootHandler(w http.ResponseWriter, r *http.Request) { //获取所有 for _, c := range r.Cookies() { fmt.Printf(\"%s : %q\\n\", c.Name, c.Value) } //获取指定 c, err := r.Cookie(\"token\") if err != nil { log.Println(err) } fmt.Printf(\"%s : %q\\n\", c.Name, c.Value) w.WriteHeader(http.StatusOK) } curl --cookie \"token=abcdefg\" http://localhost:12345 获取GET参数 获取所有参数 args := r.URL.Query() 获取指定参数(注:参数可能被重复写多次) 比如: localhost:12345/?id=5 func rootHandler(w http.ResponseWriter, r *http.Request) { ids, ok := r.URL.Query()[\"id\"] if !ok || len(ids[0]) \u003c 1 { log.Println(\"Url Param 'id' is missing\") return } id := ids[0] log.Println(\"Url Param 'id' is: \" + id) w.WriteHeader(http.StatusOK) } 或者 func rootHandler(w http.ResponseWriter, r *http.Request) { id := r.FormValue(\"id\") if id == \"\" { log.Println(\"Url Param 'id' is missing\") } fmt.Println(\"id:\", id) w.WriteHeader(http.StatusOK) } 也可以通过r.Form来获取Get参数 获取PATCH, POST or PUT参数 比如 curl -d \"id=5\u0026format=1\" http://localhost:12345/ func rootHandler(w http.ResponseWriter, r *http.Request) { //parse err := r.ParseForm() if err != nil { log.Println(\"ParseForm error:\", err) } //get post args for k, v := range r.PostForm { log.Println(\"key:\", k) log.Println(\"val:\", v) // v []string } w.WriteHeader(http.StatusOK) } 输出 2022/06/06 15:14:46 key: id 2022/06/06 15:14:46 val: [5] 2022/06/06 15:14:46 key: format 2022/06/06 15:14:46 val: [1] ParseForm会填充r.Form和r.PostForm。 对于所有的请求，ParseForm解析来自URL的原始查询并更新r.Form。 对于POST、PUT和PATCH请求，它也读取请求正文，将其解析为一个表单，并将结果放入r.PostForm和r.Form中。在r.Form中，请求正文参数优先于URL查询字符串值。 如果请求体的大小还没有被MaxBytesReader限制，那么其大小将被限制在10MB。 对于其他HTTP方法，或者当内容类型不是application/x-www-form-urlencoded时，请求正文不被读取，并且r.PostForm被初始化为一个非零的空值。 ParseMultipartForm自动调用ParseForm。ParseForm是幂等的。 r.Form属性包含了post表单和url中的get参数。 r.PostForm属性只包含了post表单参数。 获取指定参数, 比如 func rootHandler(w http.ResponseWriter, r *http.Request) { err := r.ParseForm() if err != nil { log.Println(\"ParseForm error:\", err) } ids := r.PostForm.Get(\"id\") //获取id参数的第一个值 log.Println(\"id:\", ids) w.WriteHeader(http.StatusOK) } 或者 func rootHandler(w http.ResponseWriter, r *http.Request) { id := r.PostFormValue(\"id\") if id == \"\" { log.Println(\"Url Param 'id' is missing\") } fmt.Println(\"id:\", id) w.WriteHeader(http.StatusOK) } 获取上传文件 比如 curl -F \"file=@IMG_1526.PNG;type=image/png\" http://localhost:12345/upload 下面代码中: r.ParseMultipartForm(10 \u003c\u003c 20)将一个请求体解析为multipart/form-data。整个请求正文被解析，并且其文件部分最多存储在maxMemory字节的内存中，其余部分则存储在磁盘的临时文件中。ParseMultipartForm在必要时调用ParseForm。如果ParseForm返回一个错误，ParseMultipartForm将其返回，但也继续解析请求正文。在对ParseMultipartForm进行一次调用后，随后的调用没有任何影响. FormFile 返回提供的表单key的第一个文件。如果需要，FormFile会调用ParseMultipartForm和ParseForm。 package main import ( \"io\" \"log\" \"mime/multipart\" \"net/http\" \"os\" ) func uploadHandler(w http.ResponseWriter, r *http.Request) { // Parse the multipart form in the request err := r.ParseMultipartForm(10 \u003c\u003c 20) // 10 MiB if err != nil { http.Error(w, err.Error(), http.StatusInternalServerError) return } // FormFile returns the first file for the given key `file` // it also returns the FileHeader, so we can get the Filename, the Header and the size of the file file, handler, err := r.FormFile(\"file\") if err != nil { http.Error(w, err.Error(), http.StatusInternalServerError) return } defer func(file multipart.File) { err := file.Close() if err != nil { log.Println(err) } }(file) err = os.MkdirAll(\"./upload\", 0777) if err != nil { http.Error(w, err.Error(), http.StatusInternalServerError) re","date":"2022-06-06","objectID":"/go%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84http%E6%9C%8D%E5%8A%A1%E5%99%A8/:3:2","tags":["go","http"],"title":"Go语言中的http服务器","uri":"/go%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84http%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"categories":["golang"],"content":"Handler , Handle , HandleFunc 与 http.ListenAndServe 使用默认的Handler 先看一个简单的例子 package main import \"net/http\" func main() { http.HandleFunc(\"/\", func(w http.ResponseWriter, r *http.Request) { w.Write([]byte(\"Hello, world!\")) }) http.HandleFunc(\"/blog\", func(w http.ResponseWriter, r *http.Request) { w.Write([]byte(\"This is my Blog\")) }) http.ListenAndServe(\":12345\", nil) } 在启动一个HttpServer的时候, 其实我们就关心2个东西: 地址 路由: 将请求对应到相应的处理函数中去 这两个参数 在http.ListenAndServe(\":12345\", nil)中进行设置的, 第一个为地址, 第二个传递处理函数. 如果传递nil, 则采用默认的 The handler is typically nil, in which case the DefaultServeMux is used. http.ListenAndServe的实现如下: func ListenAndServe(addr string, handler Handler) error { server := \u0026Server{Addr: addr, Handler: handler} return server.ListenAndServe() } type Handler interface { ServeHTTP(ResponseWriter, *Request) } 可以看到 Handler是一个接口, 实现这个接口的话, 我们可以创建自己的Handler 自定义Handler 定义一个结构体, 结构体实现 ServeHTTP(w http.ResponseWriter, r *http.Request)方法 然后使用 Handle函数进行路由注册 package main import \"net/http\" type MyIndexHandler struct { } func (h *MyIndexHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) { w.Write([]byte(\"Hello World\")) } type MyBlogHandler struct { } func (h *MyBlogHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) { w.Write([]byte(\"This is my Blog\")) } func main() { mux := http.NewServeMux() mux.Handle(\"/\", \u0026MyIndexHandler{}) mux.Handle(\"/blog\", \u0026MyBlogHandler{}) http.ListenAndServe(\":12345\", mux) } OSX MP16 ~ ❯ curl localhost:12345 Hello World OSX MP16 ~ ❯ curl localhost:12345/blog This is my Blog OSX MP16 ~ ❯ 但这明显看出来, 对每一个路由 都要高写一个xxxHandler结构体和实现ServeHTTP, 看上去非常混乱 这时候就可以用mux.HandleFunc来实现路由 package main import \"net/http\" func main() { mux := http.NewServeMux() mux.HandleFunc(\"/\", func(w http.ResponseWriter, r *http.Request) { w.Write([]byte(\"Hello World\")) }) mux.HandleFunc(\"/blog\", func(w http.ResponseWriter, r *http.Request) { w.Write([]byte(\"This is my Blog\")) }) http.ListenAndServe(\":12345\", mux) } 自定义ServeMux 在上面的例子中, mux := http.NewServeMux()还是使用了默认router, 其简单的同时也有不少缺点 比如, 其是通过url进行路由, 但不支持基于方法(GET, POST…)的路由, 不支持正则表达式等等 参考这个 https://www.alexedwards.net/blog/which-go-router-should-i-use ","date":"2022-06-06","objectID":"/go%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84http%E6%9C%8D%E5%8A%A1%E5%99%A8/:3:3","tags":["go","http"],"title":"Go语言中的http服务器","uri":"/go%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84http%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"categories":["golang"],"content":"人气Web框架 参考这篇文章, https://blog.51cto.com/coderaction/3001008 其中有各框架的对比, 功能上iris最全 https://github.com/kataras/iris ","date":"2022-06-06","objectID":"/go%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84http%E6%9C%8D%E5%8A%A1%E5%99%A8/:4:0","tags":["go","http"],"title":"Go语言中的http服务器","uri":"/go%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84http%E6%9C%8D%E5%8A%A1%E5%99%A8/"}]